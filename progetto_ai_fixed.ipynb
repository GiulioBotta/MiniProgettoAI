{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFhm9N37M7yb"
      },
      "source": [
        "# Mini Progetto Intelligenza Artificiale - Riconoscimento cifre manoscritte\n",
        "\n",
        "**Nome:** Giulio\n",
        "\n",
        "**Cognome:** Bottacin\n",
        "\n",
        "**Matricola:** 2042340\n",
        "\n",
        "**Data consegna:** 5/6/2025\n",
        "\n",
        "## Obiettivo\n",
        "\n",
        "In questo progetto esploreremo il riconoscimento di cifre manoscritte utilizzando il dataset MNIST, implementando simulazioni per studiare come diversi fattori influenzano le prestazioni dei modelli di deep learning. Analizzeremo in particolare l'impatto degli iperparametri, la robustezza al rumore e l'effetto della quantità di dati di training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQ9r2bcoM7yc"
      },
      "source": [
        "## Importazione delle librerie necessarie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FWfy5ZGJM7yc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from torchvision.datasets import MNIST, FashionMNIST\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configurazione per riproducibilità\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "plt.rcParams['figure.figsize'] = (12, 6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPkiWe_UM7yc"
      },
      "source": [
        "## Funzioni Helper Globali"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NHAaPe9OM7yd"
      },
      "outputs": [],
      "source": [
        "def stampa_header_esperimento(num_esp, totale, tipo_modello, config):\n",
        "    print(f\"\\n[{num_esp:2d}/{totale}] {tipo_modello}: {config}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "def stampa_risultati_esperimento(risultati):\n",
        "    print(f\"Accuracy Training: {risultati['train_accuracy']:.4f} | Accuracy Test: {risultati['test_accuracy']:.4f}\")\n",
        "    print(f\"Tempo: {risultati['training_time']:6.1f}s | Iterazioni: {risultati['iterations']:3d}\")\n",
        "    print(f\"Overfitting: {risultati['overfitting']:+.4f}\")\n",
        "\n",
        "def crea_modello_cnn(tipo_architettura, learning_rate):\n",
        "    model = keras.Sequential()\n",
        "\n",
        "    if tipo_architettura == 'baseline':\n",
        "        model.add(keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)))\n",
        "        model.add(keras.layers.Flatten())\n",
        "        model.add(keras.layers.Dense(50, activation='relu'))\n",
        "    elif tipo_architettura == 'extended':\n",
        "        model.add(keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)))\n",
        "        model.add(keras.layers.MaxPooling2D(2,2))\n",
        "        model.add(keras.layers.Conv2D(64, (3,3), activation='relu'))\n",
        "        model.add(keras.layers.Flatten())\n",
        "        model.add(keras.layers.Dense(100, activation='relu'))\n",
        "\n",
        "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "                  loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def add_gaussian_noise(images, noise_std):\n",
        "    np.random.seed(42)\n",
        "    noise = np.random.normal(0, noise_std, images.shape)\n",
        "    noisy_images = images + noise\n",
        "    return np.clip(noisy_images, 0, 1)\n",
        "\n",
        "def crea_mlp_ottimale():\n",
        "    return MLPClassifier(\n",
        "        hidden_layer_sizes=(50,),\n",
        "        learning_rate_init=0.01,\n",
        "        max_iter=100,\n",
        "        early_stopping=True,\n",
        "        validation_fraction=0.1,\n",
        "        tol=0.001,\n",
        "        n_iter_no_change=10,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "def crea_cnn_ottimale():\n",
        "    return crea_modello_cnn('baseline', 0.01)\n",
        "\n",
        "# Variabili globali per configurazioni e modelli ottimali\n",
        "BEST_MLP_CONFIG = None\n",
        "BEST_CNN_CONFIG = None\n",
        "BEST_MLP = None\n",
        "BEST_CNN = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prxr6uB6M7yd"
      },
      "source": [
        "## Caricamento e preparazione del dataset MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1E9bCo81M7yd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f14318e0-d925-4cee-e0ad-decbc8a262c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Caricamento dataset MNIST...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 18.0MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 487kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.49MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 5.46MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset caricato: 60000 esempi di training, 10000 esempi di test\n"
          ]
        }
      ],
      "source": [
        "# Caricamento dataset MNIST\n",
        "print(\"Caricamento dataset MNIST...\")\n",
        "mnist_tr = MNIST(root=\"./data\", train=True, download=True)\n",
        "mnist_te = MNIST(root=\"./data\", train=False, download=True)\n",
        "\n",
        "# Conversione in array numpy\n",
        "mnist_tr_data, mnist_tr_labels = mnist_tr.data.numpy(), mnist_tr.targets.numpy()\n",
        "mnist_te_data, mnist_te_labels = mnist_te.data.numpy(), mnist_te.targets.numpy()\n",
        "\n",
        "# Preprocessing per MLP (vettorizzazione e normalizzazione)\n",
        "x_tr = mnist_tr_data.reshape(60000, 28 * 28) / 255.0\n",
        "x_te = mnist_te_data.reshape(10000, 28 * 28) / 255.0\n",
        "\n",
        "# Preprocessing per CNN (mantenendo formato 2D)\n",
        "x_tr_conv = x_tr.reshape(-1, 28, 28, 1)\n",
        "x_te_conv = x_te.reshape(-1, 28, 28, 1)\n",
        "\n",
        "print(f\"Dataset caricato: {x_tr.shape[0]} esempi di training, {x_te.shape[0]} esempi di test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auamlpxLM7yd"
      },
      "source": [
        "## Punto A: Effetto degli iperparametri sulle prestazioni\n",
        "\n",
        "Analizziamo sistematicamente come variano le prestazioni dei modelli MLP e CNN al variare degli iperparametri chiave. Confronteremo 18 configurazioni MLP e 6 configurazioni CNN per un totale di 24 esperimenti mirati."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLy-g9bBM7yd"
      },
      "source": [
        "### Configurazione esperimenti sistematici\n",
        "\n",
        "***MLP (18 esperimenti):***\n",
        "\n",
        "- **Neuroni per strato**: *50, 100, 250* per testare la copertura da reti piccole a medio-grandi\n",
        "\n",
        "- **Numero layers**: *1 vs 2* strati nascosti per fare il confronto profondità vs larghezza\n",
        "\n",
        "- **Learning rate**: *0.001, 0.01, 0.1*\n",
        "\n",
        "***CNN (6 esperimenti):***\n",
        "\n",
        "- **Filtri**: *32*, standard per MNIST, computazionalmente efficiente\n",
        "\n",
        "- **Architettura**: *baseline vs extended* per fare il confronto sulla complessità\n",
        "\n",
        "- **Learning rate**: *0.001, 0.01, 0.1*\n",
        "\n",
        "Per tutti gli esperimenti si è scelto di utilizzare il solver **Adam**, ormai standard."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qagR-cawM7ye"
      },
      "source": [
        "### Esperimenti sistematici MLP e CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JLpQMkE5M7ye",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1104acd4-0fac-4196-f0fc-ba2cf5151ca9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INIZIO ESPERIMENTI MLP\n",
            "============================================================\n",
            "\n",
            "[ 1/18] MLP: 50n_1S_lr0.001\n",
            "--------------------------------------------------\n",
            "Accuracy Training: 0.9891 | Accuracy Test: 0.9707\n",
            "Tempo:   30.0s | Iterazioni:  24\n",
            "Overfitting: +0.0184\n",
            "\n",
            "[ 2/18] MLP: 50n_1S_lr0.01\n",
            "--------------------------------------------------\n",
            "Accuracy Training: 0.9844 | Accuracy Test: 0.9697\n",
            "Tempo:   19.0s | Iterazioni:  17\n",
            "Overfitting: +0.0147\n",
            "\n",
            "[ 3/18] MLP: 50n_1S_lr0.1\n",
            "--------------------------------------------------\n",
            "Accuracy Training: 0.9239 | Accuracy Test: 0.9155\n",
            "Tempo:   21.3s | Iterazioni:  17\n",
            "Overfitting: +0.0084\n",
            "\n",
            "[ 4/18] MLP: 50n_2S_lr0.001\n",
            "--------------------------------------------------\n",
            "Accuracy Training: 0.9905 | Accuracy Test: 0.9729\n",
            "Tempo:   37.6s | Iterazioni:  27\n",
            "Overfitting: +0.0176\n",
            "\n",
            "[ 5/18] MLP: 50n_2S_lr0.01\n",
            "--------------------------------------------------\n",
            "Accuracy Training: 0.9881 | Accuracy Test: 0.9689\n",
            "Tempo:   34.6s | Iterazioni:  27\n",
            "Overfitting: +0.0192\n",
            "\n",
            "[ 6/18] MLP: 50n_2S_lr0.1\n",
            "--------------------------------------------------\n",
            "Accuracy Training: 0.7978 | Accuracy Test: 0.7985\n",
            "Tempo:   21.1s | Iterazioni:  15\n",
            "Overfitting: -0.0007\n",
            "\n",
            "[ 7/18] MLP: 100n_1S_lr0.001\n",
            "--------------------------------------------------\n",
            "Accuracy Training: 0.9971 | Accuracy Test: 0.9771\n",
            "Tempo:   50.1s | Iterazioni:  26\n",
            "Overfitting: +0.0201\n",
            "\n",
            "[ 8/18] MLP: 100n_1S_lr0.01\n",
            "--------------------------------------------------\n",
            "Accuracy Training: 0.9926 | Accuracy Test: 0.9753\n",
            "Tempo:   47.4s | Iterazioni:  26\n",
            "Overfitting: +0.0173\n",
            "\n",
            "[ 9/18] MLP: 100n_1S_lr0.1\n",
            "--------------------------------------------------\n",
            "Accuracy Training: 0.9168 | Accuracy Test: 0.9148\n",
            "Tempo:   23.4s | Iterazioni:  13\n",
            "Overfitting: +0.0020\n",
            "\n",
            "[10/18] MLP: 100n_2S_lr0.001\n",
            "--------------------------------------------------\n",
            "Accuracy Training: 0.9967 | Accuracy Test: 0.9786\n",
            "Tempo:   43.1s | Iterazioni:  20\n",
            "Overfitting: +0.0181\n",
            "\n",
            "[11/18] MLP: 100n_2S_lr0.01\n",
            "--------------------------------------------------\n",
            "Accuracy Training: 0.9891 | Accuracy Test: 0.9715\n",
            "Tempo:   52.3s | Iterazioni:  24\n",
            "Overfitting: +0.0176\n",
            "\n",
            "[12/18] MLP: 100n_2S_lr0.1\n",
            "--------------------------------------------------\n",
            "Accuracy Training: 0.8704 | Accuracy Test: 0.8755\n",
            "Tempo:   32.4s | Iterazioni:  13\n",
            "Overfitting: -0.0051\n",
            "\n",
            "[13/18] MLP: 250n_1S_lr0.001\n",
            "--------------------------------------------------\n",
            "Accuracy Training: 0.9981 | Accuracy Test: 0.9810\n",
            "Tempo:   91.3s | Iterazioni:  24\n",
            "Overfitting: +0.0171\n",
            "\n",
            "[14/18] MLP: 250n_1S_lr0.01\n",
            "--------------------------------------------------\n",
            "Accuracy Training: 0.9911 | Accuracy Test: 0.9780\n",
            "Tempo:   88.0s | Iterazioni:  24\n",
            "Overfitting: +0.0131\n",
            "\n",
            "[15/18] MLP: 250n_1S_lr0.1\n",
            "--------------------------------------------------\n",
            "Accuracy Training: 0.9242 | Accuracy Test: 0.9176\n",
            "Tempo:   53.3s | Iterazioni:  14\n",
            "Overfitting: +0.0066\n",
            "\n",
            "[16/18] MLP: 250n_2S_lr0.001\n",
            "--------------------------------------------------\n",
            "Accuracy Training: 0.9971 | Accuracy Test: 0.9803\n",
            "Tempo:  158.5s | Iterazioni:  29\n",
            "Overfitting: +0.0168\n",
            "\n",
            "[17/18] MLP: 250n_2S_lr0.01\n",
            "--------------------------------------------------\n",
            "Accuracy Training: 0.9896 | Accuracy Test: 0.9746\n",
            "Tempo:  143.6s | Iterazioni:  26\n",
            "Overfitting: +0.0150\n",
            "\n",
            "[18/18] MLP: 250n_2S_lr0.1\n",
            "--------------------------------------------------\n",
            "Accuracy Training: 0.6490 | Accuracy Test: 0.6452\n",
            "Tempo:  164.4s | Iterazioni:  30\n",
            "Overfitting: +0.0038\n",
            "\n",
            "\n",
            "INIZIO ESPERIMENTI CNN\n",
            "============================================================\n",
            "\n",
            "[ 1/6] CNN: CNN_baseline_lr0.001\n",
            "--------------------------------------------------\n",
            "Accuracy Training: 0.9909 | Accuracy Test: 0.9790\n",
            "Tempo:  268.9s | Iterazioni:   8\n",
            "Overfitting: +0.0120\n",
            "\n",
            "[ 2/6] CNN: CNN_baseline_lr0.01\n",
            "--------------------------------------------------\n",
            "Accuracy Training: 0.9850 | Accuracy Test: 0.9747\n",
            "Tempo:  185.9s | Iterazioni:   6\n",
            "Overfitting: +0.0103\n",
            "\n",
            "[ 3/6] CNN: CNN_baseline_lr0.1\n",
            "--------------------------------------------------\n",
            "Accuracy Training: 0.9307 | Accuracy Test: 0.9187\n",
            "Tempo:  281.5s | Iterazioni:  11\n",
            "Overfitting: +0.0120\n",
            "\n",
            "[ 4/6] CNN: CNN_extended_lr0.001\n",
            "--------------------------------------------------\n",
            "Accuracy Training: 0.9942 | Accuracy Test: 0.9892\n",
            "Tempo:  491.4s | Iterazioni:   9\n",
            "Overfitting: +0.0050\n",
            "\n",
            "[ 5/6] CNN: CNN_extended_lr0.01\n",
            "--------------------------------------------------\n",
            "Accuracy Training: 0.9887 | Accuracy Test: 0.9823\n",
            "Tempo:  446.2s | Iterazioni:   8\n",
            "Overfitting: +0.0064\n",
            "\n",
            "[ 6/6] CNN: CNN_extended_lr0.1\n",
            "--------------------------------------------------\n",
            "Accuracy Training: 0.1022 | Accuracy Test: 0.1010\n",
            "Tempo:  243.6s | Iterazioni:   6\n",
            "Overfitting: +0.0012\n"
          ]
        }
      ],
      "source": [
        "# Configurazione esperimenti\n",
        "neuroni_lista = [50, 100, 250]\n",
        "strati_lista = [1, 2]\n",
        "learning_rates = [0.001, 0.01, 0.1]\n",
        "architetture_cnn = ['baseline', 'extended']\n",
        "\n",
        "risultati_mlp = []\n",
        "risultati_cnn = []\n",
        "\n",
        "print(\"INIZIO ESPERIMENTI MLP\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Esperimenti MLP\n",
        "contatore = 0\n",
        "esperimenti_totali = len(neuroni_lista) * len(strati_lista) * len(learning_rates)\n",
        "\n",
        "for neuroni in neuroni_lista:\n",
        "    for n_strati in strati_lista:\n",
        "        for lr in learning_rates:\n",
        "            contatore += 1\n",
        "\n",
        "            if n_strati == 1:\n",
        "                strati_nascosti = (neuroni,)\n",
        "                nome_config = f\"{neuroni}n_1S_lr{lr}\"\n",
        "            else:\n",
        "                strati_nascosti = (neuroni, neuroni)\n",
        "                nome_config = f\"{neuroni}n_2S_lr{lr}\"\n",
        "\n",
        "            stampa_header_esperimento(contatore, esperimenti_totali, \"MLP\", nome_config)\n",
        "\n",
        "            mlp = MLPClassifier(\n",
        "                hidden_layer_sizes=strati_nascosti,\n",
        "                learning_rate_init=lr,\n",
        "                max_iter=100,\n",
        "                early_stopping=True,\n",
        "                validation_fraction=0.1,\n",
        "                tol=0.001,\n",
        "                n_iter_no_change=10,\n",
        "                random_state=42\n",
        "            )\n",
        "\n",
        "            tempo_inizio = time.time()\n",
        "            mlp.fit(x_tr, mnist_tr_labels)\n",
        "            tempo_training = time.time() - tempo_inizio\n",
        "\n",
        "            acc_train = mlp.score(x_tr, mnist_tr_labels)\n",
        "            acc_test = mlp.score(x_te, mnist_te_labels)\n",
        "\n",
        "            risultati = {\n",
        "                'tipo_modello': 'MLP',\n",
        "                'nome_config': nome_config,\n",
        "                'neuroni': neuroni,\n",
        "                'n_strati': n_strati,\n",
        "                'learning_rate': lr,\n",
        "                'strati_nascosti': strati_nascosti,\n",
        "                'train_accuracy': acc_train,\n",
        "                'test_accuracy': acc_test,\n",
        "                'overfitting': acc_train - acc_test,\n",
        "                'training_time': tempo_training,\n",
        "                'iterations': mlp.n_iter_,\n",
        "                'loss_curve': mlp.loss_curve_ if hasattr(mlp, 'loss_curve_') else [],\n",
        "                'parametri_totali': sum([layer.size for layer in mlp.coefs_]) + sum([layer.size for layer in mlp.intercepts_])\n",
        "            }\n",
        "\n",
        "            risultati_mlp.append(risultati)\n",
        "            stampa_risultati_esperimento(risultati)\n",
        "\n",
        "print(f\"\\n\\nINIZIO ESPERIMENTI CNN\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Esperimenti CNN\n",
        "contatore_cnn = 0\n",
        "esperimenti_totali_cnn = len(architetture_cnn) * len(learning_rates)\n",
        "\n",
        "for arch in architetture_cnn:\n",
        "    for lr in learning_rates:\n",
        "        contatore_cnn += 1\n",
        "        nome_config = f\"CNN_{arch}_lr{lr}\"\n",
        "\n",
        "        stampa_header_esperimento(contatore_cnn, esperimenti_totali_cnn, \"CNN\", nome_config)\n",
        "\n",
        "        model = crea_modello_cnn(arch, lr)\n",
        "        early_stopping = keras.callbacks.EarlyStopping(\n",
        "            patience=5, min_delta=0.001, restore_best_weights=True, verbose=0\n",
        "        )\n",
        "\n",
        "        tempo_inizio = time.time()\n",
        "        history = model.fit(x_tr_conv, mnist_tr_labels, validation_split=0.1, epochs=20,\n",
        "                           batch_size=128, callbacks=[early_stopping], verbose=0)\n",
        "        tempo_training = time.time() - tempo_inizio\n",
        "\n",
        "        train_loss, acc_train = model.evaluate(x_tr_conv, mnist_tr_labels, verbose=0)\n",
        "        test_loss, acc_test = model.evaluate(x_te_conv, mnist_te_labels, verbose=0)\n",
        "\n",
        "        risultati = {\n",
        "            'tipo_modello': 'CNN',\n",
        "            'nome_config': nome_config,\n",
        "            'architettura': arch,\n",
        "            'learning_rate': lr,\n",
        "            'train_accuracy': acc_train,\n",
        "            'test_accuracy': acc_test,\n",
        "            'overfitting': acc_train - acc_test,\n",
        "            'training_time': tempo_training,\n",
        "            'iterations': len(history.history['loss']),\n",
        "            'parametri_totali': model.count_params()\n",
        "        }\n",
        "\n",
        "        risultati_cnn.append(risultati)\n",
        "        stampa_risultati_esperimento(risultati)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCod5sI6M7ye"
      },
      "source": [
        "### Grafico 1: Effetto del Learning Rate sulle prestazioni MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-z4J_NxM7ye"
      },
      "outputs": [],
      "source": [
        "# Analisi learning rate - MLP e CNN\n",
        "dati_lr_001_mlp = [r for r in risultati_mlp if r['learning_rate'] == 0.001]\n",
        "dati_lr_01_mlp = [r for r in risultati_mlp if r['learning_rate'] == 0.01]\n",
        "dati_lr_1_mlp = [r for r in risultati_mlp if r['learning_rate'] == 0.1]\n",
        "\n",
        "dati_lr_001_cnn = [r for r in risultati_cnn if r['learning_rate'] == 0.001]\n",
        "dati_lr_01_cnn = [r for r in risultati_cnn if r['learning_rate'] == 0.01]\n",
        "dati_lr_1_cnn = [r for r in risultati_cnn if r['learning_rate'] == 0.1]\n",
        "\n",
        "# Accuratezze medie MLP\n",
        "acc_lr_001_mlp = np.mean([r['test_accuracy'] for r in dati_lr_001_mlp])\n",
        "acc_lr_01_mlp = np.mean([r['test_accuracy'] for r in dati_lr_01_mlp])\n",
        "acc_lr_1_mlp = np.mean([r['test_accuracy'] for r in dati_lr_1_mlp])\n",
        "\n",
        "# Accuratezze medie CNN\n",
        "acc_lr_001_cnn = np.mean([r['test_accuracy'] for r in dati_lr_001_cnn])\n",
        "acc_lr_01_cnn = np.mean([r['test_accuracy'] for r in dati_lr_01_cnn])\n",
        "acc_lr_1_cnn = np.mean([r['test_accuracy'] for r in dati_lr_1_cnn])\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Subplot 1: Curve di convergenza MLP (CNN non hanno loss_curve salvata)\n",
        "for i, (dati_lr, colore, etichetta) in enumerate([(dati_lr_001_mlp, 'green', 'MLP LR=0.001'),\n",
        "                                                   (dati_lr_01_mlp, 'blue', 'MLP LR=0.01'),\n",
        "                                                   (dati_lr_1_mlp, 'red', 'MLP LR=0.1')]):\n",
        "    if dati_lr and dati_lr[0]['loss_curve']:\n",
        "        curva_loss = dati_lr[0]['loss_curve']\n",
        "        ax1.plot(range(len(curva_loss)), curva_loss, color=colore, linewidth=2, label=etichetta)\n",
        "\n",
        "ax1.set_xlabel('Iterazioni')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax1.set_title('Pattern di Convergenza MLP per Learning Rate\\n(CNN: curve non disponibili)')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Subplot 2: Confronto accuratezza MLP vs CNN\n",
        "learning_rates_plot = [0.001, 0.01, 0.1]\n",
        "accuratezze_mlp = [acc_lr_001_mlp, acc_lr_01_mlp, acc_lr_1_mlp]\n",
        "accuratezze_cnn = [acc_lr_001_cnn, acc_lr_01_cnn, acc_lr_1_cnn]\n",
        "\n",
        "x_pos = np.arange(len(learning_rates_plot))\n",
        "width = 0.35\n",
        "\n",
        "bars_mlp = ax2.bar(x_pos - width/2, accuratezze_mlp, width,\n",
        "                   label='MLP', alpha=0.8, color='steelblue')\n",
        "bars_cnn = ax2.bar(x_pos + width/2, accuratezze_cnn, width,\n",
        "                   label='CNN', alpha=0.8, color='darkred')\n",
        "\n",
        "ax2.set_xlabel('Learning Rate')\n",
        "ax2.set_ylabel('Accuratezza Test Media')\n",
        "ax2.set_title('Confronto Accuratezza MLP vs CNN per Learning Rate')\n",
        "ax2.set_xticks(x_pos)\n",
        "ax2.set_xticklabels(['0.001', '0.01', '0.1'])\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# Annotazioni per MLP\n",
        "for i, (bar, acc) in enumerate(zip(bars_mlp, accuratezze_mlp)):\n",
        "    height = bar.get_height()\n",
        "    ax2.annotate(f'{acc:.3f}', xy=(bar.get_x() + bar.get_width()/2, height),\n",
        "                xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom',\n",
        "                fontsize=9)\n",
        "\n",
        "# Annotazioni per CNN\n",
        "for i, (bar, acc) in enumerate(zip(bars_cnn, accuratezze_cnn)):\n",
        "    height = bar.get_height()\n",
        "    ax2.annotate(f'{acc:.3f}', xy=(bar.get_x() + bar.get_width()/2, height),\n",
        "                xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom',\n",
        "                fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcT-rnvdM7ye"
      },
      "source": [
        "### Grafico 2: Confronto Completo delle Architetture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vg1b9U7YM7ye"
      },
      "outputs": [],
      "source": [
        "tutti_risultati = risultati_mlp + risultati_cnn\n",
        "nomi_config = [r['nome_config'] for r in tutti_risultati]\n",
        "acc_train_tutte = [r['train_accuracy'] for r in tutti_risultati]\n",
        "acc_test_tutte = [r['test_accuracy'] for r in tutti_risultati]\n",
        "tipi_modello = [r['tipo_modello'] for r in tutti_risultati]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(16, 8))\n",
        "\n",
        "x = np.arange(len(nomi_config))\n",
        "larghezza = 0.35\n",
        "\n",
        "bars_train = ax.bar(x - larghezza/2, acc_train_tutte, larghezza,\n",
        "                   label='Accuratezza Training', alpha=0.8, color='lightcoral')\n",
        "bars_test = ax.bar(x + larghezza/2, acc_test_tutte, larghezza,\n",
        "                  label='Accuratezza Test', alpha=0.8, color='steelblue')\n",
        "\n",
        "for i, tipo in enumerate(tipi_modello):\n",
        "    bars_train[i].set_edgecolor('darkred')\n",
        "    bars_test[i].set_edgecolor('darkblue')\n",
        "    bars_train[i].set_linewidth(1.5)\n",
        "    bars_test[i].set_linewidth(1.5)\n",
        "\n",
        "ax.set_xlabel('Configurazione')\n",
        "ax.set_ylabel('Accuratezza')\n",
        "ax.set_title('Confronto Completo: Accuratezza Training vs Test (24 Configurazioni)')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(nomi_config, rotation=45, ha='right')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "#plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pn5dReiM7ye"
      },
      "source": [
        "### Grafico 3: Effetto Scaling MLP (1 vs 2 Strati Nascosti)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMo_qTh_M7ye"
      },
      "outputs": [],
      "source": [
        "# Analisi scaling MLP e CNN\n",
        "range_neuroni = neuroni_lista\n",
        "acc_1_strato = []\n",
        "acc_2_strati = []\n",
        "tempo_1_strato = []\n",
        "tempo_2_strati = []\n",
        "\n",
        "# Analisi MLP\n",
        "for neuroni in range_neuroni:\n",
        "    risultati_1s = [r for r in risultati_mlp if r['neuroni'] == neuroni and r['n_strati'] == 1]\n",
        "    risultati_2s = [r for r in risultati_mlp if r['neuroni'] == neuroni and r['n_strati'] == 2]\n",
        "\n",
        "    if risultati_1s:\n",
        "        acc_1_strato.append(np.mean([r['test_accuracy'] for r in risultati_1s]))\n",
        "        tempo_1_strato.append(np.mean([r['training_time'] for r in risultati_1s]))\n",
        "\n",
        "    if risultati_2s:\n",
        "        acc_2_strati.append(np.mean([r['test_accuracy'] for r in risultati_2s]))\n",
        "        tempo_2_strati.append(np.mean([r['training_time'] for r in risultati_2s]))\n",
        "\n",
        "# Analisi CNN - confronto architetture\n",
        "risultati_baseline = [r for r in risultati_cnn if r['architettura'] == 'baseline']\n",
        "risultati_extended = [r for r in risultati_cnn if r['architettura'] == 'extended']\n",
        "\n",
        "acc_baseline = np.mean([r['test_accuracy'] for r in risultati_baseline])\n",
        "acc_extended = np.mean([r['test_accuracy'] for r in risultati_extended])\n",
        "tempo_baseline = np.mean([r['training_time'] for r in risultati_baseline])\n",
        "tempo_extended = np.mean([r['training_time'] for r in risultati_extended])\n",
        "\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 6))\n",
        "\n",
        "# Subplot 1: Accuratezza MLP\n",
        "ax1.plot(range_neuroni, acc_1_strato, 'o-', linewidth=2, markersize=8,\n",
        "         label='1 Strato Nascosto', color='blue')\n",
        "ax1.plot(range_neuroni, acc_2_strati, 's-', linewidth=2, markersize=8,\n",
        "         label='2 Strati Nascosti', color='darkblue')\n",
        "\n",
        "ax1.set_xlabel('Neuroni per Strato')\n",
        "ax1.set_ylabel('Accuratezza Test')\n",
        "ax1.set_title('Scaling MLP: Accuratezza vs Profondità')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Subplot 2: Tempo di training MLP\n",
        "ax2.plot(range_neuroni, tempo_1_strato, 'o-', linewidth=2, markersize=8,\n",
        "         label='1 Strato Nascosto', color='green')\n",
        "ax2.plot(range_neuroni, tempo_2_strati, 's-', linewidth=2, markersize=8,\n",
        "         label='2 Strati Nascosti', color='darkgreen')\n",
        "\n",
        "ax2.set_xlabel('Neuroni per Strato')\n",
        "ax2.set_ylabel('Tempo di Training (secondi)')\n",
        "ax2.set_title('Scaling MLP: Tempo vs Profondità')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# Subplot 3: Confronto CNN architetture\n",
        "architetture = ['Baseline', 'Extended']\n",
        "acc_cnn = [acc_baseline, acc_extended]\n",
        "tempo_cnn = [tempo_baseline, tempo_extended]\n",
        "\n",
        "x_pos = np.arange(len(architetture))\n",
        "width = 0.35\n",
        "\n",
        "# Bars per accuratezza\n",
        "ax3_tempo = ax3.twinx()\n",
        "bars_acc = ax3.bar(x_pos - width/2, acc_cnn, width,\n",
        "                   label='Accuratezza', alpha=0.8, color='red')\n",
        "bars_tempo = ax3_tempo.bar(x_pos + width/2, tempo_cnn, width,\n",
        "                          label='Tempo (s)', alpha=0.8, color='orange')\n",
        "\n",
        "ax3.set_xlabel('Architettura CNN')\n",
        "ax3.set_ylabel('Accuratezza Test', color='red')\n",
        "ax3_tempo.set_ylabel('Tempo Training (s)', color='orange')\n",
        "ax3.set_title('Scaling CNN: Baseline vs Extended')\n",
        "ax3.set_xticks(x_pos)\n",
        "ax3.set_xticklabels(architetture)\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# Annotazioni CNN\n",
        "for i, (bar_acc, acc, bar_tempo, tempo) in enumerate(zip(bars_acc, acc_cnn, bars_tempo, tempo_cnn)):\n",
        "    # Accuratezza\n",
        "    height_acc = bar_acc.get_height()\n",
        "    ax3.annotate(f'{acc:.3f}', xy=(bar_acc.get_x() + bar_acc.get_width()/2, height_acc),\n",
        "                xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom',\n",
        "                fontsize=9, color='red')\n",
        "\n",
        "    # Tempo\n",
        "    height_tempo = bar_tempo.get_height()\n",
        "    ax3_tempo.annotate(f'{tempo:.1f}s', xy=(bar_tempo.get_x() + bar_tempo.get_width()/2, height_tempo),\n",
        "                      xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom',\n",
        "                      fontsize=9, color='orange')\n",
        "\n",
        "# Legende combinate\n",
        "lines1, labels1 = ax3.get_legend_handles_labels()\n",
        "lines2, labels2 = ax3_tempo.get_legend_handles_labels()\n",
        "ax3.legend(lines1 + lines2, labels1 + labels2, loc='upper center')\n",
        "\n",
        "plt.tight_layout()\n",
        "#plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuuoxHj5M7yf"
      },
      "source": [
        "### Analisi quantitative aggiuntive e stampe risultati"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "i8N0L-trM7yf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ebd3102-11c8-4501-9873-eb084644dbe7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANALISI EFFICIENZA (ACC/TEMPO):\n",
            "----------------------------------------\n",
            "Efficienza media MLP: 0.0234 acc/s\n",
            "Efficienza media CNN: 0.0028 acc/s\n",
            "Rapporto MLP/CNN: 8.4x\n",
            "\n",
            "Top 5 configurazioni più efficienti:\n",
            "1. 50n_1S_lr0.01: 0.0509 acc/s\n",
            "2. 50n_1S_lr0.1: 0.0430 acc/s\n",
            "3. 100n_1S_lr0.1: 0.0391 acc/s\n",
            "4. 50n_2S_lr0.1: 0.0379 acc/s\n",
            "5. 50n_1S_lr0.001: 0.0324 acc/s\n",
            "\n",
            "ANALISI OVERFITTING VS COMPLESSITÀ:\n",
            "----------------------------------------\n",
            "Range parametri: 40K - 1082K\n",
            "Overfitting medio MLP: 0.0122\n",
            "Overfitting medio CNN: 0.0078\n",
            "Correlazione parametri-overfitting: -0.218\n",
            "\n",
            "ANALISI VELOCITÀ CONVERGENZA:\n",
            "----------------------------------------\n",
            "Iterazioni medie MLP: 22.0\n",
            "Iterazioni medie CNN: 8.0\n",
            "Rapporto convergenza MLP/CNN: 2.8x\n"
          ]
        }
      ],
      "source": [
        "# Calcolo metriche di efficienza\n",
        "efficienze = [r['test_accuracy'] / r['training_time'] for r in tutti_risultati]\n",
        "efficienza_media_mlp = np.mean([efficienze[i] for i, t in enumerate(tipi_modello) if t == 'MLP'])\n",
        "efficienza_media_cnn = np.mean([efficienze[i] for i, t in enumerate(tipi_modello) if t == 'CNN'])\n",
        "\n",
        "print(\"ANALISI EFFICIENZA (ACC/TEMPO):\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"Efficienza media MLP: {efficienza_media_mlp:.4f} acc/s\")\n",
        "print(f\"Efficienza media CNN: {efficienza_media_cnn:.4f} acc/s\")\n",
        "print(f\"Rapporto MLP/CNN: {efficienza_media_mlp/efficienza_media_cnn:.1f}x\")\n",
        "\n",
        "# Top 5 configurazioni più efficienti\n",
        "top_efficienti = sorted(range(len(efficienze)), key=lambda i: efficienze[i], reverse=True)[:5]\n",
        "print(f\"\\nTop 5 configurazioni più efficienti:\")\n",
        "for i, idx in enumerate(top_efficienti):\n",
        "    print(f\"{i+1}. {nomi_config[idx]}: {efficienze[idx]:.4f} acc/s\")\n",
        "\n",
        "# Analisi overfitting vs complessità\n",
        "print(f\"\\nANALISI OVERFITTING VS COMPLESSITÀ:\")\n",
        "print(\"-\" * 40)\n",
        "complessita = [r['parametri_totali'] for r in tutti_risultati]\n",
        "overfitting_vals = [r['overfitting'] for r in tutti_risultati]\n",
        "\n",
        "print(f\"Range parametri: {min(complessita)/1000:.0f}K - {max(complessita)/1000:.0f}K\")\n",
        "print(f\"Overfitting medio MLP: {np.mean([r['overfitting'] for r in risultati_mlp]):.4f}\")\n",
        "print(f\"Overfitting medio CNN: {np.mean([r['overfitting'] for r in risultati_cnn]):.4f}\")\n",
        "\n",
        "# Correlazione complessità-overfitting\n",
        "correlazione = np.corrcoef(complessita, overfitting_vals)[0,1]\n",
        "print(f\"Correlazione parametri-overfitting: {correlazione:.3f}\")\n",
        "\n",
        "# Analisi velocità convergenza\n",
        "print(f\"\\nANALISI VELOCITÀ CONVERGENZA:\")\n",
        "print(\"-\" * 40)\n",
        "iter_mlp = [r['iterations'] for r in risultati_mlp]\n",
        "iter_cnn = [r['iterations'] for r in risultati_cnn]\n",
        "\n",
        "print(f\"Iterazioni medie MLP: {np.mean(iter_mlp):.1f}\")\n",
        "print(f\"Iterazioni medie CNN: {np.mean(iter_cnn):.1f}\")\n",
        "print(f\"Rapporto convergenza MLP/CNN: {np.mean(iter_mlp)/np.mean(iter_cnn):.1f}x\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2Y7eyafM7yf"
      },
      "source": [
        "### Discussione Finale e Conclusioni Punto A\n",
        "\n",
        "#### Le architetture vincenti\n",
        "\n",
        "Dopo aver testato **24 configurazioni diverse** tra MLP e CNN, i risultati mostrano chiaramente quali sono le architetture migliori:\n",
        "\n",
        "**Configurazione MLP ottimale**: 250 neuroni, 1 strato nascosto, learning rate 0.001\n",
        "- Accuratezza: **98.10%**\n",
        "- Ottimo bilanciamento prestazioni-efficienza\n",
        "\n",
        "**Configurazione CNN ottimale**: architettura estesa, learning rate 0.001  \n",
        "- Accuratezza: **98.85%** (la migliore in assoluto)\n",
        "- Costi computazionali molto più alti\n",
        "\n",
        "#### Il learning rate è fondamentale\n",
        "\n",
        "Il learning rate si dimostra l'iperparametro più critico per il successo del modello:\n",
        "\n",
        "- **0.001**: massimizza l'accuratezza (97.60% media per MLP)\n",
        "- **0.01**: miglior compromesso velocità-prestazioni (97.40% media)\n",
        "- **0.1**: causa un crollo catastrofico delle prestazioni (solo 86.10%)\n",
        "\n",
        "La differenza tra un learning rate ben calibrato e uno troppo alto è drammatica: oltre 11 punti percentuali di differenza.\n",
        "\n",
        "#### In questo progetto:\n",
        "\n",
        "Scegliamo i modelli con lr=0,01"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AP2XBuND3cjg"
      },
      "source": [
        "#### Salvataggio migliori modelli MLP e CNN in luce dei risultati\n",
        "\n",
        "Si sceglie di salvare i seguenti modelli:\n",
        "- **50n_1S_lr0.01** per MLP\n",
        "- **CNN_baseline_lr0.01** per CNN\n",
        "\n",
        "Questi modelli sono il giusto compromesso tra precisione e velocità di training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "sjj4hl1N3Wib",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c55ac682-e733-4cd5-f54b-62c61eff2219"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SALVATAGGIO MODELLI OTTIMALI\n",
            "========================================\n",
            "Configurazione MLP scelta: 50n_1S_lr0.01\n",
            "  Accuratezza: 0.9697\n",
            "  Tempo training: 19.0s\n",
            "\n",
            "Configurazione CNN scelta: CNN_baseline_lr0.01\n",
            "  Accuratezza: 0.9747\n",
            "  Tempo training: 185.9s\n",
            "\n",
            "Training modelli ottimali per uso nei punti successivi...\n",
            "\n",
            "Modelli trainati con successo:\n",
            "BEST_MLP accuratezza: 0.9697 (tempo: 21.3s)\n",
            "BEST_CNN accuratezza: 0.9737 (tempo: 188.7s)\n",
            "\n",
            "Modelli pronti per utilizzo nei punti successivi.\n"
          ]
        }
      ],
      "source": [
        "# Identificazione e salvataggio dei modelli ottimali scelti\n",
        "print(\"SALVATAGGIO MODELLI OTTIMALI\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# Trova configurazioni scelte dai risultati\n",
        "config_mlp_scelta = None\n",
        "config_cnn_scelta = None\n",
        "\n",
        "for risultato in risultati_mlp:\n",
        "    if risultato['nome_config'] == '50n_1S_lr0.01':\n",
        "        config_mlp_scelta = risultato\n",
        "        break\n",
        "\n",
        "for risultato in risultati_cnn:\n",
        "    if risultato['nome_config'] == 'CNN_baseline_lr0.01':\n",
        "        config_cnn_scelta = risultato\n",
        "        break\n",
        "\n",
        "\n",
        "BEST_MLP_CONFIG = {\n",
        "    'nome_config': config_mlp_scelta['nome_config'],\n",
        "    'hidden_layer_sizes': config_mlp_scelta['strati_nascosti'],\n",
        "    'learning_rate_init': config_mlp_scelta['learning_rate'],\n",
        "    'test_accuracy': config_mlp_scelta['test_accuracy'],\n",
        "    'training_time': config_mlp_scelta['training_time']\n",
        "}\n",
        "\n",
        "BEST_CNN_CONFIG = {\n",
        "    'nome_config': config_cnn_scelta['nome_config'],\n",
        "    'architettura': config_cnn_scelta['architettura'],\n",
        "    'learning_rate': config_cnn_scelta['learning_rate'],\n",
        "    'test_accuracy': config_cnn_scelta['test_accuracy'],\n",
        "    'training_time': config_cnn_scelta['training_time']\n",
        "}\n",
        "\n",
        "print(f\"Configurazione MLP scelta: {BEST_MLP_CONFIG['nome_config']}\")\n",
        "print(f\"  Accuratezza: {BEST_MLP_CONFIG['test_accuracy']:.4f}\")\n",
        "print(f\"  Tempo training: {BEST_MLP_CONFIG['training_time']:.1f}s\")\n",
        "\n",
        "print(f\"\\nConfigurazione CNN scelta: {BEST_CNN_CONFIG['nome_config']}\")\n",
        "print(f\"  Accuratezza: {BEST_CNN_CONFIG['test_accuracy']:.4f}\")\n",
        "print(f\"  Tempo training: {BEST_CNN_CONFIG['training_time']:.1f}s\")\n",
        "\n",
        "# Training e salvataggio modelli ottimali\n",
        "print(f\"\\nTraining modelli ottimali per uso nei punti successivi...\")\n",
        "\n",
        "# Training MLP ottimale\n",
        "BEST_MLP = crea_mlp_ottimale()\n",
        "start_time = time.time()\n",
        "BEST_MLP.fit(x_tr, mnist_tr_labels)\n",
        "mlp_training_time = time.time() - start_time\n",
        "\n",
        "# Training CNN ottimale\n",
        "BEST_CNN = crea_cnn_ottimale()\n",
        "early_stopping = keras.callbacks.EarlyStopping(\n",
        "    patience=5, min_delta=0.001, restore_best_weights=True, verbose=0\n",
        ")\n",
        "start_time = time.time()\n",
        "BEST_CNN.fit(x_tr_conv, mnist_tr_labels, validation_split=0.1, epochs=20,\n",
        "                batch_size=128, callbacks=[early_stopping], verbose=0)\n",
        "cnn_training_time = time.time() - start_time\n",
        "\n",
        "# Verifica accuratezza\n",
        "mlp_acc = BEST_MLP.score(x_te, mnist_te_labels)\n",
        "cnn_acc = BEST_CNN.evaluate(x_te_conv, mnist_te_labels, verbose=0)[1]\n",
        "\n",
        "print(f\"\\nModelli trainati con successo:\")\n",
        "print(f\"BEST_MLP accuratezza: {mlp_acc:.4f} (tempo: {mlp_training_time:.1f}s)\")\n",
        "print(f\"BEST_CNN accuratezza: {cnn_acc:.4f} (tempo: {cnn_training_time:.1f}s)\")\n",
        "print(f\"\\nModelli pronti per utilizzo nei punti successivi.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dsAqKkwM7yf"
      },
      "source": [
        "---\n",
        "## Punto B: Analisi delle cifre più difficili da riconoscere\n",
        "\n",
        "Utilizziamo l'architettura MLP ottimale identificata nel Punto A per analizzare sistematicamente quali cifre sono più difficili da classificare attraverso la matrice di confusione e l'analisi degli errori."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "6I-qjh_7M7yf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3a1c064-bb87-4662-e217-7044b6c50154"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANALISI ERRORI CON MODELLO MLP OTTIMALE\n",
            "==================================================\n",
            "Configurazione: 50n_1S_lr0.01\n",
            "Accuratezza test: 0.9697\n",
            "Errori totali: 303\n"
          ]
        }
      ],
      "source": [
        "# Uso del modello ottimale già trainato\n",
        "print(\"ANALISI ERRORI CON MODELLO MLP OTTIMALE\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Configurazione: {BEST_MLP_CONFIG['nome_config']}\")\n",
        "print(f\"Accuratezza test: {BEST_MLP.score(x_te, mnist_te_labels):.4f}\")\n",
        "\n",
        "# Calcolo predizioni per analisi errori\n",
        "y_pred = BEST_MLP.predict(x_te)\n",
        "y_pred_proba = BEST_MLP.predict_proba(x_te)\n",
        "total_errors = np.sum(y_pred != mnist_te_labels)\n",
        "\n",
        "print(f\"Errori totali: {total_errors}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2g07VdW2M7yf"
      },
      "source": [
        "### Grafico 1: Matrice di Confusione"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HeMBoRmlM7yf"
      },
      "outputs": [],
      "source": [
        "cm = metrics.confusion_matrix(mnist_te_labels, y_pred)\n",
        "cm_normalized = metrics.confusion_matrix(mnist_te_labels, y_pred, normalize='true')\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7))\n",
        "\n",
        "# Matrice assoluta\n",
        "im1 = ax1.imshow(cm, cmap='Blues')\n",
        "ax1.set_xticks(range(10))\n",
        "ax1.set_yticks(range(10))\n",
        "ax1.set_xlabel('Cifra Predetta', fontsize=12)\n",
        "ax1.set_ylabel('Cifra Vera', fontsize=12)\n",
        "ax1.set_title('Matrice di Confusione - Valori Assoluti', fontsize=14)\n",
        "\n",
        "for i in range(10):\n",
        "    for j in range(10):\n",
        "        color = 'white' if cm[i, j] > cm.max() / 2 else 'black'\n",
        "        ax1.text(j, i, f'{cm[i, j]}', ha='center', va='center',\n",
        "                color=color, fontweight='bold')\n",
        "\n",
        "# Matrice normalizzata\n",
        "im2 = ax2.imshow(cm_normalized, cmap='Reds')\n",
        "ax2.set_xticks(range(10))\n",
        "ax2.set_yticks(range(10))\n",
        "ax2.set_xlabel('Cifra Predetta', fontsize=12)\n",
        "ax2.set_ylabel('Cifra Vera', fontsize=12)\n",
        "ax2.set_title('Matrice di Confusione - Percentuali per Classe', fontsize=14)\n",
        "\n",
        "for i in range(10):\n",
        "    for j in range(10):\n",
        "        color = 'white' if cm_normalized[i, j] > 0.5 else 'black'\n",
        "        ax2.text(j, i, f'{cm_normalized[i, j]:.2f}', ha='center', va='center',\n",
        "                color=color, fontweight='bold')\n",
        "\n",
        "fig.colorbar(im1, ax=ax1, shrink=0.6)\n",
        "fig.colorbar(im2, ax=ax2, shrink=0.6)\n",
        "plt.tight_layout()\n",
        "#plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BVBFQEyM7yf"
      },
      "source": [
        "### Grafico 2: Difficoltà di Riconoscimento per Cifra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYg4EEtaM7yf"
      },
      "outputs": [],
      "source": [
        "# Analisi errori per singola cifra\n",
        "errors_per_digit = []\n",
        "for digit in range(10):\n",
        "    mask = mnist_te_labels == digit\n",
        "    total_samples = np.sum(mask)\n",
        "    correct_predictions = np.sum((y_pred == mnist_te_labels) & mask)\n",
        "    errors = total_samples - correct_predictions\n",
        "    error_rate = errors / total_samples\n",
        "    accuracy = correct_predictions / total_samples\n",
        "\n",
        "    digit_predictions = y_pred_proba[mask]\n",
        "    correct_mask = (y_pred == mnist_te_labels)[mask]\n",
        "\n",
        "    avg_confidence_correct = np.mean(np.max(digit_predictions[correct_mask], axis=1)) if np.any(correct_mask) else 0\n",
        "    avg_confidence_errors = np.mean(np.max(digit_predictions[~correct_mask], axis=1)) if np.any(~correct_mask) else 0\n",
        "\n",
        "    errors_per_digit.append({\n",
        "        'digit': digit,\n",
        "        'total_samples': total_samples,\n",
        "        'correct': correct_predictions,\n",
        "        'errors': errors,\n",
        "        'error_rate': error_rate,\n",
        "        'accuracy': accuracy,\n",
        "        'avg_confidence_correct': avg_confidence_correct,\n",
        "        'avg_confidence_errors': avg_confidence_errors\n",
        "    })\n",
        "\n",
        "df_errors = pd.DataFrame(errors_per_digit)\n",
        "df_errors_sorted = df_errors.sort_values('error_rate', ascending=False)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "colors = plt.cm.RdYlBu_r(df_errors_sorted['error_rate'] / df_errors_sorted['error_rate'].max())\n",
        "bars = ax.bar(range(10), df_errors_sorted['error_rate'] * 100, color=colors, alpha=0.8)\n",
        "\n",
        "ax.set_xlabel('Cifra (ordinata per difficoltà)', fontsize=12)\n",
        "ax.set_ylabel('Tasso di Errore (%)', fontsize=12)\n",
        "ax.set_title('Difficoltà di Riconoscimento per Cifra', fontsize=14)\n",
        "ax.set_xticks(range(10))\n",
        "ax.set_xticklabels(df_errors_sorted['digit'])\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Annotazioni dettagliate\n",
        "for i, (bar, row) in enumerate(zip(bars, df_errors_sorted.itertuples())):\n",
        "    height = bar.get_height()\n",
        "    ax.annotate(f'{height:.1f}%\\n({row.errors}/{row.total_samples})',\n",
        "                xy=(bar.get_x() + bar.get_width()/2, height),\n",
        "                xytext=(0, 5), textcoords=\"offset points\",\n",
        "                ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "#plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlHebDPDM7yf"
      },
      "source": [
        "### Analisi quantitative aggiuntive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "GgsdV0H-M7yf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af00766f-42c5-4fa0-aa08-5edc9ab761ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANALISI TOP CONFUSIONI:\n",
            "------------------------------\n",
            "Top 3 confusioni più frequenti:\n",
            "9.0 → 4.0: 19.0 errori (1.9%)\n",
            "9.0 → 7.0: 13.0 errori (1.3%)\n",
            "8.0 → 3.0: 10.0 errori (1.0%)\n",
            "\n",
            "ANALISI CONFIDENZA MODELLO:\n",
            "------------------------------\n",
            "Cifra | Conf_Corrette | Conf_Errate | Gap\n",
            "----------------------------------------\n",
            "  8   |     0.977     |    0.786    | +0.192\n",
            "  9   |     0.979     |    0.761    | +0.218\n",
            "  5   |     0.985     |    0.765    | +0.220\n",
            "  2   |     0.985     |    0.766    | +0.219\n",
            "  3   |     0.985     |    0.740    | +0.246\n",
            "  6   |     0.993     |    0.774    | +0.219\n",
            "  7   |     0.992     |    0.743    | +0.249\n",
            "  4   |     0.990     |    0.803    | +0.187\n",
            "  1   |     0.995     |    0.719    | +0.277\n",
            "  0   |     0.998     |    0.788    | +0.210\n",
            "\n",
            "Correlazione confidenza-accuratezza: 0.972\n"
          ]
        }
      ],
      "source": [
        "# Analisi Top confusioni\n",
        "print(\"ANALISI TOP CONFUSIONI:\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "confusion_pairs = []\n",
        "for i in range(10):\n",
        "    for j in range(10):\n",
        "        if i != j and cm[i, j] > 0:\n",
        "            confusion_pairs.append({\n",
        "                'true_digit': i,\n",
        "                'predicted_digit': j,\n",
        "                'count': cm[i, j],\n",
        "                'percentage_of_true': cm[i, j] / np.sum(cm[i, :]) * 100\n",
        "            })\n",
        "\n",
        "df_confusions = pd.DataFrame(confusion_pairs)\n",
        "top_3_confusions = df_confusions.nlargest(3, 'count')\n",
        "\n",
        "print(\"Top 3 confusioni più frequenti:\")\n",
        "for idx, row in top_3_confusions.iterrows():\n",
        "    print(f\"{row['true_digit']} → {row['predicted_digit']}: {row['count']} errori ({row['percentage_of_true']:.1f}%)\")\n",
        "\n",
        "# Analisi confidenza modello\n",
        "print(f\"\\nANALISI CONFIDENZA MODELLO:\")\n",
        "print(\"-\" * 30)\n",
        "print(\"Cifra | Conf_Corrette | Conf_Errate | Gap\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "for _, row in df_errors_sorted.iterrows():\n",
        "    gap_confidenza = row['avg_confidence_correct'] - row['avg_confidence_errors']\n",
        "    print(f\"  {int(row['digit'])}   |     {row['avg_confidence_correct']:.3f}     |    {row['avg_confidence_errors']:.3f}    | {gap_confidenza:+.3f}\")\n",
        "\n",
        "# Correlazione confidenza-accuratezza\n",
        "confidenze_corrette = df_errors_sorted['avg_confidence_correct'].values\n",
        "accuratezze = df_errors_sorted['accuracy'].values\n",
        "correlazione_conf = np.corrcoef(confidenze_corrette, accuratezze)[0,1]\n",
        "print(f\"\\nCorrelazione confidenza-accuratezza: {correlazione_conf:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOh6TJkTM7yg"
      },
      "source": [
        "---\n",
        "## Punto C: Curve psicometriche - Effetto del rumore\n",
        "\n",
        "Analizziamo sistematicamente come l'accuratezza di riconoscimento degrada all'aumentare del rumore Gaussiano aggiunto alle immagini di test, utilizzando l'architettura MLP ottimale per valutare la robustezza intrinseca del modello."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "p28ZFIfZM7yg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a957c1a8-626d-4b4f-f172-8fe4be74b351"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configurazione esperimento robustezza:\n",
            "- Subset stratificato: 2000 campioni\n",
            "- Range rumore: 0.00 - 0.45 (step 0.05)\n",
            "- Livelli testati: 10\n",
            "\n",
            "Testing robustezza MLP ottimale...\n",
            "RISULTATI ROBUSTEZZA AL RUMORE:\n",
            "----------------------------------------\n",
            "Noise σ  | MLP Accuratezza\n",
            "-------------------------\n",
            "  0.00 |     0.9705\n",
            "  0.05 |     0.9675\n",
            "  0.10 |     0.9550\n",
            "  0.15 |     0.9145\n",
            "  0.20 |     0.8210\n",
            "  0.25 |     0.7315\n",
            "  0.30 |     0.6590\n",
            "  0.35 |     0.5930\n",
            "  0.40 |     0.5400\n",
            "  0.45 |     0.4830\n"
          ]
        }
      ],
      "source": [
        "# Configurazione esperimento robustezza\n",
        "noise_levels = np.arange(0.00, 0.50, 0.05)\n",
        "subset_size = 2000\n",
        "\n",
        "# Campionamento stratificato\n",
        "indices_stratificati = []\n",
        "for digit in range(10):\n",
        "    digit_indices = np.where(mnist_te_labels == digit)[0]\n",
        "    n_samples = subset_size // 10\n",
        "    selected = np.random.choice(digit_indices, n_samples, replace=False)\n",
        "    indices_stratificati.extend(selected)\n",
        "\n",
        "x_te_subset = x_te[np.array(indices_stratificati)]\n",
        "y_te_subset = mnist_te_labels[np.array(indices_stratificati)]\n",
        "\n",
        "print(f\"Configurazione esperimento robustezza:\")\n",
        "print(f\"- Subset stratificato: {len(indices_stratificati)} campioni\")\n",
        "print(f\"- Range rumore: {noise_levels[0]:.2f} - {noise_levels[-1]:.2f} (step {noise_levels[1]-noise_levels[0]:.2f})\")\n",
        "print(f\"- Livelli testati: {len(noise_levels)}\")\n",
        "\n",
        "# Test robustezza MLP ottimale\n",
        "print(f\"\\nTesting robustezza MLP ottimale...\")\n",
        "accuracies_mlp = []\n",
        "\n",
        "for noise_std in noise_levels:\n",
        "    x_noisy = add_gaussian_noise(x_te_subset, noise_std)\n",
        "    acc = BEST_MLP.score(x_noisy, y_te_subset)\n",
        "    accuracies_mlp.append(acc)\n",
        "\n",
        "print(\"RISULTATI ROBUSTEZZA AL RUMORE:\")\n",
        "print(\"-\" * 40)\n",
        "print(\"Noise σ  | MLP Accuratezza\")\n",
        "print(\"-\" * 25)\n",
        "for noise, acc in zip(noise_levels, accuracies_mlp):\n",
        "    print(f\"{noise:6.2f} |     {acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seMYRQ6jM7yg"
      },
      "source": [
        "### Grafico 1: Curve Psicometriche MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BbCx9dLwM7yg"
      },
      "outputs": [],
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Subplot 1: Accuratezza assoluta\n",
        "ax1.plot(noise_levels, accuracies_mlp, 'o-', linewidth=3, markersize=8,\n",
        "         color='blue', label='MLP Ottimale', alpha=0.8)\n",
        "\n",
        "ax1.set_xlabel('Deviazione Standard del Rumore (σ)', fontsize=12)\n",
        "ax1.set_ylabel('Accuratezza', fontsize=12)\n",
        "ax1.set_title('Curva Psicometrica: Robustezza al Rumore\\nMLP Ottimale', fontsize=14)\n",
        "ax1.legend(fontsize=12)\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.set_ylim(0, 1.05)\n",
        "\n",
        "# Soglia 90%\n",
        "for i, (noise, acc) in enumerate(zip(noise_levels, accuracies_mlp)):\n",
        "    if acc < 0.9 and i > 0 and accuracies_mlp[i-1] >= 0.9:\n",
        "        ax1.axvline(x=noise, color='red', linestyle='--', alpha=0.7)\n",
        "        ax1.text(noise, 0.92, f'90% threshold\\nσ={noise:.2f}',\n",
        "                ha='center', va='bottom', fontsize=10, color='red',\n",
        "                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightcoral\", alpha=0.7))\n",
        "        break\n",
        "\n",
        "# Subplot 2: Degradazione relativa\n",
        "degradazione_mlp = [(accuracies_mlp[0] - acc) / accuracies_mlp[0] * 100 for acc in accuracies_mlp]\n",
        "\n",
        "ax2.plot(noise_levels, degradazione_mlp, 'o-', linewidth=3, markersize=8,\n",
        "         color='red', label='Degradazione MLP', alpha=0.8)\n",
        "\n",
        "ax2.set_xlabel('Deviazione Standard del Rumore (σ)', fontsize=12)\n",
        "ax2.set_ylabel('Degradazione Relativa (%)', fontsize=12)\n",
        "ax2.set_title('Degradazione Prestazioni\\n(% rispetto a condizioni pulite)', fontsize=14)\n",
        "ax2.legend(fontsize=12)\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "#plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7aimizkM7yg"
      },
      "source": [
        "### Grafico 2: Robustezza per Singola Classe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99r_p9JKM7yg"
      },
      "outputs": [],
      "source": [
        "# Calcolo robustezza per classe\n",
        "robustezza_per_classe = {}\n",
        "\n",
        "for digit in range(10):\n",
        "    mask = y_te_subset == digit\n",
        "    x_digit = x_te_subset[mask]\n",
        "    y_digit = y_te_subset[mask]\n",
        "\n",
        "    if len(x_digit) == 0:\n",
        "        continue\n",
        "\n",
        "    accuracies_digit = []\n",
        "    for noise_std in noise_levels:\n",
        "        x_noisy = add_gaussian_noise(x_digit, noise_std)\n",
        "        y_pred_classes = BEST_MLP.predict(x_noisy)\n",
        "        acc = np.mean(y_pred_classes == y_digit)\n",
        "        accuracies_digit.append(acc)\n",
        "\n",
        "    robustezza_per_classe[digit] = accuracies_digit\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "colors = plt.cm.tab10(np.linspace(0, 1, 10))\n",
        "for digit in range(10):\n",
        "    if digit in robustezza_per_classe:\n",
        "        ax.plot(noise_levels, robustezza_per_classe[digit],\n",
        "                'o-', color=colors[digit], label=f'Cifra {digit}',\n",
        "                linewidth=2, markersize=5, alpha=0.8)\n",
        "\n",
        "ax.set_xlabel('Deviazione Standard del Rumore (σ)', fontsize=12)\n",
        "ax.set_ylabel('Accuratezza per Classe', fontsize=12)\n",
        "ax.set_title('Robustezza al Rumore per Singola Classe - MLP Ottimale', fontsize=14)\n",
        "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.set_ylim(0, 1.05)\n",
        "\n",
        "plt.tight_layout()\n",
        "#plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKA-UNObM7yh"
      },
      "source": [
        "---\n",
        "## Punto D: Effetto della riduzione dei dati di training\n",
        "\n",
        "Analizziamo come le prestazioni del modello MLP ottimale degradano quando riduciamo drasticamente la quantità di dati di training disponibili, mantenendo il bilanciamento tra le classi attraverso campionamento stratificato."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "7SLenYnjM7yh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "deb5ec0c-b2e4-4099-87c5-f798b2fb344c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ESPERIMENTO RIDUZIONE DATI DI TRAINING\n",
            "==================================================\n",
            "Architettura: 50n_1S_lr0.01\n",
            "\n",
            "Training con 1% dei dati...\n",
            "Samples:   596 | Train: 0.995 | Test: 0.873 | Time:  0.3s\n",
            "\n",
            "Training con 5% dei dati...\n",
            "Samples:  2996 | Train: 0.994 | Test: 0.917 | Time:  1.1s\n",
            "\n",
            "Training con 10% dei dati...\n",
            "Samples:  5996 | Train: 0.995 | Test: 0.939 | Time:  6.4s\n",
            "\n",
            "Training con 25% dei dati...\n",
            "Samples: 14995 | Train: 0.992 | Test: 0.954 | Time:  4.0s\n",
            "\n",
            "Training con 50% dei dati...\n",
            "Samples: 29997 | Train: 0.992 | Test: 0.962 | Time: 13.2s\n",
            "\n",
            "Training con 75% dei dati...\n",
            "Samples: 44995 | Train: 0.989 | Test: 0.970 | Time: 21.8s\n",
            "\n",
            "Training con 100% dei dati...\n",
            "Samples: 60000 | Train: 0.988 | Test: 0.972 | Time: 21.8s\n"
          ]
        }
      ],
      "source": [
        "# Configurazione esperimento riduzione dati\n",
        "train_percentages = [1, 5, 10, 25, 50, 75, 100]\n",
        "results_data_reduction = []\n",
        "\n",
        "print(\"ESPERIMENTO RIDUZIONE DATI DI TRAINING\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Architettura: {BEST_MLP_CONFIG['nome_config']}\")\n",
        "\n",
        "for percentage in train_percentages:\n",
        "    print(f\"\\nTraining con {percentage}% dei dati...\")\n",
        "\n",
        "    # Campionamento stratificato per classe\n",
        "    indices = []\n",
        "    for digit in range(10):\n",
        "        digit_indices = np.where(mnist_tr_labels == digit)[0]\n",
        "        n_digit_samples = int(len(digit_indices) * percentage / 100)\n",
        "        if n_digit_samples > 0:\n",
        "            selected_indices = np.random.choice(digit_indices, n_digit_samples, replace=False)\n",
        "            indices.extend(selected_indices)\n",
        "\n",
        "    indices = np.array(indices)\n",
        "    x_tr_reduced = x_tr[indices]\n",
        "    y_tr_reduced = mnist_tr_labels[indices]\n",
        "\n",
        "    # Training MLP ottimale con dati ridotti\n",
        "    mlp_reduced = crea_mlp_ottimale()\n",
        "\n",
        "    start_time = time.time()\n",
        "    mlp_reduced.fit(x_tr_reduced, y_tr_reduced)\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    train_acc = mlp_reduced.score(x_tr_reduced, y_tr_reduced)\n",
        "    test_acc = mlp_reduced.score(x_te, mnist_te_labels)\n",
        "\n",
        "    results_data_reduction.append({\n",
        "        'percentage': percentage,\n",
        "        'n_samples': len(indices),\n",
        "        'train_accuracy': train_acc,\n",
        "        'test_accuracy': test_acc,\n",
        "        'overfitting': train_acc - test_acc,\n",
        "        'training_time': training_time,\n",
        "        'efficiency': test_acc / training_time\n",
        "    })\n",
        "\n",
        "    print(f\"Samples: {len(indices):5d} | Train: {train_acc:.3f} | Test: {test_acc:.3f} | Time: {training_time:4.1f}s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJ2nNTgjM7yh"
      },
      "source": [
        "### Grafico 1: Accuratezza vs Percentuale Dati"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz9QEzr1M7yh"
      },
      "outputs": [],
      "source": [
        "df_reduction = pd.DataFrame(results_data_reduction)\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Subplot 1: Accuratezza vs percentuale dati\n",
        "ax1.plot(df_reduction['percentage'], df_reduction['test_accuracy'], 'o-',\n",
        "        linewidth=3, markersize=10, color='darkblue', label='Test')\n",
        "ax1.plot(df_reduction['percentage'], df_reduction['train_accuracy'], 's-',\n",
        "        linewidth=3, markersize=10, color='lightblue', label='Train')\n",
        "\n",
        "ax1.set_xlabel('Percentuale di dati di training utilizzati (%)')\n",
        "ax1.set_ylabel('Accuratezza')\n",
        "ax1.set_title('Effetto della riduzione dei dati di training')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Evidenziazione punto 10%\n",
        "idx_10 = df_reduction[df_reduction['percentage'] == 10].index[0]\n",
        "ax1.scatter(10, df_reduction.loc[idx_10, 'test_accuracy'],\n",
        "          s=200, color='red', zorder=5)\n",
        "ax1.annotate(f\"10%: {df_reduction.loc[idx_10, 'test_accuracy']:.3f}\",\n",
        "           xy=(10, df_reduction.loc[idx_10, 'test_accuracy']),\n",
        "           xytext=(20, df_reduction.loc[idx_10, 'test_accuracy'] - 0.05),\n",
        "           arrowprops=dict(arrowstyle='->', color='red'),\n",
        "           fontsize=11)\n",
        "\n",
        "# Subplot 2: Overfitting vs dimensione dataset\n",
        "ax2.plot(df_reduction['percentage'], df_reduction['overfitting'], 'o-',\n",
        "        linewidth=3, markersize=10, color='purple')\n",
        "ax2.set_xlabel('Percentuale di dati (%)')\n",
        "ax2.set_ylabel('Overfitting (Train - Test)')\n",
        "ax2.set_title('Overfitting vs Dimensione dataset')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "ax2.axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.tight_layout()\n",
        "#plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uareFz7NM7yh"
      },
      "source": [
        "---\n",
        "## Punto E: Training con rumore per migliorare la robustezza\n",
        "\n",
        "Verifichiamo se l'aggiunta di rumore Gaussiano durante il training può migliorare le prestazioni su dati di test rumorosi, utilizzando l'architettura MLP ottimale e un range esteso di livelli di rumore per data augmentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "9ZJ-x1n4M7yh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05f22613-a058-4cd8-c085-7e91e5e04195"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ESPERIMENTO TRAINING CON RUMORE\n",
            "========================================\n",
            "Architettura: 50n_1S_lr0.01\n",
            "Range noise training: 0.0 - 0.3 (step 0.05)\n",
            "\n",
            "Training con rumore σ = 0\n",
            "Accuratezza test pulito: 0.9697 | Tempo: 18.7s\n",
            "\n",
            "Training con rumore σ = 0.075\n",
            "Accuratezza test pulito: 0.9697 | Tempo: 32.8s\n",
            "\n",
            "Training con rumore σ = 0.15\n",
            "Accuratezza test pulito: 0.9637 | Tempo: 21.0s\n",
            "\n",
            "Training con rumore σ = 0.3\n",
            "Accuratezza test pulito: 0.9424 | Tempo: 16.9s\n",
            "\n",
            "Training con rumore σ = 0.45\n",
            "Accuratezza test pulito: 0.9227 | Tempo: 32.6s\n",
            "\n",
            "Training con rumore σ = 0.6\n",
            "Accuratezza test pulito: 0.9097 | Tempo: 26.0s\n",
            "\n",
            "Test robustezza su range noise 0.0-0.35...\n",
            "Training noise σ=0: AUC = 0.345\n",
            "Training noise σ=0.075: AUC = 0.356\n",
            "Training noise σ=0.15: AUC = 0.400\n",
            "Training noise σ=0.3: AUC = 0.415\n",
            "Training noise σ=0.45: AUC = 0.412\n",
            "Training noise σ=0.6: AUC = 0.404\n"
          ]
        }
      ],
      "source": [
        "# Configurazione esperimento training con rumore\n",
        "training_noise_levels = [0, 0.075, 0.15, 0.3, 0.45, 0.60]\n",
        "models_with_noise = {}\n",
        "\n",
        "print(\"ESPERIMENTO TRAINING CON RUMORE\")\n",
        "print(\"=\" * 40)\n",
        "print(f\"Architettura: {BEST_MLP_CONFIG['nome_config']}\")\n",
        "print(f\"Range noise training: 0.0 - 0.3 (step 0.05)\")\n",
        "\n",
        "for train_noise in training_noise_levels:\n",
        "    print(f\"\\nTraining con rumore σ = {train_noise}\")\n",
        "\n",
        "    # Aggiunta rumore ai dati di training\n",
        "    if train_noise > 0:\n",
        "        x_tr_noisy = add_gaussian_noise(x_tr, train_noise)\n",
        "    else:\n",
        "        x_tr_noisy = x_tr\n",
        "\n",
        "    # Training MLP ottimale\n",
        "    mlp_noise = crea_mlp_ottimale()\n",
        "\n",
        "    start_time = time.time()\n",
        "    mlp_noise.fit(x_tr_noisy, mnist_tr_labels)\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    models_with_noise[train_noise] = mlp_noise\n",
        "\n",
        "    # Test su dati puliti\n",
        "    clean_acc = mlp_noise.score(x_te, mnist_te_labels)\n",
        "    print(f\"Accuratezza test pulito: {clean_acc:.4f} | Tempo: {training_time:.1f}s\")\n",
        "\n",
        "# Test dei modelli su diversi livelli di rumore nel test set\n",
        "test_noise_levels = np.arange(0, 0.5, 0.05)\n",
        "results_noise_training = {}\n",
        "\n",
        "print(f\"\\nTest robustezza su range noise 0.0-0.35...\")\n",
        "for train_noise, model in models_with_noise.items():\n",
        "    accuracies = []\n",
        "    for test_noise in test_noise_levels:\n",
        "        x_te_noisy = add_gaussian_noise(x_te_subset, test_noise)\n",
        "        acc = model.score(x_te_noisy, y_te_subset)\n",
        "        accuracies.append(acc)\n",
        "\n",
        "    results_noise_training[train_noise] = accuracies\n",
        "    auc = np.trapz(accuracies, test_noise_levels)\n",
        "    print(f\"Training noise σ={train_noise}: AUC = {auc:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdHooHGIM7yi"
      },
      "source": [
        "### Grafico 1: Curve Psicometriche per Diversi Training Noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S89md7C-M7yi"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "colors = plt.cm.viridis(np.linspace(0, 1, len(training_noise_levels)))\n",
        "\n",
        "for i, (train_noise, accuracies) in enumerate(results_noise_training.items()):\n",
        "    ax.plot(test_noise_levels, accuracies, 'o-',\n",
        "           label=f'Training σ = {train_noise}',\n",
        "           color=colors[i], linewidth=2, markersize=6)\n",
        "\n",
        "ax.set_xlabel('Deviazione standard del rumore (test)', fontsize=12)\n",
        "ax.set_ylabel('Accuratezza', fontsize=12)\n",
        "ax.set_title('Effetto del rumore nel training sulla robustezza', fontsize=14)\n",
        "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.set_ylim(0, 1.05)\n",
        "\n",
        "plt.tight_layout()\n",
        "#plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JLpJ9_XM7yi"
      },
      "source": [
        "## Punto Bonus: Estensione con FashionMNIST e confronto architetturale\n",
        "\n",
        "Applichiamo sia l'architettura MLP ottimale che la CNN ottimale al dataset FashionMNIST per valutare la generalizzazione su un task di classificazione più complesso."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "mdFGtZlxM7yi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91b6a799-d8ef-46d6-dff7-40874492c563"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CARICAMENTO FASHIONMNIST\n",
            "==============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:01<00:00, 13.4MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 199kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.74MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 8.54MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FashionMNIST caricato: 60000 train, 10000 test\n",
            "\n",
            "Training MLP ottimale su FashionMNIST...\n",
            "Training MLP completato in 35.2s\n",
            "MLP Train accuracy: 0.9055\n",
            "MLP Test accuracy: 0.8673\n",
            "\n",
            "Training CNN ottimale su FashionMNIST...\n",
            "Training CNN completato in 247.8s\n",
            "CNN Train accuracy: 0.8955\n",
            "CNN Test accuracy: 0.8748\n",
            "\n",
            "CONFRONTO PRESTAZIONI CROSS-DATASET:\n",
            "==================================================\n",
            "MNIST:\n",
            "  MLP Ottimale: 0.9697\n",
            "  CNN Ottimale: 0.9747\n",
            "  Gap CNN-MLP: +0.0050\n",
            "\n",
            "FashionMNIST:\n",
            "  MLP Ottimale: 0.8673\n",
            "  CNN Ottimale: 0.8748\n",
            "  Gap CNN-MLP: +0.0075\n"
          ]
        }
      ],
      "source": [
        "# Caricamento e preprocessing FashionMNIST\n",
        "print(\"CARICAMENTO FASHIONMNIST\")\n",
        "print(\"=\" * 30)\n",
        "fashion_tr = FashionMNIST(root=\"./data\", train=True, download=True)\n",
        "fashion_te = FashionMNIST(root=\"./data\", train=False, download=True)\n",
        "\n",
        "fashion_tr_data, fashion_tr_labels = fashion_tr.data.numpy(), fashion_tr.targets.numpy()\n",
        "fashion_te_data, fashion_te_labels = fashion_te.data.numpy(), fashion_te.targets.numpy()\n",
        "\n",
        "x_fashion_tr = fashion_tr_data.reshape(60000, 28 * 28) / 255.0\n",
        "x_fashion_te = fashion_te_data.reshape(10000, 28 * 28) / 255.0\n",
        "\n",
        "# Preprocessing per CNN\n",
        "x_fashion_tr_conv = fashion_tr_data.reshape(-1, 28, 28, 1) / 255.0\n",
        "x_fashion_te_conv = fashion_te_data.reshape(-1, 28, 28, 1) / 255.0\n",
        "\n",
        "fashion_classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "                  'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "print(f\"FashionMNIST caricato: {x_fashion_tr.shape[0]} train, {x_fashion_te.shape[0]} test\")\n",
        "\n",
        "# Training MLP ottimale su FashionMNIST\n",
        "print(f\"\\nTraining MLP ottimale su FashionMNIST...\")\n",
        "mlp_fashion = crea_mlp_ottimale()\n",
        "\n",
        "start_time = time.time()\n",
        "mlp_fashion.fit(x_fashion_tr, fashion_tr_labels)\n",
        "fashion_training_time_mlp = time.time() - start_time\n",
        "\n",
        "fashion_train_acc_mlp = mlp_fashion.score(x_fashion_tr, fashion_tr_labels)\n",
        "fashion_test_acc_mlp = mlp_fashion.score(x_fashion_te, fashion_te_labels)\n",
        "\n",
        "print(f\"Training MLP completato in {fashion_training_time_mlp:.1f}s\")\n",
        "print(f\"MLP Train accuracy: {fashion_train_acc_mlp:.4f}\")\n",
        "print(f\"MLP Test accuracy: {fashion_test_acc_mlp:.4f}\")\n",
        "\n",
        "# Training CNN ottimale su FashionMNIST\n",
        "print(f\"\\nTraining CNN ottimale su FashionMNIST...\")\n",
        "cnn_fashion = crea_cnn_ottimale()\n",
        "early_stopping = keras.callbacks.EarlyStopping(\n",
        "    patience=5, min_delta=0.001, restore_best_weights=True, verbose=0\n",
        ")\n",
        "\n",
        "start_time = time.time()\n",
        "history_fashion = cnn_fashion.fit(x_fashion_tr_conv, fashion_tr_labels,\n",
        "                                 validation_split=0.1, epochs=20, batch_size=128,\n",
        "                                 callbacks=[early_stopping], verbose=0)\n",
        "fashion_training_time_cnn = time.time() - start_time\n",
        "\n",
        "fashion_train_loss_cnn, fashion_train_acc_cnn = cnn_fashion.evaluate(x_fashion_tr_conv, fashion_tr_labels, verbose=0)\n",
        "fashion_test_loss_cnn, fashion_test_acc_cnn = cnn_fashion.evaluate(x_fashion_te_conv, fashion_te_labels, verbose=0)\n",
        "\n",
        "print(f\"Training CNN completato in {fashion_training_time_cnn:.1f}s\")\n",
        "print(f\"CNN Train accuracy: {fashion_train_acc_cnn:.4f}\")\n",
        "print(f\"CNN Test accuracy: {fashion_test_acc_cnn:.4f}\")\n",
        "\n",
        "# Confronto con MNIST\n",
        "mnist_test_acc_mlp = BEST_MLP_CONFIG['test_accuracy']\n",
        "mnist_test_acc_cnn = BEST_CNN_CONFIG['test_accuracy']\n",
        "\n",
        "print(f\"\\nCONFRONTO PRESTAZIONI CROSS-DATASET:\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"MNIST:\")\n",
        "print(f\"  MLP Ottimale: {mnist_test_acc_mlp:.4f}\")\n",
        "print(f\"  CNN Ottimale: {mnist_test_acc_cnn:.4f}\")\n",
        "print(f\"  Gap CNN-MLP: {mnist_test_acc_cnn - mnist_test_acc_mlp:+.4f}\")\n",
        "\n",
        "print(f\"\\nFashionMNIST:\")\n",
        "print(f\"  MLP Ottimale: {fashion_test_acc_mlp:.4f}\")\n",
        "print(f\"  CNN Ottimale: {fashion_test_acc_cnn:.4f}\")\n",
        "print(f\"  Gap CNN-MLP: {fashion_test_acc_cnn - fashion_test_acc_mlp:+.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4VQjyK6M7yj"
      },
      "source": [
        "## **Conclusioni Generali del Progetto**\n",
        "\n",
        "### **Sintesi dei risultati principali**\n",
        "\n",
        "**Punto A - Configurazioni ottimali:**\n",
        "- **Architetture vincenti**: MLP(50 neuroni, 1 strato, lr=0.01) e CNN baseline con lr=0.01\n",
        "- **Learning rate cruciale**: range 0.001-0.01 ottimale, crollo catastrofico a 0.1\n",
        "- **Meno profondità = meglio**: 1 strato supera 2 strati (meno overfitting)\n",
        "- **MLP dominano efficienza**: molto più efficienti delle CNN per rapporto accuratezza/tempo\n",
        "\n",
        "**Punto B - Errori e difficoltà:**\n",
        "- **Gerarchia cifre difficili**: pattern logici di confusione basati su similitudini visive\n",
        "- **Sistema auto-calibrato**: correlazione confidenza-accuratezza per controllo qualità\n",
        "- **Errori concentrati**: errori ben distribuiti su casi di ambiguità genuina\n",
        "\n",
        "**Punto C - Resistenza al rumore:**\n",
        "- **Soglie operative chiare**: degradazione controllata senza collassi improvvisi\n",
        "- **Vulnerabilità specifiche**: diverse cifre mostrano robustezza variabile\n",
        "\n",
        "**Punto D - Efficienza con pochi dati:**\n",
        "- **Robustezza eccezionale**: prestazioni sorprendenti anche con dataset ridotti\n",
        "- **Scaling lineare**: tempi proporzionali alla dimensione del dataset\n",
        "\n",
        "**Punto E - Training con rumore:**\n",
        "- **Data augmentation efficace**: miglioramenti significativi nella robustezza\n",
        "- **Range sicuro**: regolarizzazione benefica senza degradare prestazioni base\n",
        "\n",
        "**Punto Bonus - CNN vs MLP:**\n",
        "- **Vantaggio CNN cresce**: più evidenti su task complessi come FashionMNIST\n",
        "- **Trade-off chiari**: efficienza vs prestazioni"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "qagR-cawM7ye"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}