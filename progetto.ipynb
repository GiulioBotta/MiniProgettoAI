{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d77f4b15",
   "metadata": {},
   "source": [
    "# Mini Progetto Intelligenza Artificiale - Riconoscimento cifre manoscritte\n",
    "\n",
    "**Nome:** Giulio    \n",
    "**Cognome:** Bottacin    \n",
    "**Matricola:** 2042340    \n",
    "**Data consegna:** 5/6/2025  \n",
    "\n",
    "## Obiettivo\n",
    "\n",
    "In questo progetto esploreremo il riconoscimento di cifre manoscritte utilizzando il dataset MNIST, implementando simulazioni per studiare come diversi fattori influenzano le prestazioni dei modelli di deep learning. Analizzeremo in particolare l'impatto degli iperparametri, la robustezza al rumore e l'effetto della quantità di dati di training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44abb844",
   "metadata": {},
   "source": [
    "## Importazione delle librerie necessarie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe329e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from torchvision.datasets import MNIST, FashionMNIST\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurazione per riproducibilità\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dae275",
   "metadata": {},
   "source": [
    "## Caricamento e preparazione del dataset MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175256c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricamento dataset MNIST...\n"
     ]
    }
   ],
   "source": [
    "# Caricamento dataset MNIST\n",
    "print(\"Caricamento dataset MNIST...\")\n",
    "mnist_tr = MNIST(root=\"./data\", train=True, download=True)\n",
    "mnist_te = MNIST(root=\"./data\", train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0cae14",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Conversione in array numpy\n",
    "mnist_tr_data, mnist_tr_labels = mnist_tr.data.numpy(), mnist_tr.targets.numpy()\n",
    "mnist_te_data, mnist_te_labels = mnist_te.data.numpy(), mnist_te.targets.numpy()\n",
    "\n",
    "# Preprocessing per MLP (vettorizzazione e normalizzazione)\n",
    "x_tr = mnist_tr_data.reshape(60000, 28 * 28) / 255.0\n",
    "x_te = mnist_te_data.reshape(10000, 28 * 28) / 255.0\n",
    "\n",
    "# Preprocessing per CNN (mantenendo formato 2D)\n",
    "x_tr_conv = x_tr.reshape(-1, 28, 28, 1)\n",
    "x_te_conv = x_te.reshape(-1, 28, 28, 1)\n",
    "\n",
    "print(f\"Dataset caricato: {x_tr.shape[0]} esempi di training, {x_te.shape[0]} esempi di test\")\n",
    "print(f\"Forma dati MLP: {x_tr.shape}\")\n",
    "print(f\"Forma dati CNN: {x_tr_conv.shape}\")\n",
    "\n",
    "# Visualizzazione esempi del dataset\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 6))\n",
    "fig.suptitle('Dataset MNIST - Esempi per Cifra', fontsize=14)\n",
    "\n",
    "for digit in range(10):\n",
    "    idx = np.where(mnist_tr_labels == digit)[0][0]\n",
    "    ax = axes[digit//5, digit%5]\n",
    "    ax.imshow(mnist_tr_data[idx], cmap='gray')\n",
    "    ax.set_title(f'Cifra {digit}')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5242b1b3",
   "metadata": {},
   "source": [
    "## Punto A: Effetto degli iperparametri sulle prestazioni\n",
    "\n",
    "Analizziamo sistematicamente come variano le prestazioni dei modelli MLP e CNN al variare degli iperparametri chiave.  \n",
    "Confronteremo 18 configurazioni MLP e 6 configurazioni CNN per un totale di 24 esperimenti mirati."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7af60f",
   "metadata": {},
   "source": [
    "### Configurazione esperimenti sistematici\n",
    "\n",
    "***MLP (18 esperimenti):***\n",
    "- **Neuroni per strato**: *50, 100, 250* per testare la copertura da reti piccole a medio-grandi\n",
    "- **Numero layers**: *1 vs 2* strati nascosti per fare il confronto profondità vs larghezza\n",
    "- **Learning rate**: *0.001, 0.01, 0.1*\n",
    "\n",
    "***CNN (6 esperimenti):***\n",
    "- **Filtri**: *32*, standard per MNIST, computazionalmente efficiente\n",
    "- **Architettura**: *baseline vs extended* per fare il confronto sulla complessità\n",
    "- **Learning rate**: *0.001, 0.01, 0.1*\n",
    "\n",
    "Per entrambi i modelli si è scelto di utilizzare il solver **Adam**, ormai standard e più performante di SDG.  \n",
    "Si è volutamente scelto di eseguire meno esperimenti sulle CNN in quanto richiedono tempi molto più lunghi di training rispetto alle MLP.\n",
    "\n",
    "#### Scelta dei parametri di training\n",
    "\n",
    "***MLP:***\n",
    "- *max_iter = 100* è sufficiente per convergenza su MNIST basato su cifre manoscritte. \n",
    "- *early_stopping = True*, previene l'overfitting essenziale quando sono presenti molti parametri.\n",
    "- *validation_fraction = 0.1*, split standard 90/10.\n",
    "- *tol = 0.001* è una precisione ragionevole per classificazione.\n",
    "- *n_iter_no_change = 10* è un livello di pazienza adeguata per permettere oscillazioni temporanee.\n",
    "\n",
    "***CNN:*** \n",
    "- *epochs = 20* valore di compromesso per bilanciare velocità e convergenza, il valore è più basso delle MLP perchè le CNN tipicamente convergono più velocemente.\n",
    "- *batch_size = 128*, trade-off memoria/velocità ottimale per dataset size.\n",
    "- *validation_split = 0.1*, coerente con le scelte di MLP.\n",
    "- *patience = 5*, le CNN sono meno soggette a oscillazioni quindi è stato scelto un livello di pazienza minore.\n",
    "- *min_delta = 0.001*, scelta la stessa precisione degli MLP per comparabilità diretta.\n",
    "\n",
    "Questa configurazione permette un confronto sistematico e bilanciato tra i due tipi di architetture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dc0d98",
   "metadata": {},
   "source": [
    "#### Funzioni helper per stampe risultati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924122e4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def stampa_header_esperimento(num_esp, totale, tipo_modello, config):\n",
    "    print(f\"\\n[{num_esp:2d}/{totale}] {tipo_modello}: {config}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "def stampa_risultati_esperimento(risultati):\n",
    "    print(f\"Accuracy Training: {risultati['train_accuracy']:.4f} | Accuracy Test: {risultati['test_accuracy']:.4f}\")\n",
    "    print(f\"Tempo: {risultati['training_time']:6.1f}s | Iterazioni: {risultati['iterations']:3d}\")\n",
    "    print(f\"Overfitting: {risultati['overfitting']:+.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37445b1",
   "metadata": {},
   "source": [
    "#### Esperimenti MLP (16 configurazioni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84403193",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INIZIO ESPERIMENTI MLP\n",
      "============================================================\n",
      "\n",
      "[ 1/18] MLP: 50n_1S_lr0.001\n",
      "--------------------------------------------------\n",
      "Acc Training: 0.9891 | Acc Test: 0.9707\n",
      "Tempo:    9.0s | Iterazioni:  24\n",
      "Overfitting: +0.0184\n",
      "\n",
      "[ 2/18] MLP: 50n_1S_lr0.01\n",
      "--------------------------------------------------\n",
      "Acc Training: 0.9844 | Acc Test: 0.9697\n",
      "Tempo:    5.2s | Iterazioni:  17\n",
      "Overfitting: +0.0147\n",
      "\n",
      "[ 3/18] MLP: 50n_1S_lr0.1\n",
      "--------------------------------------------------\n",
      "Acc Training: 0.9202 | Acc Test: 0.9123\n",
      "Tempo:    5.8s | Iterazioni:  20\n",
      "Overfitting: +0.0079\n",
      "\n",
      "[ 4/18] MLP: 50n_2S_lr0.001\n",
      "--------------------------------------------------\n",
      "Acc Training: 0.9905 | Acc Test: 0.9729\n",
      "Tempo:    9.4s | Iterazioni:  27\n",
      "Overfitting: +0.0176\n",
      "\n",
      "[ 5/18] MLP: 50n_2S_lr0.01\n",
      "--------------------------------------------------\n",
      "Acc Training: 0.9863 | Acc Test: 0.9695\n",
      "Tempo:    6.3s | Iterazioni:  19\n",
      "Overfitting: +0.0168\n",
      "\n",
      "[ 6/18] MLP: 50n_2S_lr0.1\n",
      "--------------------------------------------------\n",
      "Acc Training: 0.8471 | Acc Test: 0.8467\n",
      "Tempo:    5.5s | Iterazioni:  16\n",
      "Overfitting: +0.0004\n",
      "\n",
      "[ 7/18] MLP: 100n_1S_lr0.001\n",
      "--------------------------------------------------\n",
      "Acc Training: 0.9971 | Acc Test: 0.9771\n",
      "Tempo:   13.3s | Iterazioni:  26\n",
      "Overfitting: +0.0201\n",
      "\n",
      "[ 8/18] MLP: 100n_1S_lr0.01\n",
      "--------------------------------------------------\n",
      "Acc Training: 0.9909 | Acc Test: 0.9734\n",
      "Tempo:   10.0s | Iterazioni:  19\n",
      "Overfitting: +0.0175\n",
      "\n",
      "[ 9/18] MLP: 100n_1S_lr0.1\n",
      "--------------------------------------------------\n",
      "Acc Training: 0.9168 | Acc Test: 0.9148\n",
      "Tempo:    5.8s | Iterazioni:  13\n",
      "Overfitting: +0.0020\n",
      "\n",
      "[10/18] MLP: 100n_2S_lr0.001\n",
      "--------------------------------------------------\n",
      "Acc Training: 0.9967 | Acc Test: 0.9786\n",
      "Tempo:   11.3s | Iterazioni:  20\n",
      "Overfitting: +0.0181\n",
      "\n",
      "[11/18] MLP: 100n_2S_lr0.01\n",
      "--------------------------------------------------\n",
      "Acc Training: 0.9934 | Acc Test: 0.9739\n",
      "Tempo:   24.0s | Iterazioni:  43\n",
      "Overfitting: +0.0195\n",
      "\n",
      "[12/18] MLP: 100n_2S_lr0.1\n",
      "--------------------------------------------------\n",
      "Acc Training: 0.8248 | Acc Test: 0.8212\n",
      "Tempo:    7.8s | Iterazioni:  14\n",
      "Overfitting: +0.0036\n",
      "\n",
      "[13/18] MLP: 250n_1S_lr0.001\n",
      "--------------------------------------------------\n",
      "Acc Training: 0.9981 | Acc Test: 0.9810\n",
      "Tempo:   26.3s | Iterazioni:  24\n",
      "Overfitting: +0.0171\n",
      "\n",
      "[14/18] MLP: 250n_1S_lr0.01\n",
      "--------------------------------------------------\n",
      "Acc Training: 0.9913 | Acc Test: 0.9752\n",
      "Tempo:   25.1s | Iterazioni:  25\n",
      "Overfitting: +0.0161\n",
      "\n",
      "[15/18] MLP: 250n_1S_lr0.1\n",
      "--------------------------------------------------\n",
      "Acc Training: 0.9160 | Acc Test: 0.9147\n",
      "Tempo:   15.4s | Iterazioni:  15\n",
      "Overfitting: +0.0013\n",
      "\n",
      "[16/18] MLP: 250n_2S_lr0.001\n",
      "--------------------------------------------------\n",
      "Acc Training: 0.9965 | Acc Test: 0.9788\n",
      "Tempo:   30.2s | Iterazioni:  19\n",
      "Overfitting: +0.0177\n",
      "\n",
      "[17/18] MLP: 250n_2S_lr0.01\n",
      "--------------------------------------------------\n",
      "Acc Training: 0.9924 | Acc Test: 0.9776\n",
      "Tempo:   49.0s | Iterazioni:  31\n",
      "Overfitting: +0.0148\n",
      "\n",
      "[18/18] MLP: 250n_2S_lr0.1\n",
      "--------------------------------------------------\n",
      "Acc Training: 0.7662 | Acc Test: 0.7577\n",
      "Tempo:   41.1s | Iterazioni:  27\n",
      "Overfitting: +0.0085\n",
      "\n",
      "ESPERIMENTI MLP COMPLETATI: 18 configurazioni testate\n"
     ]
    }
   ],
   "source": [
    "neuroni_lista = [50, 100, 250] # numero di neuroni per strato\n",
    "strati_lista = [1, 2]  # numero di strati nascosti\n",
    "learning_rates = [0.001, 0.01, 0.1] # learning rates \n",
    "\n",
    "risultati_mlp = []\n",
    "contatore_esperimenti = 0\n",
    "esperimenti_totali = len(neuroni_lista) * len(strati_lista) * len(learning_rates)\n",
    "\n",
    "print(\"INIZIO ESPERIMENTI MLP\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for neuroni in neuroni_lista:\n",
    "    for n_strati in strati_lista:\n",
    "        for lr in learning_rates:\n",
    "            contatore_esperimenti += 1\n",
    "            \n",
    "            # Configurazione architettura\n",
    "            if n_strati == 1:\n",
    "                strati_nascosti = (neuroni,)\n",
    "                nome_config = f\"{neuroni}n_1S_lr{lr}\"\n",
    "            else:\n",
    "                strati_nascosti = (neuroni, neuroni)\n",
    "                nome_config = f\"{neuroni}n_2S_lr{lr}\"\n",
    "            \n",
    "            stampa_header_esperimento(contatore_esperimenti, esperimenti_totali, \"MLP\", nome_config)\n",
    "            \n",
    "            # Training MLP\n",
    "            mlp = MLPClassifier(\n",
    "                hidden_layer_sizes=strati_nascosti,\n",
    "                learning_rate_init=lr,\n",
    "                max_iter=100,\n",
    "                early_stopping=True,\n",
    "                validation_fraction=0.1,\n",
    "                tol=0.001,\n",
    "                n_iter_no_change=10,\n",
    "                random_state=42\n",
    "            )\n",
    "            \n",
    "            tempo_inizio = time.time()\n",
    "            mlp.fit(x_tr, mnist_tr_labels)\n",
    "            tempo_training = time.time() - tempo_inizio\n",
    "            \n",
    "            acc_train = mlp.score(x_tr, mnist_tr_labels)\n",
    "            acc_test = mlp.score(x_te, mnist_te_labels)\n",
    "            \n",
    "            risultati = {\n",
    "                'tipo_modello': 'MLP',\n",
    "                'nome_config': nome_config,\n",
    "                'neuroni': neuroni,\n",
    "                'n_strati': n_strati,\n",
    "                'learning_rate': lr,\n",
    "                'strati_nascosti': strati_nascosti,\n",
    "                'train_accuracy': acc_train,\n",
    "                'test_accuracy': acc_test,\n",
    "                'overfitting': acc_train - acc_test,\n",
    "                'training_time': tempo_training,\n",
    "                'iterations': mlp.n_iter_,\n",
    "                'loss_curve': mlp.loss_curve_ if hasattr(mlp, 'loss_curve_') else [],\n",
    "                'parametri_totali': sum([layer.size for layer in mlp.coefs_]) + sum([layer.size for layer in mlp.intercepts_])\n",
    "            }\n",
    "            \n",
    "            risultati_mlp.append(risultati)\n",
    "            stampa_risultati_esperimento(risultati)\n",
    "\n",
    "print(f\"\\nESPERIMENTI MLP COMPLETATI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebb1437",
   "metadata": {},
   "source": [
    "#### Funzioni helper per esperimenti CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7f9a89",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def crea_modello_cnn(tipo_architettura, learning_rate):\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    if tipo_architettura == 'baseline':\n",
    "        # Architettura baseline\n",
    "        model.add(keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)))\n",
    "        model.add(keras.layers.Flatten())\n",
    "        model.add(keras.layers.Dense(50, activation='relu'))\n",
    "        \n",
    "    elif tipo_architettura == 'extended':\n",
    "        # Architettura estesa con pooling e più strati\n",
    "        model.add(keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)))\n",
    "        model.add(keras.layers.MaxPooling2D(2,2))\n",
    "        model.add(keras.layers.Conv2D(64, (3,3), activation='relu'))\n",
    "        model.add(keras.layers.Flatten())\n",
    "        model.add(keras.layers.Dense(100, activation='relu'))\n",
    "    \n",
    "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "    \n",
    "    # Configurazione optimizer\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e02fe32",
   "metadata": {},
   "source": [
    "#### Esperimenti CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b325f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "INIZIO ESPERIMENTI CNN\n",
      "============================================================\n",
      "\n",
      "[ 1/6] CNN: CNN_baseline_lr0.001\n",
      "--------------------------------------------------\n",
      "Acc Training: 0.9914 | Acc Test: 0.9805\n",
      "Tempo:   68.4s | Iterazioni:   8\n",
      "Overfitting: +0.0109\n",
      "\n",
      "[ 2/6] CNN: CNN_baseline_lr0.01\n",
      "--------------------------------------------------\n",
      "Acc Training: 0.9890 | Acc Test: 0.9765\n",
      "Tempo:   61.4s | Iterazioni:   7\n",
      "Overfitting: +0.0125\n",
      "\n",
      "[ 3/6] CNN: CNN_baseline_lr0.1\n",
      "--------------------------------------------------\n",
      "Acc Training: 0.1022 | Acc Test: 0.1010\n",
      "Tempo:   55.1s | Iterazioni:   6\n",
      "Overfitting: +0.0012\n",
      "\n",
      "[ 4/6] CNN: CNN_extended_lr0.001\n",
      "--------------------------------------------------\n",
      "Acc Training: 0.9920 | Acc Test: 0.9893\n",
      "Tempo:  107.7s | Iterazioni:   7\n",
      "Overfitting: +0.0027\n",
      "\n",
      "[ 5/6] CNN: CNN_extended_lr0.01\n",
      "--------------------------------------------------\n",
      "Acc Training: 0.9876 | Acc Test: 0.9804\n",
      "Tempo:  108.9s | Iterazioni:   7\n",
      "Overfitting: +0.0072\n",
      "\n",
      "[ 6/6] CNN: CNN_extended_lr0.1\n",
      "--------------------------------------------------\n",
      "Acc Training: 0.1022 | Acc Test: 0.1010\n",
      "Tempo:   98.8s | Iterazioni:   6\n",
      "Overfitting: +0.0012\n",
      "\n",
      "ESPERIMENTI CNN COMPLETATI: 6 configurazioni testate\n"
     ]
    }
   ],
   "source": [
    "architetture = ['baseline', 'extended']\n",
    "learning_rates_cnn = [0.001, 0.01, 0.1]\n",
    "\n",
    "risultati_cnn = []\n",
    "contatore_esperimenti_cnn = 0\n",
    "esperimenti_totali_cnn = len(architetture) * len(learning_rates_cnn)\n",
    "\n",
    "print(\"\\n\\nINIZIO ESPERIMENTI CNN\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for arch in architetture:\n",
    "    for lr in learning_rates_cnn:\n",
    "        contatore_esperimenti_cnn += 1\n",
    "        nome_config = f\"CNN_{arch}_lr{lr}\"\n",
    "        \n",
    "        stampa_header_esperimento(contatore_esperimenti_cnn, esperimenti_totali_cnn, \"CNN\", nome_config)\n",
    "        \n",
    "        # Creazione e training CNN\n",
    "        model = crea_modello_cnn(arch, lr)\n",
    "        \n",
    "        # Early stopping callback\n",
    "        early_stopping = keras.callbacks.EarlyStopping(\n",
    "            patience=5,\n",
    "            min_delta=0.001,\n",
    "            restore_best_weights=True,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        tempo_inizio = time.time()\n",
    "        history = model.fit(\n",
    "            x_tr_conv, mnist_tr_labels,\n",
    "            validation_split=0.1,\n",
    "            epochs=20,\n",
    "            batch_size=128,\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=0\n",
    "        )\n",
    "        tempo_training = time.time() - tempo_inizio\n",
    "        \n",
    "        # Valutazione\n",
    "        train_loss, acc_train = model.evaluate(x_tr_conv, mnist_tr_labels, verbose=0)\n",
    "        test_loss, acc_test = model.evaluate(x_te_conv, mnist_te_labels, verbose=0)\n",
    "        \n",
    "        risultati = {\n",
    "            'tipo_modello': 'CNN',\n",
    "            'nome_config': nome_config,\n",
    "            'architettura': arch,\n",
    "            'learning_rate': lr,\n",
    "            'train_accuracy': acc_train,\n",
    "            'test_accuracy': acc_test,\n",
    "            'overfitting': acc_train - acc_test,\n",
    "            'training_time': tempo_training,\n",
    "            'iterations': len(history.history['loss']),\n",
    "            'loss_curve': history.history['loss'],\n",
    "            'val_loss_curve': history.history['val_loss'],\n",
    "            'parametri_totali': model.count_params()\n",
    "        }\n",
    "        \n",
    "        risultati_cnn.append(risultati)\n",
    "        stampa_risultati_esperimento(risultati)\n",
    "\n",
    "print(f\"\\nESPERIMENTI CNN COMPLETATI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b8c7c7",
   "metadata": {},
   "source": [
    "#### Combinazione di tutti i risultati per le analisi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82de5349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinazione risultati per analisi\n",
    "tutti_risultati = risultati_mlp + risultati_cnn\n",
    "df_risultati = pd.DataFrame(tutti_risultati)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad25ef4c",
   "metadata": {},
   "source": [
    "### Grafico 1: Effetto del Learning Rate sulle prestazioni MLP\n",
    "\n",
    "Questo grafico analizza l'impatto critico del learning rate sulla convergenza e stabilità del training per le reti MLP. Il learning rate controlla la dimensione dei passi durante l'ottimizzazione: valori troppo alti causano instabilità e divergenza, mentre valori troppo bassi rallentano eccessivamente la convergenza. L'analisi delle curve di loss e delle accuratezze finali permette di identificare il range ottimale per il dataset MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b30d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparazione dati per analisi learning rate\n",
    "dati_lr_001 = [r for r in risultati_mlp if r['learning_rate'] == 0.001]\n",
    "dati_lr_01 = [r for r in risultati_mlp if r['learning_rate'] == 0.01]\n",
    "dati_lr_1 = [r for r in risultati_mlp if r['learning_rate'] == 0.1]\n",
    "\n",
    "# Calcolo medie per ogni learning rate\n",
    "acc_lr_001 = np.mean([r['test_accuracy'] for r in dati_lr_001])\n",
    "acc_lr_01 = np.mean([r['test_accuracy'] for r in dati_lr_01])\n",
    "acc_lr_1 = np.mean([r['test_accuracy'] for r in dati_lr_1])\n",
    "\n",
    "tempo_lr_001 = np.mean([r['training_time'] for r in dati_lr_001])\n",
    "tempo_lr_01 = np.mean([r['training_time'] for r in dati_lr_01])\n",
    "tempo_lr_1 = np.mean([r['training_time'] for r in dati_lr_1])\n",
    "\n",
    "# Visualizzazione curve di loss rappresentative\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Subplot 1: Curve di loss\n",
    "for i, (dati_lr, colore, etichetta) in enumerate([(dati_lr_001, 'green', 'LR=0.001'), \n",
    "                                           (dati_lr_01, 'blue', 'LR=0.01'), \n",
    "                                           (dati_lr_1, 'red', 'LR=0.1')]):\n",
    "    if dati_lr and dati_lr[0]['loss_curve']:\n",
    "        curva_loss = dati_lr[0]['loss_curve']  # Primo esempio rappresentativo\n",
    "        ax1.plot(range(len(curva_loss)), curva_loss, color=colore, linewidth=2, label=etichetta)\n",
    "\n",
    "ax1.set_xlabel('Iterazioni')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Pattern di Convergenza per Learning Rate')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Subplot 2: Accuratezza vs Learning Rate\n",
    "learning_rates_plot = [0.001, 0.01, 0.1]\n",
    "accuratezze = [acc_lr_001, acc_lr_01, acc_lr_1]\n",
    "colori = ['green', 'blue', 'red']\n",
    "\n",
    "bars = ax2.bar(range(len(learning_rates_plot)), accuratezze, color=colori, alpha=0.7)\n",
    "ax2.set_xlabel('Learning Rate')\n",
    "ax2.set_ylabel('Accuratezza Test Media')\n",
    "ax2.set_title('Accuratezza Test per Learning Rate')\n",
    "ax2.set_xticks(range(len(learning_rates_plot)))\n",
    "ax2.set_xticklabels(['0.001', '0.01', '0.1'])\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Annotazioni valori\n",
    "for bar, acc in zip(bars, accuratezze):\n",
    "    height = bar.get_height()\n",
    "    ax2.annotate(f'{acc:.3f}', xy=(bar.get_x() + bar.get_width()/2, height),\n",
    "                xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"DATI ANALISI LEARNING RATE:\")\n",
    "print(f\"LR=0.001: Accuratezza={acc_lr_001:.4f}, Tempo={tempo_lr_001:.1f}s\")\n",
    "print(f\"LR=0.01:  Accuratezza={acc_lr_01:.4f}, Tempo={tempo_lr_01:.1f}s\") \n",
    "print(f\"LR=0.1:   Accuratezza={acc_lr_1:.4f}, Tempo={tempo_lr_1:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6743384a",
   "metadata": {},
   "source": [
    "#### Discussione del grafico e riflessione sui risultati\n",
    "I risultati mostrano chiaramente l'effetto critico del learning rate sulle prestazioni: \n",
    "- **LR = 0.001** raggiunge la migliore accuratezza media (97.65%) con convergenza stabile ma lenta\n",
    "- **LR = 0.01** mantiene prestazioni competitive (97.32%) con convergenza più rapida rappresentando il miglior compromesso velocità-accuratezza\n",
    "- **LR = 0.1** causa un drammatico crollo delle prestazioni (86.12%) indicando instabilità nell'ottimizzazione e possibili oscillazioni eccessive. \n",
    "\n",
    "Dal punto di vista tecnico, learning rate alti causano passi troppo grandi che fanno \"saltare\" oltre i minimi locali, mentre valori troppo bassi intrappolano l'ottimizzazione in plateau prolungati. \n",
    "\n",
    "Per applicazioni pratiche, si raccomanda l'uso di LR=0.01 come punto di partenza per MLP su MNIST, con possibile fine-tuning verso 0.001 se il tempo di training non è critico e si desidera massimizzare l'accuratezza finale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d5f62c",
   "metadata": {},
   "source": [
    "### Grafico 2: Confronto Completo delle Architetture (Training vs Test)\n",
    "Questo grafico presenta un confronto esaustivo di tutte le 24 configurazioni testate, mostrando affiancate le accuratezze di training e test per identificare immediatamente pattern di overfitting.  \n",
    "La visualizzazione simultanea di train e test accuracy permette di valutare sia le prestazioni massime raggiungibili che la capacità di generalizzazione di ogni configurazione, elemento fondamentale per la selezione del modello ottimale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0515c449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selezione migliori configurazioni per evidenziazione\n",
    "migliore_mlp = max(risultati_mlp, key=lambda x: x['test_accuracy'])\n",
    "migliore_cnn = max(risultati_cnn, key=lambda x: x['test_accuracy'])\n",
    "\n",
    "# Preparazione dati per tutte le configurazioni\n",
    "nomi_config = [r['nome_config'] for r in tutti_risultati]\n",
    "acc_train_tutte = [r['train_accuracy'] for r in tutti_risultati]\n",
    "acc_test_tutte = [r['test_accuracy'] for r in tutti_risultati]\n",
    "tipi_modello = [r['tipo_modello'] for r in tutti_risultati]\n",
    "\n",
    "# Separazione indici MLP e CNN\n",
    "indici_mlp = [i for i, t in enumerate(tipi_modello) if t == 'MLP']\n",
    "indici_cnn = [i for i, t in enumerate(tipi_modello) if t == 'CNN']\n",
    "\n",
    "# Visualizzazione\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "# Posizioni delle barre\n",
    "x = np.arange(len(nomi_config))\n",
    "larghezza = 0.35\n",
    "\n",
    "# Barre per accuratezza training e test\n",
    "bars_train = ax.bar(x - larghezza/2, acc_train_tutte, larghezza, \n",
    "                   label='Accuratezza Training', alpha=0.8, color='lightcoral')\n",
    "bars_test = ax.bar(x + larghezza/2, acc_test_tutte, larghezza, \n",
    "                  label='Accuratezza Test', alpha=0.8, color='steelblue')\n",
    "\n",
    "# Colorazione diversa per MLP e CNN sui bordi\n",
    "for i in indici_mlp:\n",
    "    bars_train[i].set_edgecolor('darkred')\n",
    "    bars_test[i].set_edgecolor('darkblue')\n",
    "    bars_train[i].set_linewidth(1.5)\n",
    "    bars_test[i].set_linewidth(1.5)\n",
    "\n",
    "for i in indici_cnn:\n",
    "    bars_train[i].set_edgecolor('orange')\n",
    "    bars_test[i].set_edgecolor('green')\n",
    "    bars_train[i].set_linewidth(2)\n",
    "    bars_test[i].set_linewidth(2)\n",
    "\n",
    "ax.set_xlabel('Configurazione')\n",
    "ax.set_ylabel('Accuratezza')\n",
    "ax.set_title('Confronto Completo: Accuratezza Training vs Test per Tutte le Configurazioni')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(nomi_config, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Evidenziazione delle migliori configurazioni\n",
    "idx_migliore_mlp = tutti_risultati.index(migliore_mlp)\n",
    "idx_migliore_cnn = tutti_risultati.index(migliore_cnn)\n",
    "\n",
    "ax.annotate(f'Miglior MLP\\n{migliore_mlp[\"test_accuracy\"]:.4f}', \n",
    "           xy=(idx_migliore_mlp + larghezza/2, migliore_mlp['test_accuracy']),\n",
    "           xytext=(10, 20), textcoords='offset points',\n",
    "           bbox=dict(boxstyle='round,pad=0.3', facecolor='lightblue', alpha=0.7),\n",
    "           arrowprops=dict(arrowstyle='->', color='blue'))\n",
    "\n",
    "ax.annotate(f'Miglior CNN\\n{migliore_cnn[\"test_accuracy\"]:.4f}', \n",
    "           xy=(idx_migliore_cnn + larghezza/2, migliore_cnn['test_accuracy']),\n",
    "           xytext=(10, -30), textcoords='offset points',\n",
    "           bbox=dict(boxstyle='round,pad=0.3', facecolor='lightgreen', alpha=0.7),\n",
    "           arrowprops=dict(arrowstyle='->', color='green'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"CONFRONTO ARCHITETTURE:\")\n",
    "print(f\"Miglior MLP: {migliore_mlp['nome_config']} - Accuratezza Test: {migliore_mlp['test_accuracy']:.4f}\")\n",
    "print(f\"Miglior CNN: {migliore_cnn['nome_config']} - Accuratezza Test: {migliore_cnn['test_accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a1d72d",
   "metadata": {},
   "source": [
    "#### Discussione del grafico e riflessione sui risultati\n",
    "Il confronto completo rivela pattern distintivi tra MLP e CNN: le CNN mostrano consistentemente maggiore capacità di generalizzazione con gap train-test più contenuti (mediamente 0.0034-0.0114) rispetto agli MLP (0.0004-0.0201), indicando architetture intrinsecamente più robuste all'overfitting grazie ai meccanismi di condivisione dei pesi e alle operazioni di convoluzione che catturano invarianze spaziali.\n",
    "\n",
    "La migliore configurazione **CNN** (*extended_lr0.001*: 98.82%) supera il miglior **MLP** (*250n_1S_lr0.001*: 98.10%) di 0.72 punti percentuali, dimostrando la superiorità delle architetture convoluzionali per dati visivi anche su dataset relativamente semplici come MNIST.\n",
    "\n",
    "Particolarmente critico è l'effetto del learning rate 0.1 che causa collasso completo nelle CNN (accuratezza ~10%) suggerendo maggiore sensibilità all'instabilità di training, mentre gli MLP mostrano degrado graduale. \n",
    "\n",
    "Per applicazioni pratiche, si raccomanda l'uso di CNN con learning rate conservativi (≤0.01) quando le risorse computazionali lo permettono, riservando gli MLP a scenari con vincoli di velocità estremi dove la differenza di accuratezza è accettabile."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84ac810",
   "metadata": {},
   "source": [
    "### Grafico 3: Analisi dell'Efficienza (Accuratezza per Secondo di Training)\n",
    "\n",
    "Questo grafico quantifica l'efficienza di ogni configurazione calcolando il rapporto accuratezza/tempo, metrica fondamentale per applicazioni con vincoli temporali. L'efficienza rivela quale architettura offre il miglior ritorno in termini di prestazioni per unità di tempo investito, considerazione cruciale per deployment in produzione o sperimentazione rapida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227e43af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcolo efficienza per ogni configurazione\n",
    "efficienze = [r['test_accuracy'] / r['training_time'] for r in tutti_risultati]\n",
    "nomi_config_ordinati = []\n",
    "efficienze_ordinate = []\n",
    "tipi_ordinati = []\n",
    "\n",
    "# Ordinamento per efficienza decrescente\n",
    "indici_ordinati = sorted(range(len(efficienze)), key=lambda i: efficienze[i], reverse=True)\n",
    "\n",
    "for i in indici_ordinati:\n",
    "    nomi_config_ordinati.append(nomi_config[i])\n",
    "    efficienze_ordinate.append(efficienze[i])\n",
    "    tipi_ordinati.append(tipi_modello[i])\n",
    "\n",
    "# Visualizzazione\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "# Colori diversi per MLP e CNN\n",
    "colori = ['lightblue' if tipo == 'MLP' else 'salmon' for tipo in tipi_ordinati]\n",
    "bordi = ['darkblue' if tipo == 'MLP' else 'darkred' for tipo in tipi_ordinati]\n",
    "\n",
    "bars = ax.bar(range(len(nomi_config_ordinati)), efficienze_ordinate, \n",
    "              color=colori, edgecolor=bordi, linewidth=1.5, alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Configurazione (ordinate per efficienza decrescente)')\n",
    "ax.set_ylabel('Efficienza (Accuratezza / Tempo di Training)')\n",
    "ax.set_title('Analisi Efficienza: Accuratezza per Secondo di Training')\n",
    "ax.set_xticks(range(len(nomi_config_ordinati)))\n",
    "ax.set_xticklabels(nomi_config_ordinati, rotation=45, ha='right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Annotazioni per le configurazioni più efficienti\n",
    "for i in range(min(5, len(bars))):  # Evidenzia top 5\n",
    "    height = bars[i].get_height()\n",
    "    ax.annotate(f'{height:.4f}', xy=(i, height),\n",
    "               xytext=(0, 3), textcoords=\"offset points\", \n",
    "               ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Legenda manuale\n",
    "ax.bar([], [], color='lightblue', alpha=0.8, label='MLP')\n",
    "ax.bar([], [], color='salmon', alpha=0.8, label='CNN')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calcolo statistiche di efficienza\n",
    "eff_mlp = [efficienze[i] for i in range(len(tipi_modello)) if tipi_modello[i] == 'MLP']\n",
    "eff_cnn = [efficienze[i] for i in range(len(tipi_modello)) if tipi_modello[i] == 'CNN']\n",
    "\n",
    "print(\"ANALISI EFFICIENZA:\")\n",
    "print(f\"Configurazione più efficiente: {nomi_config_ordinati[0]} - {efficienze_ordinate[0]:.4f} acc/s\")\n",
    "print(f\"Efficienza media MLP: {np.mean(eff_mlp):.4f} acc/s\")\n",
    "print(f\"Efficienza media CNN: {np.mean(eff_cnn):.4f} acc/s\")\n",
    "print(f\"Rapporto efficienza MLP/CNN: {np.mean(eff_mlp)/np.mean(eff_cnn):.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f7f9ec",
   "metadata": {},
   "source": [
    "#### Discussione del grafico e riflessione sui risultati\n",
    "L'analisi dell'efficienza rivela una dominanza netta degli **MLP** con le configurazioni più piccole che raggiungono i vertici della classifica (tipicamente >0.2 accuratezza/secondo), principalmente dovuta ai tempi di training drammaticamente inferiori (4.5-37.9s vs 48.3-112.6s delle CNN) che compensano ampiamente il leggero gap di accuratezza.  \n",
    "\n",
    "Le **CNN**, nonostante prestazioni superiori, mostrano efficienza significativamente ridotta (media 0.018 vs 0.084 acc/s degli MLP) rappresentando un rapporto di 4.7x a favore degli MLP, confermando il trade-off fondamentale velocità-accuratezza nel machine learning. \n",
    "Le configurazioni MLP con learning rate moderati (0.01-0.001) e architetture snelle (50-100 neuroni, 1 strato) emergono come ideali per prototipazione rapida e deployment con vincoli temporali stretti. \n",
    "\n",
    "Dal punto di vista pratico, la scelta dovrebbe basarsi sui requisiti specifici: \n",
    "- MLP per iterazione veloce di sviluppo, validazione di proof-of-concept e sistemi real-time\n",
    "- CNN quando l'accuratezza marginale giustifica l'investimento computazionale aggiuntivo, tipicamente in sistemi di produzione critici dove ogni frazione di punto percentuale ha valore economico."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae94ac8d",
   "metadata": {},
   "source": [
    "### Grafico 4: Overfitting per Complessità del Modello\n",
    "\n",
    "Questo grafico analizza la relazione tra complessità del modello (numero totale di parametri) e il fenomeno dell'overfitting (differenza tra accuratezza di training e test). La visualizzazione ordinata per complessità crescente permette di identificare soglie critiche oltre le quali i modelli iniziano a memorizzare anziché generalizzare, informazione cruciale per la progettazione di architetture bilanciate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5eddf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparazione dati ordinati per complessità\n",
    "complessita = [r['parametri_totali'] for r in tutti_risultati]\n",
    "overfitting_valori = [r['overfitting'] for r in tutti_risultati]\n",
    "\n",
    "# Ordinamento per complessità crescente\n",
    "indici_complessita = sorted(range(len(complessita)), key=lambda i: complessita[i])\n",
    "\n",
    "nomi_ordinati_complessita = [nomi_config[i] for i in indici_complessita]\n",
    "complessita_ordinata = [complessita[i] for i in indici_complessita]\n",
    "overfitting_ordinato = [overfitting_valori[i] for i in indici_complessita]\n",
    "tipi_ordinati_complessita = [tipi_modello[i] for i in indici_complessita]\n",
    "\n",
    "# Visualizzazione\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "# Colori basati sul livello di overfitting\n",
    "colori_overfitting = []\n",
    "for ovf in overfitting_ordinato:\n",
    "    if ovf < 0.01:\n",
    "        colori_overfitting.append('lightgreen')  # Basso overfitting\n",
    "    elif ovf < 0.02:\n",
    "        colori_overfitting.append('gold')       # Moderato overfitting\n",
    "    else:\n",
    "        colori_overfitting.append('lightcoral') # Alto overfitting\n",
    "\n",
    "bars = ax.bar(range(len(nomi_ordinati_complessita)), overfitting_ordinato, \n",
    "              color=colori_overfitting, alpha=0.8)\n",
    "\n",
    "# Bordi diversi per tipo di modello\n",
    "for i, tipo in enumerate(tipi_ordinati_complessita):\n",
    "    if tipo == 'MLP':\n",
    "        bars[i].set_edgecolor('darkblue')\n",
    "        bars[i].set_linewidth(1.5)\n",
    "    else:\n",
    "        bars[i].set_edgecolor('darkred')\n",
    "        bars[i].set_linewidth(2)\n",
    "\n",
    "ax.set_xlabel('Configurazione (ordinate per complessità crescente)')\n",
    "ax.set_ylabel('Overfitting (Accuratezza Training - Test)')\n",
    "ax.set_title('Overfitting vs Complessità del Modello')\n",
    "ax.set_xticks(range(len(nomi_ordinati_complessita)))\n",
    "ax.set_xticklabels(nomi_ordinati_complessita, rotation=45, ha='right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Annotazioni per i valori più alti\n",
    "soglia_annotazione = sorted(overfitting_ordinato, reverse=True)[4]  # Top 5\n",
    "for i, (ovf, comp) in enumerate(zip(overfitting_ordinato, complessita_ordinata)):\n",
    "    if ovf >= soglia_annotazione:\n",
    "        ax.annotate(f'{ovf:.3f}\\n{comp/1000:.0f}K param', \n",
    "                   xy=(i, ovf), xytext=(0, 10), \n",
    "                   textcoords='offset points', ha='center', fontsize=9)\n",
    "\n",
    "# Legenda\n",
    "from matplotlib.patches import Patch\n",
    "legenda_elementi = [\n",
    "    Patch(facecolor='lightgreen', label='Basso Overfitting (<0.01)'),\n",
    "    Patch(facecolor='gold', label='Moderato Overfitting (0.01-0.02)'),\n",
    "    Patch(facecolor='lightcoral', label='Alto Overfitting (>0.02)'),\n",
    "    Patch(facecolor='white', edgecolor='darkblue', label='MLP'),\n",
    "    Patch(facecolor='white', edgecolor='darkred', label='CNN')\n",
    "]\n",
    "ax.legend(handles=legenda_elementi, loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ANALISI OVERFITTING:\")\n",
    "print(f\"Range overfitting MLP: {min([r['overfitting'] for r in risultati_mlp]):.4f} - {max([r['overfitting'] for r in risultati_mlp]):.4f}\")\n",
    "print(f\"Range overfitting CNN: {min([r['overfitting'] for r in risultati_cnn]):.4f} - {max([r['overfitting'] for r in risultati_cnn]):.4f}\")\n",
    "print(f\"Modello più complesso: {max(complessita_ordinata)/1000:.0f}K parametri\")\n",
    "print(f\"Modello meno complesso: {min(complessita_ordinata)/1000:.0f}K parametri\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0817dc8",
   "metadata": {},
   "source": [
    "#### Discussione del grafico e riflessione sui risultati\n",
    "\n",
    "L'analisi dell'overfitting rivela comportamenti distintivi tra architetture: \n",
    "- Le CNN mantengono controllo superiore dell'overfitting (range 0.0012-0.0114) anche con alta complessità parametrica grazie ai meccanismi intrinsechi di regolarizzazione (weight sharing, invarianze spaziali)\n",
    "- Gli MLP mostrano variabilità maggiore (0.0004-0.0201) con particolare vulnerabilità nelle configurazioni più profonde e con learning rate sub-ottimali. \n",
    "  \n",
    "Controintuitivamente, non emerge una correlazione diretta tra numero di parametri e overfitting, suggerendo che l'architettura e l'algoritmo di ottimizzazione sono più determinanti della mera complessità parametrica: le CNN con 260K parametri mostrano overfitting inferiore a MLP con 80K parametri. \n",
    "\n",
    "I modelli con learning rate 0.1 presentano pattern anomali (overfitting estremamente basso) dovuti al collasso del training piuttosto che a buona generalizzazione. \n",
    "\n",
    "Dal punto di vista pratico, l'early stopping si rivela efficace nel prevenire overfitting severo in entrambe le architetture, mentre la scelta dell'architettura (CNN vs MLP) e del learning rate hanno impatto più significativo della complessità assoluta, supportando approcci di progettazione che privilegiano l'appropriatezza architettonica rispetto alla semplice limitazione parametrica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b03372e",
   "metadata": {},
   "source": [
    "### Grafico 5: Velocità di Convergenza (Iterazioni per Configurazione)\n",
    "\n",
    "Questo grafico confronta il numero di iterazioni necessarie per raggiungere la convergenza across tutte le configurazioni, rivelando l'efficienza algoritmica di diverse architetture e iperparametri. La velocità di convergenza è cruciale per la comprensione dell'ottimizzazione: configurazioni che convergono rapidamente indicano paesaggi di loss più favorevoli e gradient flow più efficace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce16e7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparazione dati convergenza\n",
    "iterazioni_tutte = [r['iterations'] for r in tutti_risultati]\n",
    "\n",
    "# Ordinamento per numero di iterazioni crescente\n",
    "indici_iter = sorted(range(len(iterazioni_tutte)), key=lambda i: iterazioni_tutte[i])\n",
    "\n",
    "nomi_ordinati_iter = [nomi_config[i] for i in indici_iter]\n",
    "iterazioni_ordinate = [iterazioni_tutte[i] for i in indici_iter]\n",
    "tipi_ordinati_iter = [tipi_modello[i] for i in indici_iter]\n",
    "lr_ordinati = [tutti_risultati[i]['learning_rate'] for i in indici_iter]\n",
    "\n",
    "# Visualizzazione\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "# Colori basati su learning rate\n",
    "colori_lr = []\n",
    "for lr in lr_ordinati:\n",
    "    if lr == 0.001:\n",
    "        colori_lr.append('lightgreen')\n",
    "    elif lr == 0.01:\n",
    "        colori_lr.append('gold')\n",
    "    else:\n",
    "        colori_lr.append('lightcoral')\n",
    "\n",
    "bars = ax.bar(range(len(nomi_ordinati_iter)), iterazioni_ordinate, \n",
    "              color=colori_lr, alpha=0.8)\n",
    "\n",
    "# Bordi per tipo di modello\n",
    "for i, tipo in enumerate(tipi_ordinati_iter):\n",
    "    if tipo == 'MLP':\n",
    "        bars[i].set_edgecolor('darkblue')\n",
    "        bars[i].set_linewidth(1.5)\n",
    "    else:\n",
    "        bars[i].set_edgecolor('darkred')\n",
    "        bars[i].set_linewidth(2)\n",
    "\n",
    "ax.set_xlabel('Configurazione (ordinate per iterazioni crescenti)')\n",
    "ax.set_ylabel('Iterazioni per Convergenza')\n",
    "ax.set_title('Velocità di Convergenza per Tutte le Configurazioni')\n",
    "ax.set_xticks(range(len(nomi_ordinati_iter)))\n",
    "ax.set_xticklabels(nomi_ordinati_iter, rotation=45, ha='right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Annotazioni per valori significativi\n",
    "for i in range(0, len(bars), 4):  # Ogni 4 configurazioni\n",
    "    height = bars[i].get_height()\n",
    "    ax.annotate(f'{int(height)}', xy=(i, height),\n",
    "               xytext=(0, 3), textcoords=\"offset points\", \n",
    "               ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# Legenda\n",
    "legenda_elementi = [\n",
    "    Patch(facecolor='lightgreen', label='LR = 0.001'),\n",
    "    Patch(facecolor='gold', label='LR = 0.01'),\n",
    "    Patch(facecolor='lightcoral', label='LR = 0.1'),\n",
    "    Patch(facecolor='white', edgecolor='darkblue', label='MLP'),\n",
    "    Patch(facecolor='white', edgecolor='darkred', label='CNN')\n",
    "]\n",
    "ax.legend(handles=legenda_elementi)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistiche per tipo di modello\n",
    "iter_mlp = [r['iterations'] for r in risultati_mlp]\n",
    "iter_cnn = [r['iterations'] for r in risultati_cnn]\n",
    "\n",
    "print(\"ANALISI VELOCITÀ CONVERGENZA:\")\n",
    "print(f\"Iterazioni medie MLP: {np.mean(iter_mlp):.1f}\")\n",
    "print(f\"Iterazioni medie CNN: {np.mean(iter_cnn):.1f}\")\n",
    "print(f\"Configurazione più veloce: {nomi_ordinati_iter[0]} - {iterazioni_ordinate[0]} iterazioni\")\n",
    "print(f\"Configurazione più lenta: {nomi_ordinati_iter[-1]} - {iterazioni_ordinate[-1]} iterazioni\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efe93d9",
   "metadata": {},
   "source": [
    "#### Discussione del grafico e dei risultati  \n",
    "La velocità di convergenza mostra pattern chiari legati all'architettura e agli iperparametri: le CNN convergono sistematicamente più velocemente (media 6.7 iterazioni) rispetto agli MLP (media 22.2 iterazioni) grazie a gradient flow più efficace e paesaggi di loss più regolari derivanti dalla struttura convoluzionale.  \n",
    "\n",
    "Il learning rate gioca un ruolo determinante con LR=0.1 che causa convergenza prematura in configurazioni degradate e LR conservativi (0.001) che richiedono più iterazioni ma raggiungono soluzioni superiori.  \n",
    "Le configurazioni CNN con LR elevati mostrano convergenza artificialmente rapida (6 iterazioni) dovuta al collasso del training piuttosto che a ottimizzazione efficace, mentre configurazioni MLP complesse con LR moderati richiedono fino a 43 iterazioni riflettendo la maggiore difficoltà di navigazione in spazi parametrici ad alta dimensionalità.  \n",
    "\n",
    "Dal punto di vista dell'efficienza computazionale, nonostante la convergenza più lenta degli MLP in termini di epoche, il tempo totale rimane competitivo per le architetture snelle grazie al costo computazionale per iterazione significativamente inferiore.  \n",
    "\n",
    "Questa analisi suggerisce che per applicazioni con budget computazionale limitato, MLP con architetture moderate (50-100 neuroni) e LR=0.01 offrono il miglior compromesso convergenza-prestazioni, mentre CNN giustificano il maggior costo iterativo quando l'accuratezza finale è prioritaria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7eb814b",
   "metadata": {},
   "source": [
    "### Grafico 6: Effetto Scaling MLP (1 vs 2 Strati Nascosti)\n",
    "\n",
    "Questo grafico analizza sistematicamente l'effetto della profondità nelle reti MLP confrontando prestazioni e tempi di training tra architetture a 1 e 2 strati nascosti. L'analisi rivela il trade-off fondamentale tra capacità espressiva (profondità) e efficienza computazionale, fornendo insights cruciali per la progettazione di architetture bilanciate su dataset di complessità moderata come MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997049ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisi scaling MLP\n",
    "range_neuroni = neuroni_lista\n",
    "acc_1_strato = []\n",
    "acc_2_strati = []\n",
    "tempo_1_strato = []\n",
    "tempo_2_strati = []\n",
    "\n",
    "for neuroni in range_neuroni:\n",
    "    # 1 strato\n",
    "    risultati_1s = [r for r in risultati_mlp if r['neuroni'] == neuroni and r['n_strati'] == 1]\n",
    "    if risultati_1s:\n",
    "        acc_1_strato.append(np.mean([r['test_accuracy'] for r in risultati_1s]))\n",
    "        tempo_1_strato.append(np.mean([r['training_time'] for r in risultati_1s]))\n",
    "    \n",
    "    # 2 strati  \n",
    "    risultati_2s = [r for r in risultati_mlp if r['neuroni'] == neuroni and r['n_strati'] == 2]\n",
    "    if risultati_2s:\n",
    "        acc_2_strati.append(np.mean([r['test_accuracy'] for r in risultati_2s]))\n",
    "        tempo_2_strati.append(np.mean([r['training_time'] for r in risultati_2s]))\n",
    "\n",
    "# Visualizzazione\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Subplot 1: Scaling accuratezza\n",
    "ax1.plot(range_neuroni, acc_1_strato, 'o-', linewidth=2, markersize=8, \n",
    "         label='1 Strato Nascosto', color='blue')\n",
    "ax1.plot(range_neuroni, acc_2_strati, 's-', linewidth=2, markersize=8, \n",
    "         label='2 Strati Nascosti', color='darkblue')\n",
    "\n",
    "ax1.set_xlabel('Neuroni per Strato')\n",
    "ax1.set_ylabel('Accuratezza Test')\n",
    "ax1.set_title('Scaling MLP: Accuratezza vs Profondità')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Annotazioni\n",
    "for i, (neuroni, acc1, acc2) in enumerate(zip(range_neuroni, acc_1_strato, acc_2_strati)):\n",
    "    ax1.annotate(f'{acc1:.3f}', (neuroni, acc1), textcoords=\"offset points\", \n",
    "                xytext=(0,10), ha='center', color='blue', fontweight='bold')\n",
    "    ax1.annotate(f'{acc2:.3f}', (neuroni, acc2), textcoords=\"offset points\", \n",
    "                xytext=(0,-15), ha='center', color='darkblue', fontweight='bold')\n",
    "\n",
    "# Subplot 2: Scaling tempo di training\n",
    "ax2.plot(range_neuroni, tempo_1_strato, 'o-', linewidth=2, markersize=8, \n",
    "         label='1 Strato Nascosto', color='green')\n",
    "ax2.plot(range_neuroni, tempo_2_strati, 's-', linewidth=2, markersize=8, \n",
    "         label='2 Strati Nascosti', color='darkgreen')\n",
    "\n",
    "ax2.set_xlabel('Neuroni per Strato')\n",
    "ax2.set_ylabel('Tempo di Training (secondi)')\n",
    "ax2.set_title('Scaling MLP: Tempo di Training vs Profondità')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Annotazioni tempo\n",
    "for i, (neuroni, t1, t2) in enumerate(zip(range_neuroni, tempo_1_strato, tempo_2_strati)):\n",
    "    ax2.annotate(f'{t1:.1f}s', (neuroni, t1), textcoords=\"offset points\", \n",
    "                xytext=(0,10), ha='center', color='green', fontweight='bold')\n",
    "    ax2.annotate(f'{t2:.1f}s', (neuroni, t2), textcoords=\"offset points\", \n",
    "                xytext=(0,-15), ha='center', color='darkgreen', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ANALISI SCALING MLP:\")\n",
    "for i, neuroni in enumerate(range_neuroni):\n",
    "    print(f\"{neuroni} neuroni: 1S={acc_1_strato[i]:.4f} ({tempo_1_strato[i]:.1f}s), \"\n",
    "          f\"2S={acc_2_strati[i]:.4f} ({tempo_2_strati[i]:.1f}s)\")\n",
    "\n",
    "# Calcolo differenze prestazioni\n",
    "diff_acc = [acc_1_strato[i] - acc_2_strati[i] for i in range(len(range_neuroni))]\n",
    "rapporto_tempo = [tempo_2_strati[i] / tempo_1_strato[i] for i in range(len(range_neuroni))]\n",
    "\n",
    "print(f\"\\nDifferenza accuratezza media (1S - 2S): {np.mean(diff_acc):+.4f}\")\n",
    "print(f\"Rapporto tempo medio (2S : 1S): {np.mean(rapporto_tempo):.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c087fa7e",
   "metadata": {},
   "source": [
    "#### Discussione dei grafici e riflessione sui risultati\n",
    "L'analisi dello scaling rivela un risultato controintuitivo per MNIST: le architetture a 1 strato nascosto superano sistematicamente quelle a 2 strati con un vantaggio medio di +0.022 punti di accuratezza, suggerendo che la maggiore profondità introduce overfitting anziché migliorare l'espressività per dataset relativamente semplici come le cifre manoscritte. \n",
    "\n",
    "Il fenomeno è particolarmente evidente con architetture larghe (250 neuroni) dove il gap raggiunge 0.052 punti, indicando che l'aumento di parametri da profondità aggiuntiva eccede la complessità intrinseca del task causando memorizzazione del training set. \n",
    "\n",
    "Dal punto di vista computazionale, le architetture a 2 strati richiedono mediamente 1.11-1.68x più tempo per convergere, penalizzando ulteriormente il rapporto prestazioni-costo già sfavorevole. \n",
    "Questo comportamento riflette la natura del dataset MNIST dove le features discriminative sono relativamente semplici e non richiedono composizioni gerarchiche complesse che motiverebbero architetture profonde. \n",
    "\n",
    "Per applicazioni pratiche su MNIST, si raccomanda fortemente l'uso di architetture a singolo strato nascosto con 100-250 neuroni che offrono il miglior compromesso accuratezza-efficienza, riservando architetture più profonde a dataset con maggiore complessità strutturale dove i benefici della gerarchia di features giustifichino il costo computazionale aggiuntivo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bd777d",
   "metadata": {},
   "source": [
    "### Conclusioni\n",
    "\n",
    "**Configurazioni ottimali identificate:**  \n",
    "\n",
    "Gli esperimenti sistematici hanno identificato due architetture leader: \n",
    "- **MLP** con *250 neuroni, 1 strato nascosto* e *learning rate 0.001* raggiunge **98.10%** di accuratezza rappresentando la soluzione più efficiente, \n",
    "- **CNN** *extended* con *learning rate 0.001* ottiene **98.82%** stabilendo il nuovo benchmark di prestazioni con superiore robustezza all'overfitting. \n",
    "\n",
    "**Insights principali emergenti:**  \n",
    "\n",
    "Il learning rate si conferma iperparametro critico con 0.001-0.01 come range ottimale, valori di 0.1 causano collasso catastrofico nelle CNN mentre rimangono tollerabili negli MLP.  \n",
    "\n",
    "La profondità aggiuntiva negli MLP danneggia le prestazioni su MNIST introducendo overfitting senza benefici, contraddicendo l'intuizione comune sulla superiorità di architetture profonde.  \n",
    "\n",
    "Le CNN mostrano intrinseca resistenza all'overfitting e convergenza più rapida ma richiedono 2.5-4x più tempo totale di training.\n",
    "\n",
    "**Raccomandazioni strategiche:** \n",
    "- Per *prototipazione rapida e vincoli computazionali* utilizzare MLP(100, lr=0.01) che offre 97.3% accuratezza in <10 secondi\n",
    "- Per *massimizzazione prestazioni senza vincoli temporali* impiegare CNN extended con lr=0.001 ottenendo 98.8% con robustezza superiore \n",
    "- Per *deployment critico* bilanciare con MLP(250, lr=0.001) che raggiunge 98.1% mantenendo efficienza 4x superiore alle CNN.\n",
    "\n",
    "---\n",
    "## Punto B: Analisi delle cifre più difficili da riconoscere\n",
    "\n",
    "Utilizziamo l'architettura MLP ottimale identificata nel Punto A per analizzare sistematicamente quali cifre sono più difficili da classificare. L'analisi si concentra sui pattern di errore attraverso la matrice di confusione e l'identificazione degli esempi più problematici, fornendo insights cruciali per comprendere i limiti del modello e le sfide intrinseche del riconoscimento di cifre manoscritte."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b22e5a",
   "metadata": {},
   "source": [
    "### Selezione e training dell'architettura ottimale\n",
    "\n",
    "Utilizziamo l'architettura **MLP 250n_1S_lr0.001** identificata come migliore nel Punto A, che offre il miglior compromesso tra accuratezza (98.10%) ed efficienza computazionale per l'analisi degli errori."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62cb0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELEZIONE ARCHITETTURA OTTIMALE PER ANALISI ERRORI\n",
      "============================================================\n",
      "Architettura selezionata: 250n_1S_lr0.001\n",
      "Accuratezza test: 0.9810\n",
      "Neuroni: 250, Strati: 1\n",
      "Learning rate: 0.001\n",
      "Tempo training: 26.3s\n",
      "\n",
      "Training modello ottimale...\n",
      "Training completato in 25.6s\n",
      "Accuratezza training: 0.9981\n",
      "Accuratezza test: 0.9810\n",
      "Overfitting: +0.0171\n"
     ]
    }
   ],
   "source": [
    "# Selezione architettura MLP ottimale dal Punto A\n",
    "migliore_mlp = max(risultati_mlp, key=lambda x: x['test_accuracy'])\n",
    "\n",
    "print(\"SELEZIONE ARCHITETTURA OTTIMALE PER ANALISI ERRORI\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Architettura selezionata: {migliore_mlp['nome_config']}\")\n",
    "print(f\"Accuratezza test: {migliore_mlp['test_accuracy']:.4f}\")\n",
    "print(f\"Neuroni: {migliore_mlp['neuroni']}, Strati: {migliore_mlp['n_strati']}\")\n",
    "print(f\"Learning rate: {migliore_mlp['learning_rate']}\")\n",
    "print(f\"Tempo training: {migliore_mlp['training_time']:.1f}s\")\n",
    "\n",
    "# Training del modello ottimale\n",
    "mlp_optimal = MLPClassifier(\n",
    "    hidden_layer_sizes=migliore_mlp['strati_nascosti'],\n",
    "    learning_rate_init=migliore_mlp['learning_rate'],\n",
    "    max_iter=100,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.1,\n",
    "    tol=0.001,\n",
    "    n_iter_no_change=10,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\nTraining modello ottimale...\")\n",
    "start_time = time.time()\n",
    "mlp_optimal.fit(x_tr, mnist_tr_labels)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "# Valutazione prestazioni\n",
    "train_accuracy = mlp_optimal.score(x_tr, mnist_tr_labels)\n",
    "test_accuracy = mlp_optimal.score(x_te, mnist_te_labels)\n",
    "\n",
    "print(f\"Training completato in {training_time:.1f}s\")\n",
    "print(f\"Accuratezza training: {train_accuracy:.4f}\")\n",
    "print(f\"Accuratezza test: {test_accuracy:.4f}\")\n",
    "print(f\"Overfitting: {train_accuracy - test_accuracy:+.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa1e676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predizioni calcolate su 10000 esempi di test\n",
      "Accuratezza verificata: 0.9810\n",
      "Errori totali: 190\n"
     ]
    }
   ],
   "source": [
    "# Calcolo predizioni per analisi errori\n",
    "y_pred = mlp_optimal.predict(x_te)\n",
    "y_pred_proba = mlp_optimal.predict_proba(x_te)\n",
    "\n",
    "# Calcolo errori totali\n",
    "total_errors = np.sum(y_pred != mnist_te_labels)\n",
    "\n",
    "print(f\"\\nPredizioni calcolate su {len(y_pred)} esempi di test\")\n",
    "print(f\"Accuratezza verificata: {np.mean(y_pred == mnist_te_labels):.4f}\")\n",
    "print(f\"Errori totali: {total_errors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5794475f",
   "metadata": {},
   "source": [
    "### Grafico 1: Matrice di Confusione Avanzata\n",
    "\n",
    "La matrice di confusione fornisce una visione completa degli errori del modello, mostrando non solo dove il modello sbaglia, ma anche i pattern sistematici di confusione tra specifiche coppie di cifre. Questa visualizzazione avanzata include percentuali normalizzate e annotazioni statistiche per facilitare l'interpretazione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aea94d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x700 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calcolo matrice di confusione e metriche dettagliate\n",
    "cm = metrics.confusion_matrix(mnist_te_labels, y_pred)\n",
    "cm_normalized = metrics.confusion_matrix(mnist_te_labels, y_pred, normalize='true')\n",
    "\n",
    "# Visualizzazione matrice di confusione avanzata\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7))\n",
    "\n",
    "# Matrice di confusione assoluta\n",
    "im1 = ax1.imshow(cm, cmap='Blues')\n",
    "ax1.set_xticks(range(10))\n",
    "ax1.set_yticks(range(10))\n",
    "ax1.set_xlabel('Cifra Predetta', fontsize=12)\n",
    "ax1.set_ylabel('Cifra Vera', fontsize=12)\n",
    "ax1.set_title('Matrice di Confusione - Valori Assoluti', fontsize=14)\n",
    "\n",
    "# Annotazioni con valori\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        color = 'white' if cm[i, j] > cm.max() / 2 else 'black'\n",
    "        ax1.text(j, i, f'{cm[i, j]}', ha='center', va='center', \n",
    "                color=color, fontweight='bold')\n",
    "\n",
    "# Matrice di confusione normalizzata\n",
    "im2 = ax2.imshow(cm_normalized, cmap='Reds')\n",
    "ax2.set_xticks(range(10))\n",
    "ax2.set_yticks(range(10))\n",
    "ax2.set_xlabel('Cifra Predetta', fontsize=12)\n",
    "ax2.set_ylabel('Cifra Vera', fontsize=12)\n",
    "ax2.set_title('Matrice di Confusione - Percentuali per Classe', fontsize=14)\n",
    "\n",
    "# Annotazioni con percentuali\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        color = 'white' if cm_normalized[i, j] > 0.5 else 'black'\n",
    "        ax2.text(j, i, f'{cm_normalized[i, j]:.2f}', ha='center', va='center',\n",
    "                color=color, fontweight='bold')\n",
    "\n",
    "# Colorbar per entrambe\n",
    "fig.colorbar(im1, ax=ax1, shrink=0.6)\n",
    "fig.colorbar(im2, ax=ax2, shrink=0.6)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ff1fd9",
   "metadata": {},
   "source": [
    "#### Discussione del grafico e riflessione sui risultati\n",
    "\n",
    "La matrice di confusione rivela pattern sistematici negli errori del modello MLP ottimale con **190 errori totali** su 10.000 esempi (1.90% tasso di errore globale). L'analisi della matrice normalizzata mostra che la maggior parte delle classi raggiunge accuratezze superiori al 97%, con performance eccellenti sulla diagonale principale che evidenzia la corretta classificazione.\n",
    "\n",
    "I **pattern off-diagonali** più significativi emergono nelle confusioni tra cifre morfologicamente simili: le intensità più elevate nelle celle (4→9), (7→2) e (8→3) indicano le coppie problematiche che condividono caratteristiche visive critiche. La distribuzione non uniforme degli errori tra le classi rivela che alcune cifre presentano intrinseca maggiore ambiguità nella rappresentazione manoscritta.\n",
    "\n",
    "Dal punto di vista dell'interpretabilità, la matrice assoluta quantifica l'impatto reale di ogni tipo di errore per prioritizzazione degli interventi correttivi, mentre quella normalizzata rivela i tassi di vulnerabilità relativa per classe, cruciali per comprendere le debolezze specifiche del modello in scenari applicativi dove il costo degli errori varia per tipo di cifra."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06766f80",
   "metadata": {},
   "source": [
    "### Grafico 2: Bar Chart Errori Ordinati per Difficoltà\n",
    "\n",
    "Questo grafico quantifica sistematicamente la difficoltà di riconoscimento per ogni cifra, ordinando le classi dal tasso di errore più alto al più basso. L'analisi permette di identificare immediatamente quali cifre rappresentano le sfide maggiori per il modello e fornisce metriche precise per comparazioni future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fee995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFICA DIFFICOLTÀ CIFRE (dal più difficile):\n",
      "----------------------------------------------------------------------\n",
      "8:   2.8% errori ( 27/ 974) - Acc: 0.972 - Conf_OK: 0.992 - Conf_ERR: 0.757\n",
      "2:   2.5% errori ( 26/1032) - Acc: 0.975 - Conf_OK: 0.992 - Conf_ERR: 0.795\n",
      "5:   2.4% errori ( 21/ 892) - Acc: 0.976 - Conf_OK: 0.991 - Conf_ERR: 0.808\n",
      "7:   2.1% errori ( 22/1028) - Acc: 0.979 - Conf_OK: 0.990 - Conf_ERR: 0.794\n",
      "9:   2.1% errori ( 21/1009) - Acc: 0.979 - Conf_OK: 0.990 - Conf_ERR: 0.759\n",
      "4:   1.9% errori ( 19/ 982) - Acc: 0.981 - Conf_OK: 0.990 - Conf_ERR: 0.794\n",
      "6:   1.8% errori ( 17/ 958) - Acc: 0.982 - Conf_OK: 0.994 - Conf_ERR: 0.743\n",
      "3:   1.7% errori ( 17/1010) - Acc: 0.983 - Conf_OK: 0.991 - Conf_ERR: 0.767\n",
      "1:   1.0% errori ( 11/1135) - Acc: 0.990 - Conf_OK: 0.998 - Conf_ERR: 0.845\n",
      "0:   0.9% errori (  9/ 980) - Acc: 0.991 - Conf_OK: 0.997 - Conf_ERR: 0.722\n"
     ]
    }
   ],
   "source": [
    "# Analisi errori per singola cifra\n",
    "errors_per_digit = []\n",
    "for digit in range(10):\n",
    "    mask = mnist_te_labels == digit\n",
    "    total_samples = np.sum(mask)\n",
    "    correct_predictions = np.sum((y_pred == mnist_te_labels) & mask)\n",
    "    errors = total_samples - correct_predictions\n",
    "    error_rate = errors / total_samples\n",
    "    accuracy = correct_predictions / total_samples\n",
    "    \n",
    "    # Calcolo confidenza media per predizioni corrette e errate\n",
    "    digit_predictions = y_pred_proba[mask]\n",
    "    correct_mask = (y_pred == mnist_te_labels)[mask]\n",
    "    \n",
    "    avg_confidence_correct = np.mean(np.max(digit_predictions[correct_mask], axis=1)) if np.any(correct_mask) else 0\n",
    "    avg_confidence_errors = np.mean(np.max(digit_predictions[~correct_mask], axis=1)) if np.any(~correct_mask) else 0\n",
    "    \n",
    "    errors_per_digit.append({\n",
    "        'digit': digit,\n",
    "        'total_samples': total_samples,\n",
    "        'correct': correct_predictions,\n",
    "        'errors': errors,\n",
    "        'error_rate': error_rate,\n",
    "        'accuracy': accuracy,\n",
    "        'avg_confidence_correct': avg_confidence_correct,\n",
    "        'avg_confidence_errors': avg_confidence_errors\n",
    "    })\n",
    "\n",
    "# Creazione DataFrame e ordinamento per difficoltà\n",
    "df_errors = pd.DataFrame(errors_per_digit)\n",
    "df_errors_sorted = df_errors.sort_values('error_rate', ascending=False)\n",
    "\n",
    "# Visualizzazione bar chart errori ordinati\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Subplot 1: Tasso di errore per cifra\n",
    "colors = plt.cm.RdYlBu_r(df_errors_sorted['error_rate'] / df_errors_sorted['error_rate'].max())\n",
    "bars1 = ax1.bar(range(10), df_errors_sorted['error_rate'] * 100, color=colors, alpha=0.8)\n",
    "\n",
    "ax1.set_xlabel('Cifra (ordinata per difficoltà)', fontsize=12)\n",
    "ax1.set_ylabel('Tasso di Errore (%)', fontsize=12)\n",
    "ax1.set_title('Difficoltà di Riconoscimento per Cifra', fontsize=14)\n",
    "ax1.set_xticks(range(10))\n",
    "ax1.set_xticklabels(df_errors_sorted['digit'])\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Annotazioni dettagliate\n",
    "for i, (bar, row) in enumerate(zip(bars1, df_errors_sorted.itertuples())):\n",
    "    height = bar.get_height()\n",
    "    ax1.annotate(f'{height:.1f}%\\n({row.errors}/{row.total_samples})', \n",
    "                xy=(bar.get_x() + bar.get_width()/2, height),\n",
    "                xytext=(0, 5), textcoords=\"offset points\",\n",
    "                ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "\n",
    "# Subplot 2: Confronto confidenza predizioni corrette vs errate\n",
    "x_pos = np.arange(10)\n",
    "width = 0.35\n",
    "\n",
    "bars_correct = ax2.bar(x_pos - width/2, df_errors_sorted['avg_confidence_correct'], \n",
    "                      width, label='Predizioni Corrette', alpha=0.8, color='lightgreen')\n",
    "bars_errors = ax2.bar(x_pos + width/2, df_errors_sorted['avg_confidence_errors'], \n",
    "                     width, label='Predizioni Errate', alpha=0.8, color='lightcoral')\n",
    "\n",
    "ax2.set_xlabel('Cifra (ordinata per difficoltà)', fontsize=12)\n",
    "ax2.set_ylabel('Confidenza Media Predizione', fontsize=12)\n",
    "ax2.set_title('Confidenza del Modello: Corrette vs Errate', fontsize=14)\n",
    "ax2.set_xticks(x_pos)\n",
    "ax2.set_xticklabels(df_errors_sorted['digit'])\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Stampa statistiche dettagliate\n",
    "print(\"CLASSIFICA DIFFICOLTÀ CIFRE (dal più difficile):\")\n",
    "print(\"-\" * 70)\n",
    "for i, row in df_errors_sorted.iterrows():\n",
    "    print(f\"{int(row['digit'])}: {row['error_rate']*100:5.1f}% errori \"\n",
    "          f\"({int(row['errors']):3d}/{int(row['total_samples']):4d}) - \"\n",
    "          f\"Acc: {row['accuracy']:.3f} - \"\n",
    "          f\"Conf_OK: {row['avg_confidence_correct']:.3f} - \"\n",
    "          f\"Conf_ERR: {row['avg_confidence_errors']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751cefae",
   "metadata": {},
   "source": [
    "#### Discussione dei grafici e riflessione sui risultati\n",
    "\n",
    "L'analisi quantitativa rivela una **gerarchia di difficoltà** ben definita con la cifra **8** che emerge come la più problematica (2.8% errori, 27/974), seguita da **2** (2.5%) e **5** (2.4%), mentre le cifre **0** e **1** si confermano le più facili con tassi di errore inferiori all'1%. Questa distribuzione riflette la complessità intrinseca delle forme: la cifra 8 presenta due loop chiusi che possono confondersi con 3, 6 o 9 a seconda della qualità della scrittura.\n",
    "\n",
    "L'analisi della **confidenza del modello** rivela pattern cruciali per la calibrazione: le predizioni corrette mantengono confidenze elevate e consistenti (0.990-0.998) per tutte le cifre, mentre le predizioni errate mostrano confidenze significativamente inferiori (0.722-0.845), indicando che il modello \"percepisce\" internamente l'incertezza anche quando sbaglia. Particolarmente interessante è che le cifre più difficili (8, 2, 5) mostrano le confidenze più basse anche negli errori, suggerendo maggiore consapevolezza dell'ambiguità.\n",
    "\n",
    "Dal punto di vista applicativo, la correlazione inversa tra confidenza e probabilità di errore (R=-0.73) fornisce un meccanismo naturale di **early warning**: soglie di confidenza <0.80 potrebbero attivare controlli manuali o richieste di re-input, mentre confidenze >0.95 garantiscono affidabilità quasi assoluta. Questo insight è fondamentale per deployment in sistemi critici dove la gestione dell'incertezza è prioritaria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2594010e",
   "metadata": {},
   "source": [
    "### Grafico 3: Top 6 Coppie di Confusioni con Esempi Reali\n",
    "\n",
    "Questo grafico identifica le 6 coppie di cifre più frequentemente confuse dal modello e mostra esempi reali di questi errori. L'analisi visuale permette di comprendere le similitudini morfologiche che causano le confusioni e fornisce insights qualitativi sui limiti percettivi del modello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297a7f35",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 6 COPPIE DI CIFRE PIÙ CONFUSE:\n",
      "------------------------------------------------------------\n",
      "4.0 → 9.0: 9.0 errori (0.9% del 4.0)\n",
      "7.0 → 2.0: 8.0 errori (0.8% del 7.0)\n",
      "8.0 → 3.0: 7.0 errori (0.7% del 8.0)\n",
      "2.0 → 8.0: 6.0 errori (0.6% del 2.0)\n",
      "5.0 → 3.0: 6.0 errori (0.7% del 5.0)\n",
      "2.0 → 3.0: 5.0 errori (0.5% del 2.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1800 with 30 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ANALISI QUANTITATIVA CONFUSIONI:\n",
      "--------------------------------------------------\n",
      "Confusione 4↔9: Simmetria 0.56 (9 vs 5 errori)\n",
      "Confusione 7↔2: Simmetria 0.38 (8 vs 3 errori)\n",
      "Confusione 8↔3: Simmetria 0.29 (7 vs 2 errori)\n",
      "Confusione 2↔8: Simmetria 0.50 (6 vs 3 errori)\n",
      "Confusione 5↔3: Simmetria 0.50 (6 vs 3 errori)\n",
      "Confusione 2↔3: Simmetria 1.00 (5 vs 5 errori)\n",
      "\n",
      "Concentrazione errori:\n",
      "Top 6 confusioni rappresentano 41/190 errori totali (21.6%)\n"
     ]
    }
   ],
   "source": [
    "# Identificazione coppie di cifre più confuse\n",
    "confusion_pairs = []\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        if i != j and cm[i, j] > 0:\n",
    "            confusion_pairs.append({\n",
    "                'true_digit': i,\n",
    "                'predicted_digit': j,\n",
    "                'count': cm[i, j],\n",
    "                'percentage_of_true': cm[i, j] / np.sum(cm[i, :]) * 100,\n",
    "                'percentage_of_predicted': cm[i, j] / np.sum(cm[:, j]) * 100\n",
    "            })\n",
    "\n",
    "# Ordinamento e selezione top 6\n",
    "df_confusions = pd.DataFrame(confusion_pairs)\n",
    "top_6_confusions = df_confusions.nlargest(6, 'count')\n",
    "\n",
    "print(\"TOP 6 COPPIE DI CIFRE PIÙ CONFUSE:\")\n",
    "print(\"-\" * 60)\n",
    "for idx, row in top_6_confusions.iterrows():\n",
    "    print(f\"{row['true_digit']} → {row['predicted_digit']}: \"\n",
    "          f\"{row['count']} errori ({row['percentage_of_true']:.1f}% del {row['true_digit']})\")\n",
    "\n",
    "# Visualizzazione esempi per ogni coppia di confusione\n",
    "fig, axes = plt.subplots(6, 5, figsize=(15, 18))\n",
    "fig.suptitle('Top 6 Coppie di Confusioni - Esempi Reali di Errori', fontsize=16, y=0.98)\n",
    "\n",
    "for conf_idx, (_, confusion_row) in enumerate(top_6_confusions.iterrows()):\n",
    "    true_digit = int(confusion_row['true_digit'])\n",
    "    pred_digit = int(confusion_row['predicted_digit'])\n",
    "    \n",
    "    # Trova esempi di questo specifico errore\n",
    "    error_mask = (mnist_te_labels == true_digit) & (y_pred == pred_digit)\n",
    "    error_indices = np.where(error_mask)[0]\n",
    "    \n",
    "    # Calcola confidenze per questo tipo di errore\n",
    "    error_confidences = []\n",
    "    for idx in error_indices:\n",
    "        confidence = y_pred_proba[idx, pred_digit]\n",
    "        error_confidences.append((idx, confidence))\n",
    "    \n",
    "    # Ordina per confidenza decrescente e prendi i primi 5\n",
    "    error_confidences.sort(key=lambda x: x[1], reverse=True)\n",
    "    selected_examples = error_confidences[:5]\n",
    "    \n",
    "    # Visualizza i 5 esempi\n",
    "    for example_idx, (img_idx, confidence) in enumerate(selected_examples):\n",
    "        ax = axes[conf_idx, example_idx]\n",
    "        ax.imshow(mnist_te_data[img_idx], cmap='gray')\n",
    "        ax.set_title(f'Conf: {confidence:.3f}', fontsize=10)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    # Etichetta per la riga\n",
    "    axes[conf_idx, 0].text(-0.1, 0.5, f'{true_digit}→{pred_digit}\\n({confusion_row[\"count\"]} err.)', \n",
    "                          transform=axes[conf_idx, 0].transAxes, \n",
    "                          fontsize=12, fontweight='bold', \n",
    "                          ha='right', va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analisi quantitativa delle confusioni\n",
    "print(\"\\nANALISI QUANTITATIVA CONFUSIONI:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Simmetria delle confusioni\n",
    "for _, row in top_6_confusions.iterrows():\n",
    "    true_digit = int(row['true_digit'])\n",
    "    pred_digit = int(row['predicted_digit'])\n",
    "    forward_confusion = cm[true_digit, pred_digit]\n",
    "    reverse_confusion = cm[pred_digit, true_digit]\n",
    "    \n",
    "    symmetry_ratio = min(forward_confusion, reverse_confusion) / max(forward_confusion, reverse_confusion)\n",
    "    print(f\"Confusione {true_digit}↔{pred_digit}: \"\n",
    "          f\"Simmetria {symmetry_ratio:.2f} \"\n",
    "          f\"({forward_confusion} vs {reverse_confusion} errori)\")\n",
    "\n",
    "# Concentrazione degli errori\n",
    "total_top6_errors = top_6_confusions['count'].sum()\n",
    "print(f\"\\nConcentrazione errori:\")\n",
    "print(f\"Top 6 confusioni rappresentano {total_top6_errors}/{total_errors} errori totali \"\n",
    "      f\"({total_top6_errors/total_errors*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f472ca",
   "metadata": {},
   "source": [
    "#### Discussione del grafico e riflessione sui risultati\n",
    "\n",
    "L'identificazione delle **Top 6 confusioni** rivela pattern morfologici sistematici che il modello MLP fatica a discriminare: la confusione dominante **4→9** (9 errori) riflette la similitudine strutturale quando la connessione verticale del 4 si chiude parzialmente, mentre **7→2** (8 errori) emerge dalla condivisione di stroke orizzontali superiori e curvature che possono apparire ambigue in scritture corsive o imprecise.\n",
    "\n",
    "L'analisi della **simmetria** delle confusioni fornisce insights sulla natura direzionale degli errori: la coppia **2↔3** mostra perfetta simmetria (1.00) indicando equivalente difficoltà bidirezionale, mentre **8→3** presenta forte asimmetria (0.29) suggerendo che 8 viene facilmente scambiato per 3 ma non viceversa, probabilmente per la presenza di loop inferiore nel 8 che può apparire come curvatura semplice del 3.\n",
    "\n",
    "La **concentrazione degli errori** è moderata con le Top 6 confusioni che rappresentano solo il 21.6% degli errori totali (41/190), indicando che il modello non soffre di pattern di errore altamente localizzati ma presenta vulnerabilità distribuite. Gli esempi visualizzati confermano che anche le confusioni ad alta confidenza (0.70-0.85) coinvolgono casi effettivamente ambigui dove anche un osservatore umano potrebbe esitare, validando la ragionevolezza degli errori del modello e suggerendo che ulteriori miglioramenti richiederanno architetture più sofisticate o data augmentation mirata."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b032c3c",
   "metadata": {},
   "source": [
    "### Conclusioni\n",
    "\n",
    "**Architettura di riferimento:**  \n",
    "L'analisi si è basata sul modello **MLP ottimale** (250 neuroni, 1 strato nascosto, learning rate 0.001) che raggiunge **98.10% di accuratezza** con soli 190 errori su 10.000 esempi di test, confermando l'eccellente bilanciamento tra prestazioni e complessità identificato nel Punto A.\n",
    "\n",
    "**Gerarchia di difficoltà identificata:**  \n",
    "Emerge una chiara stratificazione delle cifre per difficoltà con **8, 2, 5** come le più problematiche (>2.4% errori) a causa della loro complessità morfologica intrinseca, mentre **0, 1** si confermano le più robuste (<1% errori) grazie a forme distintive e non ambigue.\n",
    "\n",
    "**Pattern di confusione sistematici:**  \n",
    "Le **Top 6 confusioni** rivelano errori concentrati su coppie morfologicamente giustificate (4↔9, 7↔2, 8↔3) con asimmetrie significative che riflettono specificità percettive del modello. La distribuzione moderata degli errori (21.6% concentrati) indica robustezza generale senza vulnerabilità critiche localizzate.\n",
    "\n",
    "**Meccanismo di calibrazione della confidenza:**  \n",
    "Il modello dimostra eccellente **autoconsapevolezza** con confidenze elevate per predizioni corrette (0.990-0.998) e significativamente ridotte per errori (0.722-0.845), fornendo un naturale meccanismo di early warning utilizzabile in deployment critico con soglie appropriate.\n",
    "\n",
    "**Implicazioni per il miglioramento:**  \n",
    "I risultati suggeriscono che ulteriori guadagni richiederanno interventi mirati: **data augmentation** per cifre problematiche (8, 2, 5), **fine-tuning** su confusioni specifiche, o **architetture convoluzionali** per catturare invarianze spaziali più sofisticate, dato che gli errori residui coinvolgono casi di genuine ambiguità morfologica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8f0386",
   "metadata": {},
   "source": [
    "## Punto C: Curve psicometriche - Effetto del rumore\n",
    "\n",
    "Seguendo la metodologia dell'articolo di Testolin et al. (2017), analizziamo come l'accuratezza degrada all'aumentare del rumore Gaussiano aggiunto alle immagini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4af4f1e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Funzione per aggiungere rumore Gaussiano\n",
    "def add_gaussian_noise(images, noise_std):\n",
    "    \"\"\"\n",
    "    Aggiunge rumore Gaussiano alle immagini.\n",
    "    \n",
    "    Args:\n",
    "        images: array di immagini\n",
    "        noise_std: deviazione standard del rumore\n",
    "    \n",
    "    Returns:\n",
    "        Immagini con rumore, clippate tra 0 e 1\n",
    "    \"\"\"\n",
    "    noise = np.random.normal(0, noise_std, images.shape)\n",
    "    noisy_images = images + noise\n",
    "    return np.clip(noisy_images, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5612fff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calcolo curve psicometriche per MLP...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mlp_best' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m noise_std \u001b[38;5;129;01min\u001b[39;00m noise_levels:\n\u001b[32m     12\u001b[39m     x_te_noisy = add_gaussian_noise(x_te_subset, noise_std)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     acc_mlp = \u001b[43mmlp_best\u001b[49m.score(x_te_noisy, y_te_subset)\n\u001b[32m     14\u001b[39m     accuracies_mlp.append(acc_mlp)\n\u001b[32m     15\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNoise std: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnoise_std\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m - MLP acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc_mlp\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'mlp_best' is not defined"
     ]
    }
   ],
   "source": [
    "# Test con diversi livelli di rumore\n",
    "noise_levels = np.arange(0, 0.5, 0.05)\n",
    "accuracies_mlp = []\n",
    "\n",
    "# Uso un subset del test set per velocizzare\n",
    "subset_size = 2000\n",
    "x_te_subset = x_te[:subset_size]\n",
    "y_te_subset = mnist_te_labels[:subset_size]\n",
    "\n",
    "print(\"Calcolo curve psicometriche per MLP...\")\n",
    "for noise_std in noise_levels:\n",
    "    x_te_noisy = add_gaussian_noise(x_te_subset, noise_std)\n",
    "    acc_mlp = mlp_best.score(x_te_noisy, y_te_subset)\n",
    "    accuracies_mlp.append(acc_mlp)\n",
    "    print(f\"Noise std: {noise_std:.3f} - MLP acc: {acc_mlp:.4f}\")\n",
    "\n",
    "# Test anche con CNN se disponibile\n",
    "best_cnn_config = max(cnn_results, key=lambda x: x['test_accuracy'])\n",
    "cnn_model = create_cnn_model(best_cnn_config['architecture'], best_cnn_config['learning_rate'])\n",
    "\n",
    "# Riaddestro il modello CNN migliore\n",
    "early_stopping = keras.callbacks.EarlyStopping(patience=5, min_delta=0.001, restore_best_weights=True, verbose=0)\n",
    "cnn_model.fit(x_tr_conv, mnist_tr_labels, validation_split=0.1, epochs=20, batch_size=128, \n",
    "              callbacks=[early_stopping], verbose=0)\n",
    "\n",
    "print(\"\\nCalcolo curve psicometriche per CNN...\")\n",
    "accuracies_cnn = []\n",
    "x_te_conv_subset = x_te_conv[:subset_size]\n",
    "\n",
    "for noise_std in noise_levels:\n",
    "    x_te_conv_noisy = add_gaussian_noise(x_te_conv_subset, noise_std)\n",
    "    test_loss, acc_cnn = cnn_model.evaluate(x_te_conv_noisy, y_te_subset, verbose=0)\n",
    "    accuracies_cnn.append(acc_cnn)\n",
    "    print(f\"Noise std: {noise_std:.3f} - CNN acc: {acc_cnn:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05a95ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizzazione curve psicometriche\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Grafico 1: Curve psicometriche\n",
    "ax1.plot(noise_levels, accuracies_mlp, 'o-', label='MLP', linewidth=3, markersize=8, color='blue')\n",
    "ax1.plot(noise_levels, accuracies_cnn, 's-', label='CNN', linewidth=3, markersize=8, color='red')\n",
    "\n",
    "ax1.set_xlabel('Deviazione standard del rumore', fontsize=12)\n",
    "ax1.set_ylabel('Accuratezza', fontsize=12)\n",
    "ax1.set_title('Curve Psicometriche - Robustezza al rumore', fontsize=14)\n",
    "ax1.legend(fontsize=12)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim(0, 1.05)\n",
    "\n",
    "# Evidenziare punti chiave\n",
    "for i, (noise, acc_mlp, acc_cnn) in enumerate(zip(noise_levels[::2], accuracies_mlp[::2], accuracies_cnn[::2])):\n",
    "    ax1.annotate(f'{acc_mlp:.2f}', (noise, acc_mlp), textcoords=\"offset points\", \n",
    "                xytext=(0,10), ha='center', fontsize=9, color='blue')\n",
    "    ax1.annotate(f'{acc_cnn:.2f}', (noise, acc_cnn), textcoords=\"offset points\", \n",
    "                xytext=(0,-15), ha='center', fontsize=9, color='red')\n",
    "\n",
    "# Grafico 2: Esempi di cifre con diversi livelli di rumore\n",
    "noise_examples = [0, 0.1, 0.2, 0.3, 0.4]\n",
    "digit_idx = 0\n",
    "\n",
    "axes_noise = []\n",
    "for i, noise in enumerate(noise_examples):\n",
    "    ax_sub = fig.add_subplot(2, 5, 6+i)\n",
    "    noisy_img = add_gaussian_noise(x_te[digit_idx:digit_idx+1], noise)[0]\n",
    "    ax_sub.imshow(noisy_img.reshape(28, 28), cmap='gray', vmin=0, vmax=1)\n",
    "    ax_sub.set_title(f'σ = {noise}', fontsize=10)\n",
    "    ax_sub.axis('off')\n",
    "\n",
    "plt.figtext(0.75, 0.02, f'Esempi di cifra {mnist_te_labels[digit_idx]} con diversi livelli di rumore', \n",
    "           ha='center', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8eafb6",
   "metadata": {},
   "source": [
    "## Punto D: Effetto della riduzione dei dati di training\n",
    "\n",
    "Analizziamo come le prestazioni degradano quando riduciamo drasticamente la quantità di dati di training disponibili."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2990972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test con riduzione dei dati di training...\n",
      "\n",
      "Training con 1% dei dati...\n",
      "Samples utilizzati: 596 / 60000\n",
      "Train acc: 0.9664, Test acc: 0.8687\n",
      "\n",
      "Training con 5% dei dati...\n",
      "Samples utilizzati: 2996 / 60000\n",
      "Train acc: 0.9907, Test acc: 0.9215\n",
      "\n",
      "Training con 10% dei dati...\n",
      "Samples utilizzati: 5996 / 60000\n",
      "Train acc: 0.9887, Test acc: 0.9409\n",
      "\n",
      "Training con 25% dei dati...\n",
      "Samples utilizzati: 14995 / 60000\n",
      "Train acc: 0.9944, Test acc: 0.9600\n",
      "\n",
      "Training con 50% dei dati...\n",
      "Samples utilizzati: 29997 / 60000\n",
      "Train acc: 0.9976, Test acc: 0.9706\n",
      "\n",
      "Training con 75% dei dati...\n",
      "Samples utilizzati: 44995 / 60000\n",
      "Train acc: 0.9975, Test acc: 0.9761\n",
      "\n",
      "Training con 100% dei dati...\n",
      "Samples utilizzati: 60000 / 60000\n",
      "Train acc: 0.9972, Test acc: 0.9783\n"
     ]
    }
   ],
   "source": [
    "# Test con diverse percentuali di dati di training\n",
    "train_percentages = [1, 5, 10, 25, 50, 75, 100]\n",
    "results_data_reduction = []\n",
    "\n",
    "print(\"Test con riduzione dei dati di training...\")\n",
    "for percentage in train_percentages:\n",
    "    print(f\"\\nTraining con {percentage}% dei dati...\")\n",
    "    \n",
    "    # Campionamento stratificato per mantenere bilanciamento classi\n",
    "    indices = []\n",
    "    for digit in range(10):\n",
    "        digit_indices = np.where(mnist_tr_labels == digit)[0]\n",
    "        n_digit_samples = int(len(digit_indices) * percentage / 100)\n",
    "        if n_digit_samples > 0:\n",
    "            selected_indices = np.random.choice(digit_indices, n_digit_samples, replace=False)\n",
    "            indices.extend(selected_indices)\n",
    "    \n",
    "    indices = np.array(indices)\n",
    "    x_tr_reduced = x_tr[indices]\n",
    "    y_tr_reduced = mnist_tr_labels[indices]\n",
    "    \n",
    "    print(f\"Samples utilizzati: {len(indices)} su {len(x_tr)}\")\n",
    "    \n",
    "    # Training MLP\n",
    "    mlp_reduced = MLPClassifier(\n",
    "        hidden_layer_sizes=(100, 100),\n",
    "        max_iter=100,\n",
    "        random_state=42,\n",
    "        early_stopping=True,\n",
    "        validation_fraction=0.1 if len(indices) > 100 else 0.2\n",
    "    )\n",
    "    \n",
    "    start_time = time.time()\n",
    "    mlp_reduced.fit(x_tr_reduced, y_tr_reduced)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    train_acc = mlp_reduced.score(x_tr_reduced, y_tr_reduced)\n",
    "    test_acc = mlp_reduced.score(x_te, mnist_te_labels)\n",
    "    \n",
    "    results_data_reduction.append({\n",
    "        'percentage': percentage,\n",
    "        'n_samples': len(indices),\n",
    "        'train_accuracy': train_acc,\n",
    "        'test_accuracy': test_acc,\n",
    "        'overfitting': train_acc - test_acc,\n",
    "        'training_time': training_time\n",
    "    })\n",
    "    \n",
    "    print(f\"Train acc: {train_acc:.4f}, Test acc: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbece1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizzazione effetto riduzione dati\n",
    "df_reduction = pd.DataFrame(results_data_reduction)\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Grafico 1: Accuratezza vs percentuale dati\n",
    "ax1.plot(df_reduction['percentage'], df_reduction['test_accuracy'], 'o-', \n",
    "        linewidth=3, markersize=10, color='darkblue', label='Test')\n",
    "ax1.plot(df_reduction['percentage'], df_reduction['train_accuracy'], 's-', \n",
    "        linewidth=3, markersize=10, color='lightblue', label='Train')\n",
    "ax1.set_xlabel('Percentuale di dati di training utilizzati (%)')\n",
    "ax1.set_ylabel('Accuratezza')\n",
    "ax1.set_title('Effetto della riduzione dei dati di training')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Evidenzio il punto al 10%\n",
    "idx_10 = df_reduction[df_reduction['percentage'] == 10].index[0]\n",
    "ax1.scatter(10, df_reduction.loc[idx_10, 'test_accuracy'], \n",
    "          s=200, color='red', zorder=5)\n",
    "ax1.annotate(f\"10%: {df_reduction.loc[idx_10, 'test_accuracy']:.3f}\", \n",
    "           xy=(10, df_reduction.loc[idx_10, 'test_accuracy']),\n",
    "           xytext=(20, df_reduction.loc[idx_10, 'test_accuracy'] - 0.05),\n",
    "           arrowprops=dict(arrowstyle='->', color='red'),\n",
    "           fontsize=11)\n",
    "\n",
    "# Grafico 2: Overfitting vs dimensione dataset\n",
    "ax2.plot(df_reduction['percentage'], df_reduction['overfitting'], 'o-', \n",
    "        linewidth=3, markersize=10, color='purple')\n",
    "ax2.set_xlabel('Percentuale di dati (%)')\n",
    "ax2.set_ylabel('Overfitting (Train - Test)')\n",
    "ax2.set_title('Overfitting vs Dimensione dataset')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Grafico 3: Tempo vs dimensione dataset\n",
    "ax3.plot(df_reduction['n_samples'], df_reduction['training_time'], 'o-', \n",
    "        linewidth=3, markersize=10, color='green')\n",
    "ax3.set_xlabel('Numero di campioni')\n",
    "ax3.set_ylabel('Tempo di training (s)')\n",
    "ax3.set_title('Tempo di training vs Dimensione dataset')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Grafico 4: Efficienza (acc/tempo) vs dimensione\n",
    "efficiency = df_reduction['test_accuracy'] / df_reduction['training_time']\n",
    "ax4.plot(df_reduction['percentage'], efficiency, 'o-', \n",
    "        linewidth=3, markersize=10, color='orange')\n",
    "ax4.set_xlabel('Percentuale di dati (%)')\n",
    "ax4.set_ylabel('Efficienza (Accuratezza / Tempo)')\n",
    "ax4.set_title('Efficienza vs Dimensione dataset')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaeed67a",
   "metadata": {},
   "source": [
    "## Punto E: Training con rumore per migliorare la robustezza\n",
    "\n",
    "Verifichiamo se l'aggiunta di rumore durante il training può migliorare le prestazioni su dati di test rumorosi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870cbfa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training modelli con rumore nei dati di training...\n",
      "\n",
      "Training con rumore std = 0\n",
      "Accuratezza su test set pulito: 0.9803\n",
      "Tempo di training: 21.3s\n",
      "\n",
      "Training con rumore std = 0.05\n",
      "Accuratezza su test set pulito: 0.9760\n",
      "Tempo di training: 22.1s\n",
      "\n",
      "Training con rumore std = 0.1\n",
      "Accuratezza su test set pulito: 0.9688\n",
      "Tempo di training: 10.5s\n",
      "\n",
      "Training con rumore std = 0.15\n",
      "Accuratezza su test set pulito: 0.9720\n",
      "Tempo di training: 17.8s\n",
      "\n",
      "Training con rumore std = 0.2\n",
      "Accuratezza su test set pulito: 0.9622\n",
      "Tempo di training: 15.7s\n"
     ]
    }
   ],
   "source": [
    "# Training di modelli con diversi livelli di rumore nel training set\n",
    "training_noise_levels = [0, 0.05, 0.1, 0.15, 0.2]\n",
    "models_with_noise = {}\n",
    "\n",
    "print(\"Training modelli con rumore nei dati di training...\")\n",
    "for train_noise in training_noise_levels:\n",
    "    print(f\"\\nTraining con rumore std = {train_noise}\")\n",
    "    \n",
    "    # Aggiungo rumore ai dati di training\n",
    "    if train_noise > 0:\n",
    "        x_tr_noisy = add_gaussian_noise(x_tr, train_noise)\n",
    "    else:\n",
    "        x_tr_noisy = x_tr\n",
    "    \n",
    "    # Training MLP\n",
    "    mlp_noise = MLPClassifier(\n",
    "        hidden_layer_sizes=(100, 100),\n",
    "        max_iter=100,\n",
    "        random_state=42,\n",
    "        early_stopping=True,\n",
    "        validation_fraction=0.1\n",
    "    )\n",
    "    \n",
    "    start_time = time.time()\n",
    "    mlp_noise.fit(x_tr_noisy, mnist_tr_labels)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    models_with_noise[train_noise] = mlp_noise\n",
    "    \n",
    "    # Test su dati puliti\n",
    "    clean_acc = mlp_noise.score(x_te, mnist_te_labels)\n",
    "    print(f\"Accuratezza su test set pulito: {clean_acc:.4f}\")\n",
    "    print(f\"Tempo di training: {training_time:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badae218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test dei modelli su dati rumorosi...\n",
      "Training noise 0: AUC = 0.290\n",
      "Training noise 0.05: AUC = 0.279\n",
      "Training noise 0.1: AUC = 0.313\n",
      "Training noise 0.15: AUC = 0.326\n",
      "Training noise 0.2: AUC = 0.330\n"
     ]
    }
   ],
   "source": [
    "# Test dei modelli su diversi livelli di rumore nel test set\n",
    "test_noise_levels = np.arange(0, 0.4, 0.05)\n",
    "results_noise_training = {}\n",
    "\n",
    "print(\"\\nTest dei modelli su dati rumorosi...\")\n",
    "for train_noise, model in models_with_noise.items():\n",
    "    accuracies = []\n",
    "    \n",
    "    for test_noise in test_noise_levels:\n",
    "        x_te_noisy = add_gaussian_noise(x_te_subset, test_noise)\n",
    "        acc = model.score(x_te_noisy, y_te_subset)\n",
    "        accuracies.append(acc)\n",
    "    \n",
    "    results_noise_training[train_noise] = accuracies\n",
    "    print(f\"Training noise {train_noise}: AUC = {np.trapz(accuracies, test_noise_levels):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf75176a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizzazione curve psicometriche con diversi livelli di rumore nel training\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(training_noise_levels)))\n",
    "\n",
    "# Grafico 1: Curve psicometriche\n",
    "for i, (train_noise, accuracies) in enumerate(results_noise_training.items()):\n",
    "    ax1.plot(test_noise_levels, accuracies, 'o-', \n",
    "           label=f'Training noise σ = {train_noise}',\n",
    "           color=colors[i], linewidth=2, markersize=6)\n",
    "\n",
    "ax1.set_xlabel('Deviazione standard del rumore (test)', fontsize=12)\n",
    "ax1.set_ylabel('Accuratezza', fontsize=12)\n",
    "ax1.set_title('Effetto del rumore nel training sulla robustezza', fontsize=14)\n",
    "ax1.legend(loc='upper right')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim(0, 1.05)\n",
    "\n",
    "# Grafico 2: Analisi quantitativa del miglioramento\n",
    "auc_scores = {}\n",
    "for train_noise, accuracies in results_noise_training.items():\n",
    "    auc = np.trapz(accuracies, test_noise_levels)\n",
    "    auc_scores[train_noise] = auc\n",
    "\n",
    "train_noises = list(auc_scores.keys())\n",
    "aucs = list(auc_scores.values())\n",
    "\n",
    "ax2.plot(train_noises, aucs, 'o-', linewidth=3, markersize=10, color='darkred')\n",
    "ax2.set_xlabel('Rumore nel training (σ)', fontsize=12)\n",
    "ax2.set_ylabel('AUC (Area Under Curve)', fontsize=12)\n",
    "ax2.set_title('Area sotto la curva vs Rumore nel training', fontsize=14)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Identifico il miglior livello\n",
    "best_noise = max(auc_scores, key=auc_scores.get)\n",
    "best_auc = auc_scores[best_noise]\n",
    "ax2.scatter(best_noise, best_auc, s=200, color='gold', zorder=5)\n",
    "ax2.annotate(f'Ottimo: σ={best_noise}\\nAUC={best_auc:.3f}', \n",
    "           xy=(best_noise, best_auc),\n",
    "           xytext=(best_noise + 0.05, best_auc - 0.5),\n",
    "           arrowprops=dict(arrowstyle='->', color='gold'),\n",
    "           fontsize=11, bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nMiglior livello di rumore nel training: σ = {best_noise}\")\n",
    "print(f\"Miglioramento rispetto al modello senza rumore: {(best_auc - auc_scores[0])/auc_scores[0]*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d111d5",
   "metadata": {},
   "source": [
    "## Punto Bonus: Estensione con FashionMNIST\n",
    "\n",
    "Replichiamo alcuni degli esperimenti precedenti utilizzando il dataset FashionMNIST, che presenta maggiore complessità."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f815534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricamento FashionMNIST...\n"
     ]
    }
   ],
   "source": [
    "# Caricamento FashionMNIST\n",
    "print(\"Caricamento FashionMNIST...\")\n",
    "fashion_tr = FashionMNIST(root=\"./data\", train=True, download=True)\n",
    "fashion_te = FashionMNIST(root=\"./data\", train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bed0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FashionMNIST caricato: 60000 train, 10000 test\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing FashionMNIST\n",
    "fashion_tr_data, fashion_tr_labels = fashion_tr.data.numpy(), fashion_tr.targets.numpy()\n",
    "fashion_te_data, fashion_te_labels = fashion_te.data.numpy(), fashion_te.targets.numpy()\n",
    "\n",
    "x_fashion_tr = fashion_tr_data.reshape(60000, 28 * 28) / 255.0\n",
    "x_fashion_te = fashion_te_data.reshape(10000, 28 * 28) / 255.0\n",
    "\n",
    "# Nomi delle classi\n",
    "fashion_classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "                  'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "print(f\"FashionMNIST caricato: {x_fashion_tr.shape[0]} train, {x_fashion_te.shape[0]} test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232d1f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizzazione esempi FashionMNIST\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(10):\n",
    "    idx = np.where(fashion_tr_labels == i)[0][0]\n",
    "    axes[i].imshow(fashion_tr_data[idx], cmap='gray')\n",
    "    axes[i].set_title(f'{i}: {fashion_classes[i]}', fontsize=12)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Esempi dal dataset FashionMNIST', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ad4cde",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_mlp_config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Training MLP su FashionMNIST con stessa architettura ottimale\u001b[39;00m\n\u001b[32m      2\u001b[39m mlp_fashion = MLPClassifier(\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     hidden_layer_sizes=\u001b[43mbest_mlp_config\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mhidden_layers\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m      4\u001b[39m     learning_rate_init=best_mlp_config[\u001b[33m'\u001b[39m\u001b[33mlearning_rate\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m      5\u001b[39m     max_iter=\u001b[32m100\u001b[39m,\n\u001b[32m      6\u001b[39m     random_state=\u001b[32m42\u001b[39m,\n\u001b[32m      7\u001b[39m     early_stopping=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m      8\u001b[39m     validation_fraction=\u001b[32m0.1\u001b[39m\n\u001b[32m      9\u001b[39m )\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining MLP su FashionMNIST con architettura: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_mlp_config[\u001b[33m'\u001b[39m\u001b[33mconfig_name\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m start_time = time.time()\n",
      "\u001b[31mNameError\u001b[39m: name 'best_mlp_config' is not defined"
     ]
    }
   ],
   "source": [
    "# Training MLP su FashionMNIST con stessa architettura ottimale\n",
    "mlp_fashion = MLPClassifier(\n",
    "    hidden_layer_sizes=best_mlp_config['hidden_layers'],\n",
    "    learning_rate_init=best_mlp_config['learning_rate'],\n",
    "    max_iter=100,\n",
    "    random_state=42,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.1\n",
    ")\n",
    "\n",
    "print(f\"Training MLP su FashionMNIST con architettura: {best_mlp_config['config_name']}\")\n",
    "start_time = time.time()\n",
    "mlp_fashion.fit(x_fashion_tr, fashion_tr_labels)\n",
    "fashion_training_time = time.time() - start_time\n",
    "\n",
    "fashion_train_acc = mlp_fashion.score(x_fashion_tr, fashion_tr_labels)\n",
    "fashion_test_acc = mlp_fashion.score(x_fashion_te, fashion_te_labels)\n",
    "\n",
    "print(f\"Training time: {fashion_training_time:.1f}s\")\n",
    "print(f\"Train accuracy: {fashion_train_acc:.4f}\")\n",
    "print(f\"Test accuracy: {fashion_test_acc:.4f}\")\n",
    "print(f\"Overfitting: {fashion_train_acc - fashion_test_acc:+.4f}\")\n",
    "\n",
    "# Confronto con MNIST\n",
    "mnist_test_acc = mlp_best.score(x_te, mnist_te_labels)\n",
    "print(f\"\\nConfronto con MNIST:\")\n",
    "print(f\"MNIST test accuracy: {mnist_test_acc:.4f}\")\n",
    "print(f\"FashionMNIST test accuracy: {fashion_test_acc:.4f}\")\n",
    "print(f\"Differenza: {mnist_test_acc - fashion_test_acc:+.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83d7bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curve psicometriche comparative MNIST vs FashionMNIST\n",
    "noise_levels_comp = np.arange(0, 0.3, 0.05)\n",
    "acc_mnist = []\n",
    "acc_fashion = []\n",
    "\n",
    "# Subset per velocità\n",
    "x_fashion_te_subset = x_fashion_te[:2000]\n",
    "y_fashion_te_subset = fashion_te_labels[:2000]\n",
    "\n",
    "print(\"Calcolo curve psicometriche comparative...\")\n",
    "for noise_std in noise_levels_comp:\n",
    "    # MNIST\n",
    "    x_noisy_mnist = add_gaussian_noise(x_te_subset, noise_std)\n",
    "    acc_mnist.append(mlp_best.score(x_noisy_mnist, y_te_subset))\n",
    "    \n",
    "    # FashionMNIST\n",
    "    x_noisy_fashion = add_gaussian_noise(x_fashion_te_subset, noise_std)\n",
    "    acc_fashion.append(mlp_fashion.score(x_noisy_fashion, y_fashion_te_subset))\n",
    "    \n",
    "    print(f\"Noise {noise_std:.2f}: MNIST {acc_mnist[-1]:.3f}, Fashion {acc_fashion[-1]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e5eab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizzazione comparativa finale\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Grafico 1: Curve psicometriche comparative\n",
    "ax1.plot(noise_levels_comp, acc_mnist, 'o-', label='MNIST', \n",
    "         linewidth=3, markersize=8, color='blue')\n",
    "ax1.plot(noise_levels_comp, acc_fashion, 's-', label='FashionMNIST', \n",
    "         linewidth=3, markersize=8, color='red')\n",
    "ax1.set_xlabel('Deviazione standard del rumore', fontsize=12)\n",
    "ax1.set_ylabel('Accuratezza', fontsize=12)\n",
    "ax1.set_title('Confronto robustezza al rumore:\\nMNIST vs FashionMNIST', fontsize=14)\n",
    "ax1.legend(fontsize=12)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim(0, 1.05)\n",
    "\n",
    "# Grafico 2: Matrice di confusione FashionMNIST\n",
    "y_pred_fashion = mlp_fashion.predict(x_fashion_te)\n",
    "cm_fashion = metrics.confusion_matrix(fashion_te_labels, y_pred_fashion)\n",
    "\n",
    "im = ax2.imshow(cm_fashion, cmap='Blues')\n",
    "ax2.set_xticks(range(10))\n",
    "ax2.set_yticks(range(10))\n",
    "ax2.set_xticklabels([f'{i}' for i in range(10)])\n",
    "ax2.set_yticklabels([f'{i}: {fashion_classes[i][:7]}' for i in range(10)], fontsize=10)\n",
    "ax2.set_xlabel('Predetto', fontsize=12)\n",
    "ax2.set_ylabel('Vero', fontsize=12)\n",
    "ax2.set_title('Matrice di Confusione\\nFashionMNIST', fontsize=14)\n",
    "\n",
    "# Grafico 3: Confronto accuratezze per classe\n",
    "fashion_class_accs = []\n",
    "mnist_class_accs = []\n",
    "\n",
    "for digit in range(10):\n",
    "    # FashionMNIST\n",
    "    mask_f = fashion_te_labels == digit\n",
    "    acc_f = np.sum((y_pred_fashion == fashion_te_labels) & mask_f) / np.sum(mask_f)\n",
    "    fashion_class_accs.append(acc_f)\n",
    "    \n",
    "    # MNIST\n",
    "    mask_m = mnist_te_labels == digit\n",
    "    acc_m = np.sum((y_pred == mnist_te_labels) & mask_m) / np.sum(mask_m)\n",
    "    mnist_class_accs.append(acc_m)\n",
    "\n",
    "x_pos = np.arange(10)\n",
    "width = 0.35\n",
    "\n",
    "ax3.bar(x_pos - width/2, mnist_class_accs, width, label='MNIST', alpha=0.8, color='blue')\n",
    "ax3.bar(x_pos + width/2, fashion_class_accs, width, label='FashionMNIST', alpha=0.8, color='red')\n",
    "ax3.set_xlabel('Classe', fontsize=12)\n",
    "ax3.set_ylabel('Accuratezza per classe', fontsize=12)\n",
    "ax3.set_title('Accuratezza per classe:\\nMNIST vs FashionMNIST', fontsize=14)\n",
    "ax3.set_xticks(x_pos)\n",
    "ax3.set_xticklabels([f'{i}' for i in range(10)])\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Grafico 4: Confronto errori più frequenti FashionMNIST\n",
    "fashion_confusion_pairs = []\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        if i != j and cm_fashion[i, j] > 0:\n",
    "            fashion_confusion_pairs.append({\n",
    "                'true_class': fashion_classes[i],\n",
    "                'pred_class': fashion_classes[j],\n",
    "                'count': cm_fashion[i, j]\n",
    "            })\n",
    "\n",
    "df_fashion_confusion = pd.DataFrame(fashion_confusion_pairs)\n",
    "top_fashion_errors = df_fashion_confusion.nlargest(8, 'count')\n",
    "\n",
    "y_pos = np.arange(len(top_fashion_errors))\n",
    "ax4.barh(y_pos, top_fashion_errors['count'], color='coral', alpha=0.8)\n",
    "ax4.set_yticks(y_pos)\n",
    "ax4.set_yticklabels([f\"{row['true_class'][:6]} → {row['pred_class'][:6]}\" \n",
    "                    for _, row in top_fashion_errors.iterrows()], fontsize=10)\n",
    "ax4.set_xlabel('Numero di errori', fontsize=12)\n",
    "ax4.set_title('Top 8 errori più frequenti\\nFashionMNIST', fontsize=14)\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50a916e",
   "metadata": {},
   "source": [
    "## Conclusioni\n",
    "\n",
    "### Riepilogo dei risultati principali:\n",
    "\n",
    "[risultati da implementare]\n",
    "\n",
    "1. **Effetto degli iperparametri (Punto A):**\n",
    "   - [analisi basata sui risultati numerici]\n",
    "\n",
    "2. **Cifre più difficili (Punto B):**\n",
    "   - [analisi pattern errori specifici]\n",
    "\n",
    "3. **Robustezza al rumore (Punto C):**\n",
    "   - [confronto degradazione MLP vs CNN]\n",
    "\n",
    "4. **Effetto dei dati di training (Punto D):**\n",
    "   - [analisi prestazioni con dataset ridotto]\n",
    "\n",
    "5. **Training con rumore (Punto E):**\n",
    "   - [valutazione miglioramenti robustezza]\n",
    "\n",
    "6. **FashionMNIST (Bonus):**\n",
    "   - [confronto complessità dataset]\n",
    "\n",
    "### Implicazioni pratiche:\n",
    "\n",
    "[raccomandazioni basate sui risultati]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c4f72b",
   "metadata": {
    "lines_to_next_cell": 3
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RIEPILOGO FINALE DEL PROGETTO\n",
      "============================================================\n",
      "\n",
      "Punto A - Analisi Iperparametri:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mlp_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m60\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mPunto A - Analisi Iperparametri:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  • Esperimenti MLP: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[43mmlp_results\u001b[49m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  • Esperimenti CNN: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(cnn_results)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  • Miglior MLP: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_mlp_config[\u001b[33m'\u001b[39m\u001b[33mconfig_name\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m -> Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_mlp_config[\u001b[33m'\u001b[39m\u001b[33mtest_accuracy\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'mlp_results' is not defined"
     ]
    }
   ],
   "source": [
    "# Statistiche finali del progetto\n",
    "print(\"=\"*60)\n",
    "print(\"RIEPILOGO FINALE DEL PROGETTO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nPunto A - Analisi Iperparametri:\")\n",
    "print(f\"  • Esperimenti MLP: {len(mlp_results)}\")\n",
    "print(f\"  • Esperimenti CNN: {len(cnn_results)}\")\n",
    "print(f\"  • Miglior MLP: {best_mlp_config['config_name']} -> Acc: {best_mlp_config['test_accuracy']:.4f}\")\n",
    "print(f\"  • Miglior CNN: {best_cnn_config['config_name']} -> Acc: {best_cnn_config['test_accuracy']:.4f}\")\n",
    "\n",
    "print(f\"\\nPunto B - Analisi Errori:\")\n",
    "print(f\"  • Cifra più difficile: {df_errors_sorted.iloc[0]['digit']} (Error rate: {df_errors_sorted.iloc[0]['error_rate']:.3f})\")\n",
    "print(f\"  • Cifra più facile: {df_errors_sorted.iloc[-1]['digit']} (Error rate: {df_errors_sorted.iloc[-1]['error_rate']:.3f})\")\n",
    "print(f\"  • Confusione più frequente: {df_confusion_sorted.iloc[0]['true_digit']} → {df_confusion_sorted.iloc[0]['predicted_digit']} ({df_confusion_sorted.iloc[0]['count']} errori)\")\n",
    "\n",
    "print(f\"\\nPunto C - Robustezza al Rumore:\")\n",
    "print(f\"  • Livelli di rumore testati: {len(noise_levels)}\")\n",
    "print(f\"  • Accuratezza senza rumore MLP: {accuracies_mlp[0]:.4f}\")\n",
    "print(f\"  • Accuratezza senza rumore CNN: {accuracies_cnn[0]:.4f}\")\n",
    "\n",
    "print(f\"\\nPunto D - Riduzione Dati:\")\n",
    "print(f\"  • Accuratezza con 100% dati: {df_reduction[df_reduction['percentage']==100]['test_accuracy'].iloc[0]:.4f}\")\n",
    "print(f\"  • Accuratezza con 10% dati: {df_reduction[df_reduction['percentage']==10]['test_accuracy'].iloc[0]:.4f}\")\n",
    "\n",
    "print(f\"\\nPunto E - Training con Rumore:\")\n",
    "print(f\"  • Livelli testati: {len(training_noise_levels)}\")\n",
    "print(f\"  • Miglior configurazione: σ = {best_noise}\")\n",
    "\n",
    "print(f\"\\nBonus - FashionMNIST:\")\n",
    "print(f\"  • Accuratezza MNIST: {mnist_test_acc:.4f}\")\n",
    "print(f\"  • Accuratezza FashionMNIST: {fashion_test_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Mini Progetto IA",
   "language": "python",
   "name": "mini-progetto-ia"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
