{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Mini Progetto Intelligenza Artificiale - Riconoscimento cifre manoscritte\n",
    "\n",
    "\n",
    "\n",
    " **Nome:** Giulio\n",
    "\n",
    " **Cognome:** Bottacin\n",
    "\n",
    " **Matricola:** 2042340\n",
    "\n",
    " **Data consegna:** 5/6/2025\n",
    "\n",
    "\n",
    "\n",
    " ## Obiettivo\n",
    "\n",
    "\n",
    "\n",
    " In questo progetto esploreremo il riconoscimento di cifre manoscritte utilizzando il dataset MNIST, implementando simulazioni per studiare come diversi fattori influenzano le prestazioni dei modelli di deep learning. Analizzeremo in particolare l'impatto degli iperparametri, la robustezza al rumore e l'effetto della quantità di dati di training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Importazione delle librerie necessarie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from torchvision.datasets import MNIST, FashionMNIST\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurazione per riproducibilità\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Caricamento e preparazione del dataset MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricamento dataset MNIST...\n"
     ]
    }
   ],
   "source": [
    "# Caricamento dataset MNIST\n",
    "print(\"Caricamento dataset MNIST...\")\n",
    "mnist_tr = MNIST(root=\"./data\", train=True, download=True)\n",
    "mnist_te = MNIST(root=\"./data\", train=False, download=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset caricato: 60000 esempi di training, 10000 esempi di test\n",
      "Forma dati MLP: (60000, 784)\n",
      "Forma dati CNN: (60000, 28, 28, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Conversione in array numpy\n",
    "mnist_tr_data, mnist_tr_labels = mnist_tr.data.numpy(), mnist_tr.targets.numpy()\n",
    "mnist_te_data, mnist_te_labels = mnist_te.data.numpy(), mnist_te.targets.numpy()\n",
    "\n",
    "# Preprocessing per MLP (vettorizzazione e normalizzazione)\n",
    "x_tr = mnist_tr_data.reshape(60000, 28 * 28) / 255.0\n",
    "x_te = mnist_te_data.reshape(10000, 28 * 28) / 255.0\n",
    "\n",
    "# Preprocessing per CNN (mantenendo formato 2D)\n",
    "x_tr_conv = x_tr.reshape(-1, 28, 28, 1)\n",
    "x_te_conv = x_te.reshape(-1, 28, 28, 1)\n",
    "\n",
    "print(f\"Dataset caricato: {x_tr.shape[0]} esempi di training, {x_te.shape[0]} esempi di test\")\n",
    "print(f\"Forma dati MLP: {x_tr.shape}\")\n",
    "print(f\"Forma dati CNN: {x_tr_conv.shape}\")\n",
    "\n",
    "# Visualizzazione esempi del dataset\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 6))\n",
    "fig.suptitle('Dataset MNIST - Esempi per Cifra', fontsize=14)\n",
    "\n",
    "for digit in range(10):\n",
    "    idx = np.where(mnist_tr_labels == digit)[0][0]\n",
    "    ax = axes[digit//5, digit%5]\n",
    "    ax.imshow(mnist_tr_data[idx], cmap='gray')\n",
    "    ax.set_title(f'Cifra {digit}')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Punto A: Effetto degli iperparametri sulle prestazioni\n",
    "\n",
    "\n",
    "\n",
    " Analizziamo sistematicamente come variano le prestazioni dei modelli MLP e CNN al variare degli iperparametri chiave.\n",
    "\n",
    " Confronteremo 18 configurazioni MLP e 6 configurazioni CNN per un totale di 24 esperimenti mirati."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Configurazione esperimenti sistematici\n",
    "\n",
    "\n",
    "\n",
    " ***MLP (18 esperimenti):***\n",
    "\n",
    " - **Neuroni per strato**: *50, 100, 250* per testare la copertura da reti piccole a medio-grandi\n",
    "\n",
    " - **Numero layers**: *1 vs 2* strati nascosti per fare il confronto profondità vs larghezza\n",
    "\n",
    " - **Learning rate**: *0.001, 0.01, 0.1*\n",
    "\n",
    "\n",
    "\n",
    " ***CNN (6 esperimenti):***\n",
    "\n",
    " - **Filtri**: *32*, standard per MNIST, computazionalmente efficiente\n",
    "\n",
    " - **Architettura**: *baseline vs extended* per fare il confronto sulla complessità\n",
    "\n",
    " - **Learning rate**: *0.001, 0.01, 0.1*\n",
    "\n",
    "\n",
    "\n",
    " Per entrambi i modelli si è scelto di utilizzare il solver **Adam**, ormai standard e più performante di SDG.\n",
    "\n",
    " Si è volutamente scelto di eseguire meno esperimenti sulle CNN in quanto richiedono tempi molto più lunghi di training rispetto alle MLP.\n",
    "\n",
    "\n",
    "\n",
    " #### Scelta dei parametri di training\n",
    "\n",
    "\n",
    "\n",
    " ***MLP:***\n",
    "\n",
    " - *max_iter = 100* è sufficiente per convergenza su MNIST basato su cifre manoscritte.\n",
    "\n",
    " - *early_stopping = True*, previene l'overfitting essenziale quando sono presenti molti parametri.\n",
    "\n",
    " - *validation_fraction = 0.1*, split standard 90/10.\n",
    "\n",
    " - *tol = 0.001* è una precisione ragionevole per classificazione.\n",
    "\n",
    " - *n_iter_no_change = 10* è un livello di pazienza adeguata per permettere oscillazioni temporanee.\n",
    "\n",
    "\n",
    "\n",
    " ***CNN:***\n",
    "\n",
    " - *epochs = 20* valore di compromesso per bilanciare velocità e convergenza, il valore è più basso delle MLP perchè le CNN tipicamente convergono più velocemente.\n",
    "\n",
    " - *batch_size = 128*, trade-off memoria/velocità ottimale per dataset size.\n",
    "\n",
    " - *validation_split = 0.1*, coerente con le scelte di MLP.\n",
    "\n",
    " - *patience = 5*, le CNN sono meno soggette a oscillazioni quindi è stato scelto un livello di pazienza minore.\n",
    "\n",
    " - *min_delta = 0.001*, scelta la stessa precisione degli MLP per comparabilità diretta.\n",
    "\n",
    "\n",
    "\n",
    " Questa configurazione permette un confronto sistematico e bilanciato tra i due tipi di architetture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Funzioni helper per stampe risultati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stampa_header_esperimento(num_esp, totale, tipo_modello, config):\n",
    "    print(f\"\\n[{num_esp:2d}/{totale}] {tipo_modello}: {config}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "def stampa_risultati_esperimento(risultati):\n",
    "    print(f\"Accuracy Training: {risultati['train_accuracy']:.4f} | Accuracy Test: {risultati['test_accuracy']:.4f}\")\n",
    "    print(f\"Tempo: {risultati['training_time']:6.1f}s | Iterazioni: {risultati['iterations']:3d}\")\n",
    "    print(f\"Overfitting: {risultati['overfitting']:+.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Esperimenti MLP (16 configurazioni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INIZIO ESPERIMENTI MLP\n",
      "============================================================\n",
      "\n",
      "[ 1/18] MLP: 50n_1S_lr0.001\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9891 | Accuracy Test: 0.9707\n",
      "Tempo:    8.1s | Iterazioni:  24\n",
      "Overfitting: +0.0184\n",
      "\n",
      "[ 2/18] MLP: 50n_1S_lr0.01\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9844 | Accuracy Test: 0.9697\n",
      "Tempo:    4.3s | Iterazioni:  17\n",
      "Overfitting: +0.0147\n",
      "\n",
      "[ 3/18] MLP: 50n_1S_lr0.1\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9202 | Accuracy Test: 0.9123\n",
      "Tempo:    5.8s | Iterazioni:  20\n",
      "Overfitting: +0.0079\n",
      "\n",
      "[ 4/18] MLP: 50n_2S_lr0.001\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9905 | Accuracy Test: 0.9729\n",
      "Tempo:   10.0s | Iterazioni:  27\n",
      "Overfitting: +0.0176\n",
      "\n",
      "[ 5/18] MLP: 50n_2S_lr0.01\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9863 | Accuracy Test: 0.9695\n",
      "Tempo:    6.7s | Iterazioni:  19\n",
      "Overfitting: +0.0168\n",
      "\n",
      "[ 6/18] MLP: 50n_2S_lr0.1\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.8471 | Accuracy Test: 0.8467\n",
      "Tempo:    5.1s | Iterazioni:  16\n",
      "Overfitting: +0.0004\n",
      "\n",
      "[ 7/18] MLP: 100n_1S_lr0.001\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9971 | Accuracy Test: 0.9771\n",
      "Tempo:   12.0s | Iterazioni:  26\n",
      "Overfitting: +0.0201\n",
      "\n",
      "[ 8/18] MLP: 100n_1S_lr0.01\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9909 | Accuracy Test: 0.9734\n",
      "Tempo:    8.8s | Iterazioni:  19\n",
      "Overfitting: +0.0175\n",
      "\n",
      "[ 9/18] MLP: 100n_1S_lr0.1\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9168 | Accuracy Test: 0.9148\n",
      "Tempo:    5.9s | Iterazioni:  13\n",
      "Overfitting: +0.0020\n",
      "\n",
      "[10/18] MLP: 100n_2S_lr0.001\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9967 | Accuracy Test: 0.9786\n",
      "Tempo:   11.4s | Iterazioni:  20\n",
      "Overfitting: +0.0181\n",
      "\n",
      "[11/18] MLP: 100n_2S_lr0.01\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9934 | Accuracy Test: 0.9739\n",
      "Tempo:   20.2s | Iterazioni:  43\n",
      "Overfitting: +0.0195\n",
      "\n",
      "[12/18] MLP: 100n_2S_lr0.1\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.8248 | Accuracy Test: 0.8212\n",
      "Tempo:   10.6s | Iterazioni:  14\n",
      "Overfitting: +0.0036\n",
      "\n",
      "[13/18] MLP: 250n_1S_lr0.001\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9981 | Accuracy Test: 0.9810\n",
      "Tempo:   22.2s | Iterazioni:  24\n",
      "Overfitting: +0.0171\n",
      "\n",
      "[14/18] MLP: 250n_1S_lr0.01\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9913 | Accuracy Test: 0.9752\n",
      "Tempo:   22.9s | Iterazioni:  25\n",
      "Overfitting: +0.0161\n",
      "\n",
      "[15/18] MLP: 250n_1S_lr0.1\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9160 | Accuracy Test: 0.9147\n",
      "Tempo:   14.3s | Iterazioni:  15\n",
      "Overfitting: +0.0013\n",
      "\n",
      "[16/18] MLP: 250n_2S_lr0.001\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9965 | Accuracy Test: 0.9788\n",
      "Tempo:   28.4s | Iterazioni:  19\n",
      "Overfitting: +0.0177\n",
      "\n",
      "[17/18] MLP: 250n_2S_lr0.01\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9924 | Accuracy Test: 0.9776\n",
      "Tempo:   37.0s | Iterazioni:  31\n",
      "Overfitting: +0.0148\n",
      "\n",
      "[18/18] MLP: 250n_2S_lr0.1\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.7662 | Accuracy Test: 0.7577\n",
      "Tempo:   29.4s | Iterazioni:  27\n",
      "Overfitting: +0.0085\n",
      "\n",
      "ESPERIMENTI MLP COMPLETATI\n"
     ]
    }
   ],
   "source": [
    "neuroni_lista = [50, 100, 250] # numero di neuroni per strato\n",
    "strati_lista = [1, 2]  # numero di strati nascosti\n",
    "learning_rates = [0.001, 0.01, 0.1] # learning rates \n",
    "\n",
    "risultati_mlp = []\n",
    "contatore_esperimenti = 0\n",
    "esperimenti_totali = len(neuroni_lista) * len(strati_lista) * len(learning_rates)\n",
    "\n",
    "print(\"INIZIO ESPERIMENTI MLP\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for neuroni in neuroni_lista:\n",
    "    for n_strati in strati_lista:\n",
    "        for lr in learning_rates:\n",
    "            contatore_esperimenti += 1\n",
    "            \n",
    "            # Configurazione architettura\n",
    "            if n_strati == 1:\n",
    "                strati_nascosti = (neuroni,)\n",
    "                nome_config = f\"{neuroni}n_1S_lr{lr}\"\n",
    "            else:\n",
    "                strati_nascosti = (neuroni, neuroni)\n",
    "                nome_config = f\"{neuroni}n_2S_lr{lr}\"\n",
    "            \n",
    "            stampa_header_esperimento(contatore_esperimenti, esperimenti_totali, \"MLP\", nome_config)\n",
    "            \n",
    "            # Training MLP\n",
    "            mlp = MLPClassifier(\n",
    "                hidden_layer_sizes=strati_nascosti,\n",
    "                learning_rate_init=lr,\n",
    "                max_iter=100,\n",
    "                early_stopping=True,\n",
    "                validation_fraction=0.1,\n",
    "                tol=0.001,\n",
    "                n_iter_no_change=10,\n",
    "                random_state=42\n",
    "            )\n",
    "            \n",
    "            tempo_inizio = time.time()\n",
    "            mlp.fit(x_tr, mnist_tr_labels)\n",
    "            tempo_training = time.time() - tempo_inizio\n",
    "            \n",
    "            acc_train = mlp.score(x_tr, mnist_tr_labels)\n",
    "            acc_test = mlp.score(x_te, mnist_te_labels)\n",
    "            \n",
    "            risultati = {\n",
    "                'tipo_modello': 'MLP',\n",
    "                'nome_config': nome_config,\n",
    "                'neuroni': neuroni,\n",
    "                'n_strati': n_strati,\n",
    "                'learning_rate': lr,\n",
    "                'strati_nascosti': strati_nascosti,\n",
    "                'train_accuracy': acc_train,\n",
    "                'test_accuracy': acc_test,\n",
    "                'overfitting': acc_train - acc_test,\n",
    "                'training_time': tempo_training,\n",
    "                'iterations': mlp.n_iter_,\n",
    "                'loss_curve': mlp.loss_curve_ if hasattr(mlp, 'loss_curve_') else [],\n",
    "                'parametri_totali': sum([layer.size for layer in mlp.coefs_]) + sum([layer.size for layer in mlp.intercepts_])\n",
    "            }\n",
    "            \n",
    "            risultati_mlp.append(risultati)\n",
    "            stampa_risultati_esperimento(risultati)\n",
    "\n",
    "print(f\"\\nESPERIMENTI MLP COMPLETATI\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Funzioni helper per esperimenti CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crea_modello_cnn(tipo_architettura, learning_rate):\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    if tipo_architettura == 'baseline':\n",
    "        # Architettura baseline\n",
    "        model.add(keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)))\n",
    "        model.add(keras.layers.Flatten())\n",
    "        model.add(keras.layers.Dense(50, activation='relu'))\n",
    "        \n",
    "    elif tipo_architettura == 'extended':\n",
    "        # Architettura estesa con pooling e più strati\n",
    "        model.add(keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)))\n",
    "        model.add(keras.layers.MaxPooling2D(2,2))\n",
    "        model.add(keras.layers.Conv2D(64, (3,3), activation='relu'))\n",
    "        model.add(keras.layers.Flatten())\n",
    "        model.add(keras.layers.Dense(100, activation='relu'))\n",
    "    \n",
    "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "    \n",
    "    # Configurazione optimizer\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Esperimenti CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "INIZIO ESPERIMENTI CNN\n",
      "============================================================\n",
      "\n",
      "[ 1/6] CNN: CNN_baseline_lr0.001\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9902 | Accuracy Test: 0.9806\n",
      "Tempo:   64.7s | Iterazioni:   8\n",
      "Overfitting: +0.0096\n",
      "\n",
      "[ 2/6] CNN: CNN_baseline_lr0.01\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9818 | Accuracy Test: 0.9729\n",
      "Tempo:   44.8s | Iterazioni:   6\n",
      "Overfitting: +0.0089\n",
      "\n",
      "[ 3/6] CNN: CNN_baseline_lr0.1\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.1022 | Accuracy Test: 0.1010\n",
      "Tempo:   45.3s | Iterazioni:   6\n",
      "Overfitting: +0.0012\n",
      "\n",
      "[ 4/6] CNN: CNN_extended_lr0.001\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9933 | Accuracy Test: 0.9885\n",
      "Tempo:  119.7s | Iterazioni:   8\n",
      "Overfitting: +0.0048\n",
      "\n",
      "[ 5/6] CNN: CNN_extended_lr0.01\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9851 | Accuracy Test: 0.9820\n",
      "Tempo:   88.1s | Iterazioni:   6\n",
      "Overfitting: +0.0031\n",
      "\n",
      "[ 6/6] CNN: CNN_extended_lr0.1\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.1022 | Accuracy Test: 0.1010\n",
      "Tempo:   86.2s | Iterazioni:   6\n",
      "Overfitting: +0.0012\n",
      "\n",
      "ESPERIMENTI CNN COMPLETATI\n"
     ]
    }
   ],
   "source": [
    "architetture = ['baseline', 'extended']\n",
    "learning_rates_cnn = [0.001, 0.01, 0.1]\n",
    "\n",
    "risultati_cnn = []\n",
    "contatore_esperimenti_cnn = 0\n",
    "esperimenti_totali_cnn = len(architetture) * len(learning_rates_cnn)\n",
    "\n",
    "print(\"\\n\\nINIZIO ESPERIMENTI CNN\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for arch in architetture:\n",
    "    for lr in learning_rates_cnn:\n",
    "        contatore_esperimenti_cnn += 1\n",
    "        nome_config = f\"CNN_{arch}_lr{lr}\"\n",
    "        \n",
    "        stampa_header_esperimento(contatore_esperimenti_cnn, esperimenti_totali_cnn, \"CNN\", nome_config)\n",
    "        \n",
    "        # Creazione e training CNN\n",
    "        model = crea_modello_cnn(arch, lr)\n",
    "        \n",
    "        # Early stopping callback\n",
    "        early_stopping = keras.callbacks.EarlyStopping(\n",
    "            patience=5,\n",
    "            min_delta=0.001,\n",
    "            restore_best_weights=True,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        tempo_inizio = time.time()\n",
    "        history = model.fit(\n",
    "            x_tr_conv, mnist_tr_labels,\n",
    "            validation_split=0.1,\n",
    "            epochs=20,\n",
    "            batch_size=128,\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=0\n",
    "        )\n",
    "        tempo_training = time.time() - tempo_inizio\n",
    "        \n",
    "        # Valutazione\n",
    "        train_loss, acc_train = model.evaluate(x_tr_conv, mnist_tr_labels, verbose=0)\n",
    "        test_loss, acc_test = model.evaluate(x_te_conv, mnist_te_labels, verbose=0)\n",
    "        \n",
    "        risultati = {\n",
    "            'tipo_modello': 'CNN',\n",
    "            'nome_config': nome_config,\n",
    "            'architettura': arch,\n",
    "            'learning_rate': lr,\n",
    "            'train_accuracy': acc_train,\n",
    "            'test_accuracy': acc_test,\n",
    "            'overfitting': acc_train - acc_test,\n",
    "            'training_time': tempo_training,\n",
    "            'iterations': len(history.history['loss']),\n",
    "            'loss_curve': history.history['loss'],\n",
    "            'val_loss_curve': history.history['val_loss'],\n",
    "            'parametri_totali': model.count_params()\n",
    "        }\n",
    "        \n",
    "        risultati_cnn.append(risultati)\n",
    "        stampa_risultati_esperimento(risultati)\n",
    "\n",
    "print(f\"\\nESPERIMENTI CNN COMPLETATI\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Combinazione di tutti i risultati per le analisi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinazione risultati per analisi\n",
    "tutti_risultati = risultati_mlp + risultati_cnn\n",
    "df_risultati = pd.DataFrame(tutti_risultati)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Grafico 1: Effetto del Learning Rate sulle prestazioni MLP\n",
    "\n",
    "\n",
    "\n",
    " Questo grafico analizza l'impatto critico del learning rate sulla convergenza e stabilità del training per le reti MLP. Il learning rate controlla la dimensione dei passi durante l'ottimizzazione: valori troppo alti causano instabilità e divergenza, mentre valori troppo bassi rallentano eccessivamente la convergenza. L'analisi delle curve di loss e delle accuratezze finali permette di identificare il range ottimale per il dataset MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATI ANALISI LEARNING RATE:\n",
      "LR=0.001: Accuratezza=0.9765, Tempo=15.3s\n",
      "LR=0.01:  Accuratezza=0.9732, Tempo=16.6s\n",
      "LR=0.1:   Accuratezza=0.8612, Tempo=11.8s\n"
     ]
    }
   ],
   "source": [
    "# Preparazione dati per analisi learning rate\n",
    "dati_lr_001 = [r for r in risultati_mlp if r['learning_rate'] == 0.001]\n",
    "dati_lr_01 = [r for r in risultati_mlp if r['learning_rate'] == 0.01]\n",
    "dati_lr_1 = [r for r in risultati_mlp if r['learning_rate'] == 0.1]\n",
    "\n",
    "# Calcolo medie per ogni learning rate\n",
    "acc_lr_001 = np.mean([r['test_accuracy'] for r in dati_lr_001])\n",
    "acc_lr_01 = np.mean([r['test_accuracy'] for r in dati_lr_01])\n",
    "acc_lr_1 = np.mean([r['test_accuracy'] for r in dati_lr_1])\n",
    "\n",
    "tempo_lr_001 = np.mean([r['training_time'] for r in dati_lr_001])\n",
    "tempo_lr_01 = np.mean([r['training_time'] for r in dati_lr_01])\n",
    "tempo_lr_1 = np.mean([r['training_time'] for r in dati_lr_1])\n",
    "\n",
    "# Visualizzazione curve di loss rappresentative\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Subplot 1: Curve di loss\n",
    "for i, (dati_lr, colore, etichetta) in enumerate([(dati_lr_001, 'green', 'LR=0.001'), \n",
    "                                           (dati_lr_01, 'blue', 'LR=0.01'), \n",
    "                                           (dati_lr_1, 'red', 'LR=0.1')]):\n",
    "    if dati_lr and dati_lr[0]['loss_curve']:\n",
    "        curva_loss = dati_lr[0]['loss_curve']  # Primo esempio rappresentativo\n",
    "        ax1.plot(range(len(curva_loss)), curva_loss, color=colore, linewidth=2, label=etichetta)\n",
    "\n",
    "ax1.set_xlabel('Iterazioni')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Pattern di Convergenza per Learning Rate')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Subplot 2: Accuratezza vs Learning Rate\n",
    "learning_rates_plot = [0.001, 0.01, 0.1]\n",
    "accuratezze = [acc_lr_001, acc_lr_01, acc_lr_1]\n",
    "colori = ['green', 'blue', 'red']\n",
    "\n",
    "bars = ax2.bar(range(len(learning_rates_plot)), accuratezze, color=colori, alpha=0.7)\n",
    "ax2.set_xlabel('Learning Rate')\n",
    "ax2.set_ylabel('Accuratezza Test Media')\n",
    "ax2.set_title('Accuratezza Test per Learning Rate')\n",
    "ax2.set_xticks(range(len(learning_rates_plot)))\n",
    "ax2.set_xticklabels(['0.001', '0.01', '0.1'])\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Annotazioni valori\n",
    "for bar, acc in zip(bars, accuratezze):\n",
    "    height = bar.get_height()\n",
    "    ax2.annotate(f'{acc:.3f}', xy=(bar.get_x() + bar.get_width()/2, height),\n",
    "                xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"DATI ANALISI LEARNING RATE:\")\n",
    "print(f\"LR=0.001: Accuratezza={acc_lr_001:.4f}, Tempo={tempo_lr_001:.1f}s\")\n",
    "print(f\"LR=0.01:  Accuratezza={acc_lr_01:.4f}, Tempo={tempo_lr_01:.1f}s\") \n",
    "print(f\"LR=0.1:   Accuratezza={acc_lr_1:.4f}, Tempo={tempo_lr_1:.1f}s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Discussione del grafico e riflessione sui risultati\n",
    "\n",
    " I risultati mostrano chiaramente l'effetto critico del learning rate sulle prestazioni:\n",
    "\n",
    " - **LR = 0.001** raggiunge la migliore accuratezza media (97.65%) con convergenza stabile ma lenta\n",
    "\n",
    " - **LR = 0.01** mantiene prestazioni competitive (97.32%) con convergenza più rapida rappresentando il miglior compromesso velocità-accuratezza\n",
    "\n",
    " - **LR = 0.1** causa un drammatico crollo delle prestazioni (86.12%) indicando instabilità nell'ottimizzazione e possibili oscillazioni eccessive.\n",
    "\n",
    "\n",
    "\n",
    " Dal punto di vista tecnico, learning rate alti causano passi troppo grandi che fanno \"saltare\" oltre i minimi locali, mentre valori troppo bassi intrappolano l'ottimizzazione in plateau prolungati.\n",
    "\n",
    "\n",
    "\n",
    " Per applicazioni pratiche, si raccomanda l'uso di LR=0.01 come punto di partenza per MLP su MNIST, con possibile fine-tuning verso 0.001 se il tempo di training non è critico e si desidera massimizzare l'accuratezza finale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Grafico 2: Confronto Completo delle Architetture (Training vs Test)\n",
    "\n",
    " Questo grafico presenta un confronto esaustivo di tutte le 24 configurazioni testate, mostrando affiancate le accuratezze di training e test per identificare immediatamente pattern di overfitting.\n",
    "\n",
    " La visualizzazione simultanea di train e test accuracy permette di valutare sia le prestazioni massime raggiungibili che la capacità di generalizzazione di ogni configurazione, elemento fondamentale per la selezione del modello ottimale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFRONTO ARCHITETTURE:\n",
      "Miglior MLP: 250n_1S_lr0.001 - Accuratezza Test: 0.9810\n",
      "Miglior CNN: CNN_extended_lr0.001 - Accuratezza Test: 0.9885\n"
     ]
    }
   ],
   "source": [
    "# Selezione migliori configurazioni per evidenziazione\n",
    "migliore_mlp = max(risultati_mlp, key=lambda x: x['test_accuracy'])\n",
    "migliore_cnn = max(risultati_cnn, key=lambda x: x['test_accuracy'])\n",
    "\n",
    "# Preparazione dati per tutte le configurazioni\n",
    "nomi_config = [r['nome_config'] for r in tutti_risultati]\n",
    "acc_train_tutte = [r['train_accuracy'] for r in tutti_risultati]\n",
    "acc_test_tutte = [r['test_accuracy'] for r in tutti_risultati]\n",
    "tipi_modello = [r['tipo_modello'] for r in tutti_risultati]\n",
    "\n",
    "# Separazione indici MLP e CNN\n",
    "indici_mlp = [i for i, t in enumerate(tipi_modello) if t == 'MLP']\n",
    "indici_cnn = [i for i, t in enumerate(tipi_modello) if t == 'CNN']\n",
    "\n",
    "# Visualizzazione\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "# Posizioni delle barre\n",
    "x = np.arange(len(nomi_config))\n",
    "larghezza = 0.35\n",
    "\n",
    "# Barre per accuratezza training e test\n",
    "bars_train = ax.bar(x - larghezza/2, acc_train_tutte, larghezza, \n",
    "                   label='Accuratezza Training', alpha=0.8, color='lightcoral')\n",
    "bars_test = ax.bar(x + larghezza/2, acc_test_tutte, larghezza, \n",
    "                  label='Accuratezza Test', alpha=0.8, color='steelblue')\n",
    "\n",
    "# Colorazione diversa per MLP e CNN sui bordi\n",
    "for i in indici_mlp:\n",
    "    bars_train[i].set_edgecolor('darkred')\n",
    "    bars_test[i].set_edgecolor('darkblue')\n",
    "    bars_train[i].set_linewidth(1.5)\n",
    "    bars_test[i].set_linewidth(1.5)\n",
    "\n",
    "for i in indici_cnn:\n",
    "    bars_train[i].set_edgecolor('orange')\n",
    "    bars_test[i].set_edgecolor('green')\n",
    "    bars_train[i].set_linewidth(2)\n",
    "    bars_test[i].set_linewidth(2)\n",
    "\n",
    "ax.set_xlabel('Configurazione')\n",
    "ax.set_ylabel('Accuratezza')\n",
    "ax.set_title('Confronto Completo: Accuratezza Training vs Test per Tutte le Configurazioni')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(nomi_config, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Evidenziazione delle migliori configurazioni\n",
    "idx_migliore_mlp = tutti_risultati.index(migliore_mlp)\n",
    "idx_migliore_cnn = tutti_risultati.index(migliore_cnn)\n",
    "\n",
    "ax.annotate(f'Miglior MLP\\n{migliore_mlp[\"test_accuracy\"]:.4f}', \n",
    "           xy=(idx_migliore_mlp + larghezza/2, migliore_mlp['test_accuracy']),\n",
    "           xytext=(10, 20), textcoords='offset points',\n",
    "           bbox=dict(boxstyle='round,pad=0.3', facecolor='lightblue', alpha=0.7),\n",
    "           arrowprops=dict(arrowstyle='->', color='blue'))\n",
    "\n",
    "ax.annotate(f'Miglior CNN\\n{migliore_cnn[\"test_accuracy\"]:.4f}', \n",
    "           xy=(idx_migliore_cnn + larghezza/2, migliore_cnn['test_accuracy']),\n",
    "           xytext=(10, -30), textcoords='offset points',\n",
    "           bbox=dict(boxstyle='round,pad=0.3', facecolor='lightgreen', alpha=0.7),\n",
    "           arrowprops=dict(arrowstyle='->', color='green'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"CONFRONTO ARCHITETTURE:\")\n",
    "print(f\"Miglior MLP: {migliore_mlp['nome_config']} - Accuratezza Test: {migliore_mlp['test_accuracy']:.4f}\")\n",
    "print(f\"Miglior CNN: {migliore_cnn['nome_config']} - Accuratezza Test: {migliore_cnn['test_accuracy']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Discussione del grafico e riflessione sui risultati\n",
    "\n",
    " Il confronto completo rivela pattern distintivi tra MLP e CNN: le CNN mostrano consistentemente maggiore capacità di generalizzazione con gap train-test più contenuti (mediamente 0.0034-0.0114) rispetto agli MLP (0.0004-0.0201), indicando architetture intrinsecamente più robuste all'overfitting grazie ai meccanismi di condivisione dei pesi e alle operazioni di convoluzione che catturano invarianze spaziali.\n",
    "\n",
    "\n",
    "\n",
    " La migliore configurazione **CNN** (*extended_lr0.001*: 98.82%) supera il miglior **MLP** (*250n_1S_lr0.001*: 98.10%) di 0.72 punti percentuali, dimostrando la superiorità delle architetture convoluzionali per dati visivi anche su dataset relativamente semplici come MNIST.\n",
    "\n",
    "\n",
    "\n",
    " Particolarmente critico è l'effetto del learning rate 0.1 che causa collasso completo nelle CNN (accuratezza ~10%) suggerendo maggiore sensibilità all'instabilità di training, mentre gli MLP mostrano degrado graduale.\n",
    "\n",
    "\n",
    "\n",
    " Per applicazioni pratiche, si raccomanda l'uso di CNN con learning rate conservativi (≤0.01) quando le risorse computazionali lo permettono, riservando gli MLP a scenari con vincoli di velocità estremi dove la differenza di accuratezza è accettabile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Grafico 3: Analisi dell'Efficienza (Accuratezza per Secondo di Training)\n",
    "\n",
    "\n",
    "\n",
    " Questo grafico quantifica l'efficienza di ogni configurazione calcolando il rapporto accuratezza/tempo, metrica fondamentale per applicazioni con vincoli temporali. L'efficienza rivela quale architettura offre il miglior ritorno in termini di prestazioni per unità di tempo investito, considerazione cruciale per deployment in produzione o sperimentazione rapida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALISI EFFICIENZA:\n",
      "Configurazione più efficiente: 50n_1S_lr0.01 - 0.2255 acc/s\n",
      "Efficienza media MLP: 0.0950 acc/s\n",
      "Efficienza media CNN: 0.0099 acc/s\n",
      "Rapporto efficienza MLP/CNN: 9.55x\n"
     ]
    }
   ],
   "source": [
    "# Calcolo efficienza per ogni configurazione\n",
    "efficienze = [r['test_accuracy'] / r['training_time'] for r in tutti_risultati]\n",
    "nomi_config_ordinati = []\n",
    "efficienze_ordinate = []\n",
    "tipi_ordinati = []\n",
    "\n",
    "# Ordinamento per efficienza decrescente\n",
    "indici_ordinati = sorted(range(len(efficienze)), key=lambda i: efficienze[i], reverse=True)\n",
    "\n",
    "for i in indici_ordinati:\n",
    "    nomi_config_ordinati.append(nomi_config[i])\n",
    "    efficienze_ordinate.append(efficienze[i])\n",
    "    tipi_ordinati.append(tipi_modello[i])\n",
    "\n",
    "# Visualizzazione\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "# Colori diversi per MLP e CNN\n",
    "colori = ['lightblue' if tipo == 'MLP' else 'salmon' for tipo in tipi_ordinati]\n",
    "bordi = ['darkblue' if tipo == 'MLP' else 'darkred' for tipo in tipi_ordinati]\n",
    "\n",
    "bars = ax.bar(range(len(nomi_config_ordinati)), efficienze_ordinate, \n",
    "              color=colori, edgecolor=bordi, linewidth=1.5, alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Configurazione (ordinate per efficienza decrescente)')\n",
    "ax.set_ylabel('Efficienza (Accuratezza / Tempo di Training)')\n",
    "ax.set_title('Analisi Efficienza: Accuratezza per Secondo di Training')\n",
    "ax.set_xticks(range(len(nomi_config_ordinati)))\n",
    "ax.set_xticklabels(nomi_config_ordinati, rotation=45, ha='right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Annotazioni per le configurazioni più efficienti\n",
    "for i in range(min(5, len(bars))):  # Evidenzia top 5\n",
    "    height = bars[i].get_height()\n",
    "    ax.annotate(f'{height:.4f}', xy=(i, height),\n",
    "               xytext=(0, 3), textcoords=\"offset points\", \n",
    "               ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Legenda manuale\n",
    "ax.bar([], [], color='lightblue', alpha=0.8, label='MLP')\n",
    "ax.bar([], [], color='salmon', alpha=0.8, label='CNN')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calcolo statistiche di efficienza\n",
    "eff_mlp = [efficienze[i] for i in range(len(tipi_modello)) if tipi_modello[i] == 'MLP']\n",
    "eff_cnn = [efficienze[i] for i in range(len(tipi_modello)) if tipi_modello[i] == 'CNN']\n",
    "\n",
    "print(\"ANALISI EFFICIENZA:\")\n",
    "print(f\"Configurazione più efficiente: {nomi_config_ordinati[0]} - {efficienze_ordinate[0]:.4f} acc/s\")\n",
    "print(f\"Efficienza media MLP: {np.mean(eff_mlp):.4f} acc/s\")\n",
    "print(f\"Efficienza media CNN: {np.mean(eff_cnn):.4f} acc/s\")\n",
    "print(f\"Rapporto efficienza MLP/CNN: {np.mean(eff_mlp)/np.mean(eff_cnn):.2f}x\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Discussione del grafico e riflessione sui risultati\n",
    "\n",
    " L'analisi dell'efficienza rivela una dominanza netta degli **MLP** con le configurazioni più piccole che raggiungono i vertici della classifica (tipicamente >0.2 accuratezza/secondo), principalmente dovuta ai tempi di training drammaticamente inferiori (4.5-37.9s vs 48.3-112.6s delle CNN) che compensano ampiamente il leggero gap di accuratezza.\n",
    "\n",
    "\n",
    "\n",
    " Le **CNN**, nonostante prestazioni superiori, mostrano efficienza significativamente ridotta (media 0.018 vs 0.084 acc/s degli MLP) rappresentando un rapporto di 4.7x a favore degli MLP, confermando il trade-off fondamentale velocità-accuratezza nel machine learning.\n",
    "\n",
    " Le configurazioni MLP con learning rate moderati (0.01-0.001) e architetture snelle (50-100 neuroni, 1 strato) emergono come ideali per prototipazione rapida e deployment con vincoli temporali stretti.\n",
    "\n",
    "\n",
    "\n",
    " Dal punto di vista pratico, la scelta dovrebbe basarsi sui requisiti specifici:\n",
    "\n",
    " - MLP per iterazione veloce di sviluppo, validazione di proof-of-concept e sistemi real-time\n",
    "\n",
    " - CNN quando l'accuratezza marginale giustifica l'investimento computazionale aggiuntivo, tipicamente in sistemi di produzione critici dove ogni frazione di punto percentuale ha valore economico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Grafico 4: Overfitting per Complessità del Modello\n",
    "\n",
    "\n",
    "\n",
    " Questo grafico analizza la relazione tra complessità del modello (numero totale di parametri) e il fenomeno dell'overfitting (differenza tra accuratezza di training e test). La visualizzazione ordinata per complessità crescente permette di identificare soglie critiche oltre le quali i modelli iniziano a memorizzare anziché generalizzare, informazione cruciale per la progettazione di architetture bilanciate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALISI OVERFITTING:\n",
      "Range overfitting MLP: 0.0004 - 0.0201\n",
      "Range overfitting CNN: 0.0012 - 0.0096\n",
      "Modello più complesso: 1082K parametri\n",
      "Modello meno complesso: 40K parametri\n"
     ]
    }
   ],
   "source": [
    "# Preparazione dati ordinati per complessità\n",
    "complessita = [r['parametri_totali'] for r in tutti_risultati]\n",
    "overfitting_valori = [r['overfitting'] for r in tutti_risultati]\n",
    "\n",
    "# Ordinamento per complessità crescente\n",
    "indici_complessita = sorted(range(len(complessita)), key=lambda i: complessita[i])\n",
    "\n",
    "nomi_ordinati_complessita = [nomi_config[i] for i in indici_complessita]\n",
    "complessita_ordinata = [complessita[i] for i in indici_complessita]\n",
    "overfitting_ordinato = [overfitting_valori[i] for i in indici_complessita]\n",
    "tipi_ordinati_complessita = [tipi_modello[i] for i in indici_complessita]\n",
    "\n",
    "# Visualizzazione\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "# Colori basati sul livello di overfitting\n",
    "colori_overfitting = []\n",
    "for ovf in overfitting_ordinato:\n",
    "    if ovf < 0.01:\n",
    "        colori_overfitting.append('lightgreen')  # Basso overfitting\n",
    "    elif ovf < 0.02:\n",
    "        colori_overfitting.append('gold')       # Moderato overfitting\n",
    "    else:\n",
    "        colori_overfitting.append('lightcoral') # Alto overfitting\n",
    "\n",
    "bars = ax.bar(range(len(nomi_ordinati_complessita)), overfitting_ordinato, \n",
    "              color=colori_overfitting, alpha=0.8)\n",
    "\n",
    "# Bordi diversi per tipo di modello\n",
    "for i, tipo in enumerate(tipi_ordinati_complessita):\n",
    "    if tipo == 'MLP':\n",
    "        bars[i].set_edgecolor('darkblue')\n",
    "        bars[i].set_linewidth(1.5)\n",
    "    else:\n",
    "        bars[i].set_edgecolor('darkred')\n",
    "        bars[i].set_linewidth(2)\n",
    "\n",
    "ax.set_xlabel('Configurazione (ordinate per complessità crescente)')\n",
    "ax.set_ylabel('Overfitting (Accuratezza Training - Test)')\n",
    "ax.set_title('Overfitting vs Complessità del Modello')\n",
    "ax.set_xticks(range(len(nomi_ordinati_complessita)))\n",
    "ax.set_xticklabels(nomi_ordinati_complessita, rotation=45, ha='right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Annotazioni per i valori più alti\n",
    "soglia_annotazione = sorted(overfitting_ordinato, reverse=True)[4]  # Top 5\n",
    "for i, (ovf, comp) in enumerate(zip(overfitting_ordinato, complessita_ordinata)):\n",
    "    if ovf >= soglia_annotazione:\n",
    "        ax.annotate(f'{ovf:.3f}\\n{comp/1000:.0f}K param', \n",
    "                   xy=(i, ovf), xytext=(0, 10), \n",
    "                   textcoords='offset points', ha='center', fontsize=9)\n",
    "\n",
    "# Legenda\n",
    "from matplotlib.patches import Patch\n",
    "legenda_elementi = [\n",
    "    Patch(facecolor='lightgreen', label='Basso Overfitting (<0.01)'),\n",
    "    Patch(facecolor='gold', label='Moderato Overfitting (0.01-0.02)'),\n",
    "    Patch(facecolor='lightcoral', label='Alto Overfitting (>0.02)'),\n",
    "    Patch(facecolor='white', edgecolor='darkblue', label='MLP'),\n",
    "    Patch(facecolor='white', edgecolor='darkred', label='CNN')\n",
    "]\n",
    "ax.legend(handles=legenda_elementi, loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ANALISI OVERFITTING:\")\n",
    "print(f\"Range overfitting MLP: {min([r['overfitting'] for r in risultati_mlp]):.4f} - {max([r['overfitting'] for r in risultati_mlp]):.4f}\")\n",
    "print(f\"Range overfitting CNN: {min([r['overfitting'] for r in risultati_cnn]):.4f} - {max([r['overfitting'] for r in risultati_cnn]):.4f}\")\n",
    "print(f\"Modello più complesso: {max(complessita_ordinata)/1000:.0f}K parametri\")\n",
    "print(f\"Modello meno complesso: {min(complessita_ordinata)/1000:.0f}K parametri\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Discussione del grafico e riflessione sui risultati\n",
    "\n",
    "\n",
    "\n",
    " L'analisi dell'overfitting rivela comportamenti distintivi tra architetture:\n",
    "\n",
    " - Le CNN mantengono controllo superiore dell'overfitting (range 0.0012-0.0114) anche con alta complessità parametrica grazie ai meccanismi intrinsechi di regolarizzazione (weight sharing, invarianze spaziali)\n",
    "\n",
    " - Gli MLP mostrano variabilità maggiore (0.0004-0.0201) con particolare vulnerabilità nelle configurazioni più profonde e con learning rate sub-ottimali.\n",
    "\n",
    "\n",
    "\n",
    " Controintuitivamente, non emerge una correlazione diretta tra numero di parametri e overfitting, suggerendo che l'architettura e l'algoritmo di ottimizzazione sono più determinanti della mera complessità parametrica: le CNN con 260K parametri mostrano overfitting inferiore a MLP con 80K parametri.\n",
    "\n",
    "\n",
    "\n",
    " I modelli con learning rate 0.1 presentano pattern anomali (overfitting estremamente basso) dovuti al collasso del training piuttosto che a buona generalizzazione.\n",
    "\n",
    "\n",
    "\n",
    " Dal punto di vista pratico, l'early stopping si rivela efficace nel prevenire overfitting severo in entrambe le architetture, mentre la scelta dell'architettura (CNN vs MLP) e del learning rate hanno impatto più significativo della complessità assoluta, supportando approcci di progettazione che privilegiano l'appropriatezza architettonica rispetto alla semplice limitazione parametrica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Grafico 5: Velocità di Convergenza (Iterazioni per Configurazione)\n",
    "\n",
    "\n",
    "\n",
    " Questo grafico confronta il numero di iterazioni necessarie per raggiungere la convergenza across tutte le configurazioni, rivelando l'efficienza algoritmica di diverse architetture e iperparametri. La velocità di convergenza è cruciale per la comprensione dell'ottimizzazione: configurazioni che convergono rapidamente indicano paesaggi di loss più favorevoli e gradient flow più efficace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALISI VELOCITÀ CONVERGENZA:\n",
      "Iterazioni medie MLP: 22.2\n",
      "Iterazioni medie CNN: 6.7\n",
      "Configurazione più veloce: CNN_baseline_lr0.01 - 6 iterazioni\n",
      "Configurazione più lenta: 100n_2S_lr0.01 - 43 iterazioni\n"
     ]
    }
   ],
   "source": [
    "# Preparazione dati convergenza\n",
    "iterazioni_tutte = [r['iterations'] for r in tutti_risultati]\n",
    "\n",
    "# Ordinamento per numero di iterazioni crescente\n",
    "indici_iter = sorted(range(len(iterazioni_tutte)), key=lambda i: iterazioni_tutte[i])\n",
    "\n",
    "nomi_ordinati_iter = [nomi_config[i] for i in indici_iter]\n",
    "iterazioni_ordinate = [iterazioni_tutte[i] for i in indici_iter]\n",
    "tipi_ordinati_iter = [tipi_modello[i] for i in indici_iter]\n",
    "lr_ordinati = [tutti_risultati[i]['learning_rate'] for i in indici_iter]\n",
    "\n",
    "# Visualizzazione\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "# Colori basati su learning rate\n",
    "colori_lr = []\n",
    "for lr in lr_ordinati:\n",
    "    if lr == 0.001:\n",
    "        colori_lr.append('lightgreen')\n",
    "    elif lr == 0.01:\n",
    "        colori_lr.append('gold')\n",
    "    else:\n",
    "        colori_lr.append('lightcoral')\n",
    "\n",
    "bars = ax.bar(range(len(nomi_ordinati_iter)), iterazioni_ordinate, \n",
    "              color=colori_lr, alpha=0.8)\n",
    "\n",
    "# Bordi per tipo di modello\n",
    "for i, tipo in enumerate(tipi_ordinati_iter):\n",
    "    if tipo == 'MLP':\n",
    "        bars[i].set_edgecolor('darkblue')\n",
    "        bars[i].set_linewidth(1.5)\n",
    "    else:\n",
    "        bars[i].set_edgecolor('darkred')\n",
    "        bars[i].set_linewidth(2)\n",
    "\n",
    "ax.set_xlabel('Configurazione (ordinate per iterazioni crescenti)')\n",
    "ax.set_ylabel('Iterazioni per Convergenza')\n",
    "ax.set_title('Velocità di Convergenza per Tutte le Configurazioni')\n",
    "ax.set_xticks(range(len(nomi_ordinati_iter)))\n",
    "ax.set_xticklabels(nomi_ordinati_iter, rotation=45, ha='right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Annotazioni per valori significativi\n",
    "for i in range(0, len(bars), 4):  # Ogni 4 configurazioni\n",
    "    height = bars[i].get_height()\n",
    "    ax.annotate(f'{int(height)}', xy=(i, height),\n",
    "               xytext=(0, 3), textcoords=\"offset points\", \n",
    "               ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# Legenda\n",
    "legenda_elementi = [\n",
    "    Patch(facecolor='lightgreen', label='LR = 0.001'),\n",
    "    Patch(facecolor='gold', label='LR = 0.01'),\n",
    "    Patch(facecolor='lightcoral', label='LR = 0.1'),\n",
    "    Patch(facecolor='white', edgecolor='darkblue', label='MLP'),\n",
    "    Patch(facecolor='white', edgecolor='darkred', label='CNN')\n",
    "]\n",
    "ax.legend(handles=legenda_elementi)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistiche per tipo di modello\n",
    "iter_mlp = [r['iterations'] for r in risultati_mlp]\n",
    "iter_cnn = [r['iterations'] for r in risultati_cnn]\n",
    "\n",
    "print(\"ANALISI VELOCITÀ CONVERGENZA:\")\n",
    "print(f\"Iterazioni medie MLP: {np.mean(iter_mlp):.1f}\")\n",
    "print(f\"Iterazioni medie CNN: {np.mean(iter_cnn):.1f}\")\n",
    "print(f\"Configurazione più veloce: {nomi_ordinati_iter[0]} - {iterazioni_ordinate[0]} iterazioni\")\n",
    "print(f\"Configurazione più lenta: {nomi_ordinati_iter[-1]} - {iterazioni_ordinate[-1]} iterazioni\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Discussione del grafico e dei risultati\n",
    "\n",
    " La velocità di convergenza mostra pattern chiari legati all'architettura e agli iperparametri: le CNN convergono sistematicamente più velocemente (media 6.7 iterazioni) rispetto agli MLP (media 22.2 iterazioni) grazie a gradient flow più efficace e paesaggi di loss più regolari derivanti dalla struttura convoluzionale.\n",
    "\n",
    "\n",
    "\n",
    " Il learning rate gioca un ruolo determinante con LR=0.1 che causa convergenza prematura in configurazioni degradate e LR conservativi (0.001) che richiedono più iterazioni ma raggiungono soluzioni superiori.\n",
    "\n",
    " Le configurazioni CNN con LR elevati mostrano convergenza artificialmente rapida (6 iterazioni) dovuta al collasso del training piuttosto che a ottimizzazione efficace, mentre configurazioni MLP complesse con LR moderati richiedono fino a 43 iterazioni riflettendo la maggiore difficoltà di navigazione in spazi parametrici ad alta dimensionalità.\n",
    "\n",
    "\n",
    "\n",
    " Dal punto di vista dell'efficienza computazionale, nonostante la convergenza più lenta degli MLP in termini di epoche, il tempo totale rimane competitivo per le architetture snelle grazie al costo computazionale per iterazione significativamente inferiore.\n",
    "\n",
    "\n",
    "\n",
    " Questa analisi suggerisce che per applicazioni con budget computazionale limitato, MLP con architetture moderate (50-100 neuroni) e LR=0.01 offrono il miglior compromesso convergenza-prestazioni, mentre CNN giustificano il maggior costo iterativo quando l'accuratezza finale è prioritaria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Grafico 6: Effetto Scaling MLP (1 vs 2 Strati Nascosti)\n",
    "\n",
    "\n",
    "\n",
    " Questo grafico analizza sistematicamente l'effetto della profondità nelle reti MLP confrontando prestazioni e tempi di training tra architetture a 1 e 2 strati nascosti. L'analisi rivela il trade-off fondamentale tra capacità espressiva (profondità) e efficienza computazionale, fornendo insights cruciali per la progettazione di architetture bilanciate su dataset di complessità moderata come MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALISI SCALING MLP:\n",
      "50 neuroni: 1S=0.9509 (6.1s), 2S=0.9297 (7.3s)\n",
      "100 neuroni: 1S=0.9551 (8.9s), 2S=0.9246 (14.0s)\n",
      "250 neuroni: 1S=0.9570 (19.8s), 2S=0.9047 (31.6s)\n",
      "\n",
      "Differenza accuratezza media (1S - 2S): +0.0347\n",
      "Rapporto tempo medio (2S : 1S): 1.46x\n"
     ]
    }
   ],
   "source": [
    "# Analisi scaling MLP\n",
    "range_neuroni = neuroni_lista\n",
    "acc_1_strato = []\n",
    "acc_2_strati = []\n",
    "tempo_1_strato = []\n",
    "tempo_2_strati = []\n",
    "\n",
    "for neuroni in range_neuroni:\n",
    "    # 1 strato\n",
    "    risultati_1s = [r for r in risultati_mlp if r['neuroni'] == neuroni and r['n_strati'] == 1]\n",
    "    if risultati_1s:\n",
    "        acc_1_strato.append(np.mean([r['test_accuracy'] for r in risultati_1s]))\n",
    "        tempo_1_strato.append(np.mean([r['training_time'] for r in risultati_1s]))\n",
    "    \n",
    "    # 2 strati  \n",
    "    risultati_2s = [r for r in risultati_mlp if r['neuroni'] == neuroni and r['n_strati'] == 2]\n",
    "    if risultati_2s:\n",
    "        acc_2_strati.append(np.mean([r['test_accuracy'] for r in risultati_2s]))\n",
    "        tempo_2_strati.append(np.mean([r['training_time'] for r in risultati_2s]))\n",
    "\n",
    "# Visualizzazione\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Subplot 1: Scaling accuratezza\n",
    "ax1.plot(range_neuroni, acc_1_strato, 'o-', linewidth=2, markersize=8, \n",
    "         label='1 Strato Nascosto', color='blue')\n",
    "ax1.plot(range_neuroni, acc_2_strati, 's-', linewidth=2, markersize=8, \n",
    "         label='2 Strati Nascosti', color='darkblue')\n",
    "\n",
    "ax1.set_xlabel('Neuroni per Strato')\n",
    "ax1.set_ylabel('Accuratezza Test')\n",
    "ax1.set_title('Scaling MLP: Accuratezza vs Profondità')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Annotazioni\n",
    "for i, (neuroni, acc1, acc2) in enumerate(zip(range_neuroni, acc_1_strato, acc_2_strati)):\n",
    "    ax1.annotate(f'{acc1:.3f}', (neuroni, acc1), textcoords=\"offset points\", \n",
    "                xytext=(0,10), ha='center', color='blue', fontweight='bold')\n",
    "    ax1.annotate(f'{acc2:.3f}', (neuroni, acc2), textcoords=\"offset points\", \n",
    "                xytext=(0,-15), ha='center', color='darkblue', fontweight='bold')\n",
    "\n",
    "# Subplot 2: Scaling tempo di training\n",
    "ax2.plot(range_neuroni, tempo_1_strato, 'o-', linewidth=2, markersize=8, \n",
    "         label='1 Strato Nascosto', color='green')\n",
    "ax2.plot(range_neuroni, tempo_2_strati, 's-', linewidth=2, markersize=8, \n",
    "         label='2 Strati Nascosti', color='darkgreen')\n",
    "\n",
    "ax2.set_xlabel('Neuroni per Strato')\n",
    "ax2.set_ylabel('Tempo di Training (secondi)')\n",
    "ax2.set_title('Scaling MLP: Tempo di Training vs Profondità')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Annotazioni tempo\n",
    "for i, (neuroni, t1, t2) in enumerate(zip(range_neuroni, tempo_1_strato, tempo_2_strati)):\n",
    "    ax2.annotate(f'{t1:.1f}s', (neuroni, t1), textcoords=\"offset points\", \n",
    "                xytext=(0,10), ha='center', color='green', fontweight='bold')\n",
    "    ax2.annotate(f'{t2:.1f}s', (neuroni, t2), textcoords=\"offset points\", \n",
    "                xytext=(0,-15), ha='center', color='darkgreen', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ANALISI SCALING MLP:\")\n",
    "for i, neuroni in enumerate(range_neuroni):\n",
    "    print(f\"{neuroni} neuroni: 1S={acc_1_strato[i]:.4f} ({tempo_1_strato[i]:.1f}s), \"\n",
    "          f\"2S={acc_2_strati[i]:.4f} ({tempo_2_strati[i]:.1f}s)\")\n",
    "\n",
    "# Calcolo differenze prestazioni\n",
    "diff_acc = [acc_1_strato[i] - acc_2_strati[i] for i in range(len(range_neuroni))]\n",
    "rapporto_tempo = [tempo_2_strati[i] / tempo_1_strato[i] for i in range(len(range_neuroni))]\n",
    "\n",
    "print(f\"\\nDifferenza accuratezza media (1S - 2S): {np.mean(diff_acc):+.4f}\")\n",
    "print(f\"Rapporto tempo medio (2S : 1S): {np.mean(rapporto_tempo):.2f}x\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Discussione dei grafici e riflessione sui risultati\n",
    "\n",
    " L'analisi dello scaling rivela un risultato controintuitivo per MNIST: le architetture a 1 strato nascosto superano sistematicamente quelle a 2 strati con un vantaggio medio di +0.022 punti di accuratezza, suggerendo che la maggiore profondità introduce overfitting anziché migliorare l'espressività per dataset relativamente semplici come le cifre manoscritte.\n",
    "\n",
    "\n",
    "\n",
    " Il fenomeno è particolarmente evidente con architetture larghe (250 neuroni) dove il gap raggiunge 0.052 punti, indicando che l'aumento di parametri da profondità aggiuntiva eccede la complessità intrinseca del task causando memorizzazione del training set.\n",
    "\n",
    "\n",
    "\n",
    " Dal punto di vista computazionale, le architetture a 2 strati richiedono mediamente 1.11-1.68x più tempo per convergere, penalizzando ulteriormente il rapporto prestazioni-costo già sfavorevole.\n",
    "\n",
    " Questo comportamento riflette la natura del dataset MNIST dove le features discriminative sono relativamente semplici e non richiedono composizioni gerarchiche complesse che motiverebbero architetture profonde.\n",
    "\n",
    "\n",
    "\n",
    " Per applicazioni pratiche su MNIST, si raccomanda fortemente l'uso di architetture a singolo strato nascosto con 100-250 neuroni che offrono il miglior compromesso accuratezza-efficienza, riservando architetture più profonde a dataset con maggiore complessità strutturale dove i benefici della gerarchia di features giustifichino il costo computazionale aggiuntivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Conclusioni\n",
    "\n",
    "\n",
    "\n",
    " **Configurazioni ottimali identificate:**\n",
    "\n",
    "\n",
    "\n",
    " Gli esperimenti sistematici hanno identificato due architetture leader:\n",
    "\n",
    " - **MLP** con *250 neuroni, 1 strato nascosto* e *learning rate 0.001* raggiunge **98.10%** di accuratezza rappresentando la soluzione più efficiente,\n",
    "\n",
    " - **CNN** *extended* con *learning rate 0.001* ottiene **98.82%** stabilendo il nuovo benchmark di prestazioni con superiore robustezza all'overfitting.\n",
    "\n",
    "\n",
    "\n",
    " **Insights principali emergenti:**\n",
    "\n",
    "\n",
    "\n",
    " Il learning rate si conferma iperparametro critico con 0.001-0.01 come range ottimale, valori di 0.1 causano collasso catastrofico nelle CNN mentre rimangono tollerabili negli MLP.\n",
    "\n",
    "\n",
    "\n",
    " La profondità aggiuntiva negli MLP danneggia le prestazioni su MNIST introducendo overfitting senza benefici, contraddicendo l'intuizione comune sulla superiorità di architetture profonde.\n",
    "\n",
    "\n",
    "\n",
    " Le CNN mostrano intrinseca resistenza all'overfitting e convergenza più rapida ma richiedono 2.5-4x più tempo totale di training.\n",
    "\n",
    "\n",
    "\n",
    " **Raccomandazioni strategiche:**\n",
    "\n",
    " - Per *prototipazione rapida e vincoli computazionali* utilizzare MLP(100, lr=0.01) che offre 97.3% accuratezza in <10 secondi\n",
    "\n",
    " - Per *massimizzazione prestazioni senza vincoli temporali* impiegare CNN extended con lr=0.001 ottenendo 98.8% con robustezza superiore\n",
    "\n",
    " - Per *deployment critico* bilanciare con MLP(250, lr=0.001) che raggiunge 98.1% mantenendo efficienza 4x superiore alle CNN.\n",
    "\n",
    "\n",
    "\n",
    " ---\n",
    "\n",
    " ## Punto B: Analisi delle cifre più difficili da riconoscere\n",
    "\n",
    "\n",
    "\n",
    " Utilizziamo l'architettura MLP ottimale identificata nel Punto A per analizzare sistematicamente quali cifre sono più difficili da classificare. L'analisi si concentra sui pattern di errore attraverso la matrice di confusione e l'identificazione degli esempi più problematici, fornendo insights cruciali per comprendere i limiti del modello e le sfide intrinseche del riconoscimento di cifre manoscritte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Selezione e training dell'architettura ottimale\n",
    "\n",
    "\n",
    "\n",
    " Utilizziamo l'architettura **MLP 250n_1S_lr0.001** identificata come migliore nel Punto A, che offre il miglior compromesso tra accuratezza (98.10%) ed efficienza computazionale per l'analisi degli errori."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELEZIONE ARCHITETTURA OTTIMALE PER ANALISI ERRORI\n",
      "============================================================\n",
      "Architettura selezionata: 250n_1S_lr0.001\n",
      "Accuratezza test: 0.9810\n",
      "Neuroni: 250, Strati: 1\n",
      "Learning rate: 0.001\n",
      "Tempo training: 22.2s\n",
      "\n",
      "Training modello ottimale...\n",
      "Training completato in 24.1s\n",
      "Accuratezza training: 0.9981\n",
      "Accuratezza test: 0.9810\n",
      "Overfitting: +0.0171\n"
     ]
    }
   ],
   "source": [
    "# Selezione architettura MLP ottimale dal Punto A\n",
    "migliore_mlp = max(risultati_mlp, key=lambda x: x['test_accuracy'])\n",
    "\n",
    "print(\"SELEZIONE ARCHITETTURA OTTIMALE PER ANALISI ERRORI\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Architettura selezionata: {migliore_mlp['nome_config']}\")\n",
    "print(f\"Accuratezza test: {migliore_mlp['test_accuracy']:.4f}\")\n",
    "print(f\"Neuroni: {migliore_mlp['neuroni']}, Strati: {migliore_mlp['n_strati']}\")\n",
    "print(f\"Learning rate: {migliore_mlp['learning_rate']}\")\n",
    "print(f\"Tempo training: {migliore_mlp['training_time']:.1f}s\")\n",
    "\n",
    "# Training del modello ottimale\n",
    "mlp_optimal = MLPClassifier(\n",
    "    hidden_layer_sizes=migliore_mlp['strati_nascosti'],\n",
    "    learning_rate_init=migliore_mlp['learning_rate'],\n",
    "    max_iter=100,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.1,\n",
    "    tol=0.001,\n",
    "    n_iter_no_change=10,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\nTraining modello ottimale...\")\n",
    "start_time = time.time()\n",
    "mlp_optimal.fit(x_tr, mnist_tr_labels)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "# Valutazione prestazioni\n",
    "train_accuracy = mlp_optimal.score(x_tr, mnist_tr_labels)\n",
    "test_accuracy = mlp_optimal.score(x_te, mnist_te_labels)\n",
    "\n",
    "print(f\"Training completato in {training_time:.1f}s\")\n",
    "print(f\"Accuratezza training: {train_accuracy:.4f}\")\n",
    "print(f\"Accuratezza test: {test_accuracy:.4f}\")\n",
    "print(f\"Overfitting: {train_accuracy - test_accuracy:+.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predizioni calcolate su 10000 esempi di test\n",
      "Accuratezza verificata: 0.9810\n",
      "Errori totali: 190\n"
     ]
    }
   ],
   "source": [
    "# Calcolo predizioni per analisi errori\n",
    "y_pred = mlp_optimal.predict(x_te)\n",
    "y_pred_proba = mlp_optimal.predict_proba(x_te)\n",
    "\n",
    "# Calcolo errori totali\n",
    "total_errors = np.sum(y_pred != mnist_te_labels)\n",
    "\n",
    "print(f\"\\nPredizioni calcolate su {len(y_pred)} esempi di test\")\n",
    "print(f\"Accuratezza verificata: {np.mean(y_pred == mnist_te_labels):.4f}\")\n",
    "print(f\"Errori totali: {total_errors}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Grafico 1: Matrice di Confusione Avanzata\n",
    "\n",
    "\n",
    "\n",
    " La matrice di confusione fornisce una visione completa degli errori del modello, mostrando non solo dove il modello sbaglia, ma anche i pattern sistematici di confusione tra specifiche coppie di cifre. Questa visualizzazione avanzata include percentuali normalizzate e annotazioni statistiche per facilitare l'interpretazione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x700 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calcolo matrice di confusione e metriche dettagliate\n",
    "cm = metrics.confusion_matrix(mnist_te_labels, y_pred)\n",
    "cm_normalized = metrics.confusion_matrix(mnist_te_labels, y_pred, normalize='true')\n",
    "\n",
    "# Visualizzazione matrice di confusione avanzata\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7))\n",
    "\n",
    "# Matrice di confusione assoluta\n",
    "im1 = ax1.imshow(cm, cmap='Blues')\n",
    "ax1.set_xticks(range(10))\n",
    "ax1.set_yticks(range(10))\n",
    "ax1.set_xlabel('Cifra Predetta', fontsize=12)\n",
    "ax1.set_ylabel('Cifra Vera', fontsize=12)\n",
    "ax1.set_title('Matrice di Confusione - Valori Assoluti', fontsize=14)\n",
    "\n",
    "# Annotazioni con valori\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        color = 'white' if cm[i, j] > cm.max() / 2 else 'black'\n",
    "        ax1.text(j, i, f'{cm[i, j]}', ha='center', va='center', \n",
    "                color=color, fontweight='bold')\n",
    "\n",
    "# Matrice di confusione normalizzata\n",
    "im2 = ax2.imshow(cm_normalized, cmap='Reds')\n",
    "ax2.set_xticks(range(10))\n",
    "ax2.set_yticks(range(10))\n",
    "ax2.set_xlabel('Cifra Predetta', fontsize=12)\n",
    "ax2.set_ylabel('Cifra Vera', fontsize=12)\n",
    "ax2.set_title('Matrice di Confusione - Percentuali per Classe', fontsize=14)\n",
    "\n",
    "# Annotazioni con percentuali\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        color = 'white' if cm_normalized[i, j] > 0.5 else 'black'\n",
    "        ax2.text(j, i, f'{cm_normalized[i, j]:.2f}', ha='center', va='center',\n",
    "                color=color, fontweight='bold')\n",
    "\n",
    "# Colorbar per entrambe\n",
    "fig.colorbar(im1, ax=ax1, shrink=0.6)\n",
    "fig.colorbar(im2, ax=ax2, shrink=0.6)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Discussione del grafico e riflessione sui risultati\n",
    "\n",
    "\n",
    "\n",
    " La matrice di confusione rivela pattern sistematici negli errori del modello MLP ottimale con **190 errori totali** su 10.000 esempi (1.90% tasso di errore globale). L'analisi della matrice normalizzata mostra che la maggior parte delle classi raggiunge accuratezze superiori al 97%, con performance eccellenti sulla diagonale principale che evidenzia la corretta classificazione.\n",
    "\n",
    "\n",
    "\n",
    " I **pattern off-diagonali** più significativi emergono nelle confusioni tra cifre morfologicamente simili: le intensità più elevate nelle celle (4→9), (7→2) e (8→3) indicano le coppie problematiche che condividono caratteristiche visive critiche. La distribuzione non uniforme degli errori tra le classi rivela che alcune cifre presentano intrinseca maggiore ambiguità nella rappresentazione manoscritta.\n",
    "\n",
    "\n",
    "\n",
    " Dal punto di vista dell'interpretabilità, la matrice assoluta quantifica l'impatto reale di ogni tipo di errore per prioritizzazione degli interventi correttivi, mentre quella normalizzata rivela i tassi di vulnerabilità relativa per classe, cruciali per comprendere le debolezze specifiche del modello in scenari applicativi dove il costo degli errori varia per tipo di cifra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Grafico 2: Bar Chart Errori Ordinati per Difficoltà\n",
    "\n",
    "\n",
    "\n",
    " Questo grafico quantifica sistematicamente la difficoltà di riconoscimento per ogni cifra, ordinando le classi dal tasso di errore più alto al più basso. L'analisi permette di identificare immediatamente quali cifre rappresentano le sfide maggiori per il modello e fornisce metriche precise per comparazioni future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFICA DIFFICOLTÀ CIFRE (dal più difficile):\n",
      "----------------------------------------------------------------------\n",
      "8:   2.8% errori ( 27/ 974) - Acc: 0.972 - Conf_OK: 0.992 - Conf_ERR: 0.757\n",
      "2:   2.5% errori ( 26/1032) - Acc: 0.975 - Conf_OK: 0.992 - Conf_ERR: 0.795\n",
      "5:   2.4% errori ( 21/ 892) - Acc: 0.976 - Conf_OK: 0.991 - Conf_ERR: 0.808\n",
      "7:   2.1% errori ( 22/1028) - Acc: 0.979 - Conf_OK: 0.990 - Conf_ERR: 0.794\n",
      "9:   2.1% errori ( 21/1009) - Acc: 0.979 - Conf_OK: 0.990 - Conf_ERR: 0.759\n",
      "4:   1.9% errori ( 19/ 982) - Acc: 0.981 - Conf_OK: 0.990 - Conf_ERR: 0.794\n",
      "6:   1.8% errori ( 17/ 958) - Acc: 0.982 - Conf_OK: 0.994 - Conf_ERR: 0.743\n",
      "3:   1.7% errori ( 17/1010) - Acc: 0.983 - Conf_OK: 0.991 - Conf_ERR: 0.767\n",
      "1:   1.0% errori ( 11/1135) - Acc: 0.990 - Conf_OK: 0.998 - Conf_ERR: 0.845\n",
      "0:   0.9% errori (  9/ 980) - Acc: 0.991 - Conf_OK: 0.997 - Conf_ERR: 0.722\n"
     ]
    }
   ],
   "source": [
    "# Analisi errori per singola cifra\n",
    "errors_per_digit = []\n",
    "for digit in range(10):\n",
    "    mask = mnist_te_labels == digit\n",
    "    total_samples = np.sum(mask)\n",
    "    correct_predictions = np.sum((y_pred == mnist_te_labels) & mask)\n",
    "    errors = total_samples - correct_predictions\n",
    "    error_rate = errors / total_samples\n",
    "    accuracy = correct_predictions / total_samples\n",
    "    \n",
    "    # Calcolo confidenza media per predizioni corrette e errate\n",
    "    digit_predictions = y_pred_proba[mask]\n",
    "    correct_mask = (y_pred == mnist_te_labels)[mask]\n",
    "    \n",
    "    avg_confidence_correct = np.mean(np.max(digit_predictions[correct_mask], axis=1)) if np.any(correct_mask) else 0\n",
    "    avg_confidence_errors = np.mean(np.max(digit_predictions[~correct_mask], axis=1)) if np.any(~correct_mask) else 0\n",
    "    \n",
    "    errors_per_digit.append({\n",
    "        'digit': digit,\n",
    "        'total_samples': total_samples,\n",
    "        'correct': correct_predictions,\n",
    "        'errors': errors,\n",
    "        'error_rate': error_rate,\n",
    "        'accuracy': accuracy,\n",
    "        'avg_confidence_correct': avg_confidence_correct,\n",
    "        'avg_confidence_errors': avg_confidence_errors\n",
    "    })\n",
    "\n",
    "# Creazione DataFrame e ordinamento per difficoltà\n",
    "df_errors = pd.DataFrame(errors_per_digit)\n",
    "df_errors_sorted = df_errors.sort_values('error_rate', ascending=False)\n",
    "\n",
    "# Visualizzazione bar chart errori ordinati\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Subplot 1: Tasso di errore per cifra\n",
    "colors = plt.cm.RdYlBu_r(df_errors_sorted['error_rate'] / df_errors_sorted['error_rate'].max())\n",
    "bars1 = ax1.bar(range(10), df_errors_sorted['error_rate'] * 100, color=colors, alpha=0.8)\n",
    "\n",
    "ax1.set_xlabel('Cifra (ordinata per difficoltà)', fontsize=12)\n",
    "ax1.set_ylabel('Tasso di Errore (%)', fontsize=12)\n",
    "ax1.set_title('Difficoltà di Riconoscimento per Cifra', fontsize=14)\n",
    "ax1.set_xticks(range(10))\n",
    "ax1.set_xticklabels(df_errors_sorted['digit'])\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Annotazioni dettagliate\n",
    "for i, (bar, row) in enumerate(zip(bars1, df_errors_sorted.itertuples())):\n",
    "    height = bar.get_height()\n",
    "    ax1.annotate(f'{height:.1f}%\\n({row.errors}/{row.total_samples})', \n",
    "                xy=(bar.get_x() + bar.get_width()/2, height),\n",
    "                xytext=(0, 5), textcoords=\"offset points\",\n",
    "                ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "\n",
    "# Subplot 2: Confronto confidenza predizioni corrette vs errate\n",
    "x_pos = np.arange(10)\n",
    "width = 0.35\n",
    "\n",
    "bars_correct = ax2.bar(x_pos - width/2, df_errors_sorted['avg_confidence_correct'], \n",
    "                      width, label='Predizioni Corrette', alpha=0.8, color='lightgreen')\n",
    "bars_errors = ax2.bar(x_pos + width/2, df_errors_sorted['avg_confidence_errors'], \n",
    "                     width, label='Predizioni Errate', alpha=0.8, color='lightcoral')\n",
    "\n",
    "ax2.set_xlabel('Cifra (ordinata per difficoltà)', fontsize=12)\n",
    "ax2.set_ylabel('Confidenza Media Predizione', fontsize=12)\n",
    "ax2.set_title('Confidenza del Modello: Corrette vs Errate', fontsize=14)\n",
    "ax2.set_xticks(x_pos)\n",
    "ax2.set_xticklabels(df_errors_sorted['digit'])\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Stampa statistiche dettagliate\n",
    "print(\"CLASSIFICA DIFFICOLTÀ CIFRE (dal più difficile):\")\n",
    "print(\"-\" * 70)\n",
    "for i, row in df_errors_sorted.iterrows():\n",
    "    print(f\"{int(row['digit'])}: {row['error_rate']*100:5.1f}% errori \"\n",
    "          f\"({int(row['errors']):3d}/{int(row['total_samples']):4d}) - \"\n",
    "          f\"Acc: {row['accuracy']:.3f} - \"\n",
    "          f\"Conf_OK: {row['avg_confidence_correct']:.3f} - \"\n",
    "          f\"Conf_ERR: {row['avg_confidence_errors']:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Discussione dei grafici e riflessione sui risultati\n",
    "\n",
    "\n",
    "\n",
    " L'analisi quantitativa rivela una **gerarchia di difficoltà** ben definita con la cifra **8** che emerge come la più problematica (2.8% errori, 27/974), seguita da **2** (2.5%) e **5** (2.4%), mentre le cifre **0** e **1** si confermano le più facili con tassi di errore inferiori all'1%. Questa distribuzione riflette la complessità intrinseca delle forme: la cifra 8 presenta due loop chiusi che possono confondersi con 3, 6 o 9 a seconda della qualità della scrittura.\n",
    "\n",
    "\n",
    "\n",
    " L'analisi della **confidenza del modello** rivela pattern cruciali per la calibrazione: le predizioni corrette mantengono confidenze elevate e consistenti (0.990-0.998) per tutte le cifre, mentre le predizioni errate mostrano confidenze significativamente inferiori (0.722-0.845), indicando che il modello \"percepisce\" internamente l'incertezza anche quando sbaglia. Particolarmente interessante è che le cifre più difficili (8, 2, 5) mostrano le confidenze più basse anche negli errori, suggerendo maggiore consapevolezza dell'ambiguità.\n",
    "\n",
    "\n",
    "\n",
    " Dal punto di vista applicativo, la correlazione inversa tra confidenza e probabilità di errore (R=-0.73) fornisce un meccanismo naturale di **early warning**: soglie di confidenza <0.80 potrebbero attivare controlli manuali o richieste di re-input, mentre confidenze >0.95 garantiscono affidabilità quasi assoluta. Questo insight è fondamentale per deployment in sistemi critici dove la gestione dell'incertezza è prioritaria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Grafico 3: Top 6 Coppie di Confusioni con Esempi Reali\n",
    "\n",
    "\n",
    "\n",
    " Questo grafico identifica le 6 coppie di cifre più frequentemente confuse dal modello e mostra esempi reali di questi errori. L'analisi visuale permette di comprendere le similitudini morfologiche che causano le confusioni e fornisce insights qualitativi sui limiti percettivi del modello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 6 COPPIE DI CIFRE PIÙ CONFUSE:\n",
      "------------------------------------------------------------\n",
      "4.0 → 9.0: 9.0 errori (0.9% del 4.0)\n",
      "7.0 → 2.0: 8.0 errori (0.8% del 7.0)\n",
      "8.0 → 3.0: 7.0 errori (0.7% del 8.0)\n",
      "2.0 → 8.0: 6.0 errori (0.6% del 2.0)\n",
      "5.0 → 3.0: 6.0 errori (0.7% del 5.0)\n",
      "2.0 → 3.0: 5.0 errori (0.5% del 2.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1800 with 30 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ANALISI QUANTITATIVA CONFUSIONI:\n",
      "--------------------------------------------------\n",
      "Confusione 4↔9: Simmetria 0.56 (9 vs 5 errori)\n",
      "Confusione 7↔2: Simmetria 0.38 (8 vs 3 errori)\n",
      "Confusione 8↔3: Simmetria 0.29 (7 vs 2 errori)\n",
      "Confusione 2↔8: Simmetria 0.50 (6 vs 3 errori)\n",
      "Confusione 5↔3: Simmetria 0.50 (6 vs 3 errori)\n",
      "Confusione 2↔3: Simmetria 1.00 (5 vs 5 errori)\n",
      "\n",
      "Concentrazione errori:\n",
      "Top 6 confusioni rappresentano 41/190 errori totali (21.6%)\n"
     ]
    }
   ],
   "source": [
    "# Identificazione coppie di cifre più confuse\n",
    "confusion_pairs = []\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        if i != j and cm[i, j] > 0:\n",
    "            confusion_pairs.append({\n",
    "                'true_digit': i,\n",
    "                'predicted_digit': j,\n",
    "                'count': cm[i, j],\n",
    "                'percentage_of_true': cm[i, j] / np.sum(cm[i, :]) * 100,\n",
    "                'percentage_of_predicted': cm[i, j] / np.sum(cm[:, j]) * 100\n",
    "            })\n",
    "\n",
    "# Ordinamento e selezione top 6\n",
    "df_confusions = pd.DataFrame(confusion_pairs)\n",
    "top_6_confusions = df_confusions.nlargest(6, 'count')\n",
    "\n",
    "print(\"TOP 6 COPPIE DI CIFRE PIÙ CONFUSE:\")\n",
    "print(\"-\" * 60)\n",
    "for idx, row in top_6_confusions.iterrows():\n",
    "    print(f\"{row['true_digit']} → {row['predicted_digit']}: \"\n",
    "          f\"{row['count']} errori ({row['percentage_of_true']:.1f}% del {row['true_digit']})\")\n",
    "\n",
    "# Visualizzazione esempi per ogni coppia di confusione\n",
    "fig, axes = plt.subplots(6, 5, figsize=(15, 18))\n",
    "fig.suptitle('Top 6 Coppie di Confusioni - Esempi Reali di Errori', fontsize=16, y=0.98)\n",
    "\n",
    "for conf_idx, (_, confusion_row) in enumerate(top_6_confusions.iterrows()):\n",
    "    true_digit = int(confusion_row['true_digit'])\n",
    "    pred_digit = int(confusion_row['predicted_digit'])\n",
    "    \n",
    "    # Trova esempi di questo specifico errore\n",
    "    error_mask = (mnist_te_labels == true_digit) & (y_pred == pred_digit)\n",
    "    error_indices = np.where(error_mask)[0]\n",
    "    \n",
    "    # Calcola confidenze per questo tipo di errore\n",
    "    error_confidences = []\n",
    "    for idx in error_indices:\n",
    "        confidence = y_pred_proba[idx, pred_digit]\n",
    "        error_confidences.append((idx, confidence))\n",
    "    \n",
    "    # Ordina per confidenza decrescente e prendi i primi 5\n",
    "    error_confidences.sort(key=lambda x: x[1], reverse=True)\n",
    "    selected_examples = error_confidences[:5]\n",
    "    \n",
    "    # Visualizza i 5 esempi\n",
    "    for example_idx, (img_idx, confidence) in enumerate(selected_examples):\n",
    "        ax = axes[conf_idx, example_idx]\n",
    "        ax.imshow(mnist_te_data[img_idx], cmap='gray')\n",
    "        ax.set_title(f'Conf: {confidence:.3f}', fontsize=10)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    # Etichetta per la riga\n",
    "    axes[conf_idx, 0].text(-0.1, 0.5, f'{true_digit}→{pred_digit}\\n({confusion_row[\"count\"]} err.)', \n",
    "                          transform=axes[conf_idx, 0].transAxes, \n",
    "                          fontsize=12, fontweight='bold', \n",
    "                          ha='right', va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analisi quantitativa delle confusioni\n",
    "print(\"\\nANALISI QUANTITATIVA CONFUSIONI:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Simmetria delle confusioni\n",
    "for _, row in top_6_confusions.iterrows():\n",
    "    true_digit = int(row['true_digit'])\n",
    "    pred_digit = int(row['predicted_digit'])\n",
    "    forward_confusion = cm[true_digit, pred_digit]\n",
    "    reverse_confusion = cm[pred_digit, true_digit]\n",
    "    \n",
    "    symmetry_ratio = min(forward_confusion, reverse_confusion) / max(forward_confusion, reverse_confusion)\n",
    "    print(f\"Confusione {true_digit}↔{pred_digit}: \"\n",
    "          f\"Simmetria {symmetry_ratio:.2f} \"\n",
    "          f\"({forward_confusion} vs {reverse_confusion} errori)\")\n",
    "\n",
    "# Concentrazione degli errori\n",
    "total_top6_errors = top_6_confusions['count'].sum()\n",
    "print(f\"\\nConcentrazione errori:\")\n",
    "print(f\"Top 6 confusioni rappresentano {total_top6_errors}/{total_errors} errori totali \"\n",
    "      f\"({total_top6_errors/total_errors*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Discussione del grafico e riflessione sui risultati\n",
    "\n",
    "\n",
    "\n",
    " L'identificazione delle **Top 6 confusioni** rivela pattern morfologici sistematici che il modello MLP fatica a discriminare: la confusione dominante **4→9** (9 errori) riflette la similitudine strutturale quando la connessione verticale del 4 si chiude parzialmente, mentre **7→2** (8 errori) emerge dalla condivisione di stroke orizzontali superiori e curvature che possono apparire ambigue in scritture corsive o imprecise.\n",
    "\n",
    "\n",
    "\n",
    " L'analisi della **simmetria** delle confusioni fornisce insights sulla natura direzionale degli errori: la coppia **2↔3** mostra perfetta simmetria (1.00) indicando equivalente difficoltà bidirezionale, mentre **8→3** presenta forte asimmetria (0.29) suggerendo che 8 viene facilmente scambiato per 3 ma non viceversa, probabilmente per la presenza di loop inferiore nel 8 che può apparire come curvatura semplice del 3.\n",
    "\n",
    "\n",
    "\n",
    " La **concentrazione degli errori** è moderata con le Top 6 confusioni che rappresentano solo il 21.6% degli errori totali (41/190), indicando che il modello non soffre di pattern di errore altamente localizzati ma presenta vulnerabilità distribuite. Gli esempi visualizzati confermano che anche le confusioni ad alta confidenza (0.70-0.85) coinvolgono casi effettivamente ambigui dove anche un osservatore umano potrebbe esitare, validando la ragionevolezza degli errori del modello e suggerendo che ulteriori miglioramenti richiederanno architetture più sofisticate o data augmentation mirata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Conclusioni\n",
    "\n",
    "\n",
    "\n",
    " **Architettura di riferimento:**\n",
    "\n",
    " L'analisi si è basata sul modello **MLP ottimale** (250 neuroni, 1 strato nascosto, learning rate 0.001) che raggiunge **98.10% di accuratezza** con soli 190 errori su 10.000 esempi di test, confermando l'eccellente bilanciamento tra prestazioni e complessità identificato nel Punto A.\n",
    "\n",
    "\n",
    "\n",
    " **Gerarchia di difficoltà identificata:**\n",
    "\n",
    " Emerge una chiara stratificazione delle cifre per difficoltà con **8, 2, 5** come le più problematiche (>2.4% errori) a causa della loro complessità morfologica intrinseca, mentre **0, 1** si confermano le più robuste (<1% errori) grazie a forme distintive e non ambigue.\n",
    "\n",
    "\n",
    "\n",
    " **Pattern di confusione sistematici:**\n",
    "\n",
    " Le **Top 6 confusioni** rivelano errori concentrati su coppie morfologicamente giustificate (4↔9, 7↔2, 8↔3) con asimmetrie significative che riflettono specificità percettive del modello. La distribuzione moderata degli errori (21.6% concentrati) indica robustezza generale senza vulnerabilità critiche localizzate.\n",
    "\n",
    "\n",
    "\n",
    " **Meccanismo di calibrazione della confidenza:**\n",
    "\n",
    " Il modello dimostra eccellente **autoconsapevolezza** con confidenze elevate per predizioni corrette (0.990-0.998) e significativamente ridotte per errori (0.722-0.845), fornendo un naturale meccanismo di early warning utilizzabile in deployment critico con soglie appropriate.\n",
    "\n",
    "\n",
    "\n",
    " **Implicazioni per il miglioramento:**\n",
    "\n",
    " I risultati suggeriscono che ulteriori guadagni richiederanno interventi mirati: **data augmentation** per cifre problematiche (8, 2, 5), **fine-tuning** su confusioni specifiche, o **architetture convoluzionali** per catturare invarianze spaziali più sofisticate, dato che gli errori residui coinvolgono casi di genuine ambiguità morfologica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Punto C: Curve psicometriche - Effetto del rumore\n",
    "\n",
    "\n",
    "\n",
    " Analizziamo sistematicamente come l'accuratezza di riconoscimento degrada all'aumentare del rumore Gaussiano aggiunto alle immagini di test. Questa analisi è cruciale per comprendere la robustezza dei modelli in condizioni reali dove i dati possono essere corrotti da rumore di acquisizione, compressione o trasmissione.\n",
    "\n",
    "\n",
    "\n",
    " L'analisi utilizza le architetture ottimali identificate nel Punto A per fornire un assessment accurato della robustezza intrinseca di diversi approcci di machine learning su dati visivi corrotti."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Selezione delle architetture ottimali\n",
    "\n",
    "\n",
    "\n",
    " Utilizziamo le architetture leader identificate nel Punto A per garantire che l'analisi di robustezza si basi sulle migliori configurazioni disponibili, fornendo così un benchmark realistico per applicazioni pratiche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELEZIONE ARCHITETTURE PER ANALISI ROBUSTEZZA\n",
      "============================================================\n",
      "MLP ottimale: 250n_1S_lr0.001\n",
      "  • Accuratezza: 0.9810\n",
      "  • Architettura: (250,)\n",
      "  • Learning rate: 0.001\n",
      "\n",
      "CNN ottimale: CNN_extended_lr0.001\n",
      "  • Accuratezza: 0.9885\n",
      "  • Architettura: extended\n",
      "  • Learning rate: 0.001\n"
     ]
    }
   ],
   "source": [
    "# Selezione architetture ottimali dal Punto A\n",
    "migliore_mlp_config = max(risultati_mlp, key=lambda x: x['test_accuracy'])\n",
    "migliore_cnn_config = max(risultati_cnn, key=lambda x: x['test_accuracy'])\n",
    "\n",
    "print(\"SELEZIONE ARCHITETTURE PER ANALISI ROBUSTEZZA\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"MLP ottimale: {migliore_mlp_config['nome_config']}\")\n",
    "print(f\"  • Accuratezza: {migliore_mlp_config['test_accuracy']:.4f}\")\n",
    "print(f\"  • Architettura: {migliore_mlp_config['strati_nascosti']}\")\n",
    "print(f\"  • Learning rate: {migliore_mlp_config['learning_rate']}\")\n",
    "\n",
    "print(f\"\\nCNN ottimale: {migliore_cnn_config['nome_config']}\")\n",
    "print(f\"  • Accuratezza: {migliore_cnn_config['test_accuracy']:.4f}\")\n",
    "print(f\"  • Architettura: {migliore_cnn_config['architettura']}\")\n",
    "print(f\"  • Learning rate: {migliore_cnn_config['learning_rate']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training modelli ottimali...\n",
      "Training MLP...\n",
      "MLP - Training time: 23.2s, Clean accuracy: 0.9810\n",
      "Training CNN...\n",
      "CNN - Training time: 108.3s, Clean accuracy: 0.9876\n"
     ]
    }
   ],
   "source": [
    "# Training dei modelli ottimali per analisi robustezza\n",
    "print(\"\\nTraining modelli ottimali...\")\n",
    "\n",
    "# Training MLP ottimale\n",
    "mlp_robustezza = MLPClassifier(\n",
    "    hidden_layer_sizes=migliore_mlp_config['strati_nascosti'],\n",
    "    learning_rate_init=migliore_mlp_config['learning_rate'],\n",
    "    max_iter=100,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.1,\n",
    "    tol=0.001,\n",
    "    n_iter_no_change=10,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Training MLP...\")\n",
    "start_time = time.time()\n",
    "mlp_robustezza.fit(x_tr, mnist_tr_labels)\n",
    "mlp_training_time = time.time() - start_time\n",
    "\n",
    "mlp_clean_acc = mlp_robustezza.score(x_te, mnist_te_labels)\n",
    "print(f\"MLP - Training time: {mlp_training_time:.1f}s, Clean accuracy: {mlp_clean_acc:.4f}\")\n",
    "\n",
    "# Training CNN ottimale\n",
    "cnn_robustezza = crea_modello_cnn(\n",
    "    migliore_cnn_config['architettura'], \n",
    "    migliore_cnn_config['learning_rate']\n",
    ")\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    patience=5, min_delta=0.001, restore_best_weights=True, verbose=0\n",
    ")\n",
    "\n",
    "print(\"Training CNN...\")\n",
    "start_time = time.time()\n",
    "cnn_robustezza.fit(\n",
    "    x_tr_conv, mnist_tr_labels,\n",
    "    validation_split=0.1, epochs=20, batch_size=128,\n",
    "    callbacks=[early_stopping], verbose=0\n",
    ")\n",
    "cnn_training_time = time.time() - start_time\n",
    "\n",
    "_, cnn_clean_acc = cnn_robustezza.evaluate(x_te_conv, mnist_te_labels, verbose=0)\n",
    "print(f\"CNN - Training time: {cnn_training_time:.1f}s, Clean accuracy: {cnn_clean_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Funzioni helper per analisi robustezza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gaussian_noise(images, noise_std):\n",
    "    \"\"\"Aggiunge rumore Gaussiano alle immagini.\"\"\"\n",
    "    np.random.seed(42)  # Per riproducibilità\n",
    "    noise = np.random.normal(0, noise_std, images.shape)\n",
    "    noisy_images = images + noise\n",
    "    return np.clip(noisy_images, 0, 1)\n",
    "\n",
    "def test_model_robustezza(model, x_test, y_test, noise_levels, is_cnn=False):\n",
    "    \"\"\"Testa la robustezza di un modello a diversi livelli di rumore.\"\"\"\n",
    "    accuracies = []\n",
    "    \n",
    "    for noise_std in noise_levels:\n",
    "        # Prepara dati rumorosi\n",
    "        x_noisy = add_gaussian_noise(x_test, noise_std)\n",
    "        \n",
    "        # Calcola accuratezza\n",
    "        if is_cnn:\n",
    "            # Per CNN, rimodella in formato 4D se necessario\n",
    "            if len(x_noisy.shape) == 2:\n",
    "                x_noisy = x_noisy.reshape(-1, 28, 28, 1)\n",
    "            _, acc = model.evaluate(x_noisy, y_test, verbose=0)\n",
    "        else:\n",
    "            # Per MLP, assicura formato 2D\n",
    "            if len(x_noisy.shape) == 4:\n",
    "                x_noisy = x_noisy.reshape(x_noisy.shape[0], -1)\n",
    "            acc = model.score(x_noisy, y_test)\n",
    "        \n",
    "        accuracies.append(acc)\n",
    "    \n",
    "    return accuracies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Configurazione esperimento robustezza\n",
    "\n",
    "\n",
    "\n",
    " **Range di rumore:** 0.00-0.45 con step 0.05 per catturare degradazioni significative\n",
    "\n",
    " **Subset di test:** 2000 campioni stratificati per bilanciare velocità computazionale e rappresentatività statistica\n",
    "\n",
    " **Metriche:** Accuratezza per livello di rumore globale e per singola classe per identificare vulnerabilità specifiche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset stratificato: 2000 campioni\n",
      "Range rumore: 0.00 - 0.45 (step 0.05)\n",
      "Livelli testati: 10\n"
     ]
    }
   ],
   "source": [
    "# Configurazione esperimento con range esteso\n",
    "noise_levels = np.arange(0.00, 0.50, 0.05)  # Range esteso fino a 0.50\n",
    "subset_size = 2000  # Ridotto per velocità ma mantenendo rappresentatività\n",
    "\n",
    "# Campionamento stratificato per mantenere bilanciamento classi\n",
    "indices_stratificati = []\n",
    "for digit in range(10):\n",
    "    digit_indices = np.where(mnist_te_labels == digit)[0]\n",
    "    n_samples = subset_size // 10\n",
    "    selected = np.random.choice(digit_indices, n_samples, replace=False)\n",
    "    indices_stratificati.extend(selected)\n",
    "\n",
    "indices_stratificati = np.array(indices_stratificati)\n",
    "x_te_subset = x_te[indices_stratificati]\n",
    "y_te_subset = mnist_te_labels[indices_stratificati]\n",
    "\n",
    "print(f\"Subset stratificato: {len(indices_stratificati)} campioni\")\n",
    "print(f\"Range rumore: {noise_levels[0]:.2f} - {noise_levels[-1]:.2f} (step {noise_levels[1]-noise_levels[0]:.2f})\")\n",
    "print(f\"Livelli testati: {len(noise_levels)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Calcolo curve psicometriche sistematiche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calcolo robustezza modelli...\n",
      "Testing MLP...\n",
      "Testing CNN...\n",
      "\n",
      "RISULTATI ROBUSTEZZA AL RUMORE:\n",
      "--------------------------------------------------\n",
      "Noise σ  | MLP Acc | CNN Acc | Differenza\n",
      "--------------------------------------------------\n",
      "  0.00 |  0.9795 |  0.9900 |  +0.0105\n",
      "  0.05 |  0.9790 |  0.9885 |  +0.0095\n",
      "  0.10 |  0.9705 |  0.9880 |  +0.0175\n",
      "  0.15 |  0.9540 |  0.9825 |  +0.0285\n",
      "  0.20 |  0.8970 |  0.9795 |  +0.0825\n",
      "  0.25 |  0.8135 |  0.9710 |  +0.1575\n",
      "  0.30 |  0.7390 |  0.9580 |  +0.2190\n",
      "  0.35 |  0.6605 |  0.9165 |  +0.2560\n",
      "  0.40 |  0.5915 |  0.8540 |  +0.2625\n",
      "  0.45 |  0.5240 |  0.7790 |  +0.2550\n",
      "\n",
      "METRICHE AGGREGATE:\n",
      "AUC MLP: 0.368 | AUC CNN: 0.426 | Rapporto: 1.158\n"
     ]
    }
   ],
   "source": [
    "# Test robustezza modelli\n",
    "print(\"\\nCalcolo robustezza modelli...\")\n",
    "\n",
    "# Test robustezza MLP\n",
    "print(\"Testing MLP...\")\n",
    "accuracies_mlp = test_model_robustezza(\n",
    "    mlp_robustezza, x_te_subset, y_te_subset, noise_levels, is_cnn=False\n",
    ")\n",
    "\n",
    "# Test robustezza CNN  \n",
    "print(\"Testing CNN...\")\n",
    "accuracies_cnn = test_model_robustezza(\n",
    "    cnn_robustezza, x_te_subset, y_te_subset, noise_levels, is_cnn=True\n",
    ")\n",
    "\n",
    "# Stampa risultati tabulari\n",
    "print(\"\\nRISULTATI ROBUSTEZZA AL RUMORE:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"Noise σ  | MLP Acc | CNN Acc | Differenza\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for noise, mlp_acc, cnn_acc in zip(noise_levels, accuracies_mlp, accuracies_cnn):\n",
    "    diff = cnn_acc - mlp_acc\n",
    "    print(f\"{noise:6.2f} | {mlp_acc:7.4f} | {cnn_acc:7.4f} | {diff:+8.4f}\")\n",
    "\n",
    "# Calcolo metriche aggregate\n",
    "auc_mlp = np.trapz(accuracies_mlp, noise_levels)\n",
    "auc_cnn = np.trapz(accuracies_cnn, noise_levels)\n",
    "\n",
    "print(f\"\\nMETRICHE AGGREGATE:\")\n",
    "print(f\"AUC MLP: {auc_mlp:.3f} | AUC CNN: {auc_cnn:.3f} | Rapporto: {auc_cnn/auc_mlp:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Analisi robustezza per singola classe\n",
    "\n",
    "\n",
    "\n",
    " Questa analisi rivela quali cifre sono più vulnerabili al rumore e permette di identificare pattern di degradazione classe-specifici, informazione cruciale per comprendere i limiti intrinseci dei modelli e pianificare interventi mirati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calcolo robustezza per singola classe...\n",
      "Analisi per classe completata.\n"
     ]
    }
   ],
   "source": [
    "# Calcolo degradazione per singola classe\n",
    "def calcola_robustezza_per_classe(model, x_test, y_test, noise_levels, is_cnn=False):\n",
    "    \"\"\"Calcola accuratezza per classe a diversi livelli di rumore.\"\"\"\n",
    "    risultati_per_classe = {}\n",
    "    \n",
    "    for digit in range(10):\n",
    "        # Seleziona campioni della classe specifica\n",
    "        mask = y_test == digit\n",
    "        x_digit = x_test[mask]\n",
    "        y_digit = y_test[mask]\n",
    "        \n",
    "        if len(x_digit) == 0:\n",
    "            continue\n",
    "            \n",
    "        accuracies_digit = []\n",
    "        \n",
    "        for noise_std in noise_levels:\n",
    "            x_noisy = add_gaussian_noise(x_digit, noise_std)\n",
    "            \n",
    "            if is_cnn:\n",
    "                if len(x_noisy.shape) == 2:\n",
    "                    x_noisy = x_noisy.reshape(-1, 28, 28, 1)\n",
    "                y_pred = model.predict(x_noisy, verbose=0)\n",
    "                y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "            else:\n",
    "                if len(x_noisy.shape) == 4:\n",
    "                    x_noisy = x_noisy.reshape(x_noisy.shape[0], -1)\n",
    "                y_pred_classes = model.predict(x_noisy)\n",
    "            \n",
    "            acc = np.mean(y_pred_classes == y_digit)\n",
    "            accuracies_digit.append(acc)\n",
    "        \n",
    "        risultati_per_classe[digit] = accuracies_digit\n",
    "    \n",
    "    return risultati_per_classe\n",
    "\n",
    "print(\"Calcolo robustezza per singola classe...\")\n",
    "\n",
    "# Analisi per classe\n",
    "robustezza_mlp_per_classe = calcola_robustezza_per_classe(\n",
    "    mlp_robustezza, x_te_subset, y_te_subset, noise_levels, is_cnn=False\n",
    ")\n",
    "\n",
    "robustezza_cnn_per_classe = calcola_robustezza_per_classe(\n",
    "    cnn_robustezza, x_te_subset, y_te_subset, noise_levels, is_cnn=True\n",
    ")\n",
    "\n",
    "print(\"Analisi per classe completata.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Grafico 1: Curve Psicometriche Principali\n",
    "\n",
    "\n",
    "\n",
    " Questo grafico presenta il confronto diretto tra MLP e CNN in termini di robustezza al rumore, mostrando sia l'accuratezza assoluta che la degradazione relativa. La visualizzazione permette di identificare immediatamente quale architettura mantiene prestazioni superiori all'aumentare del rumore e a quali soglie critiche si verificano i crolli prestazionali."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Grafico 1: Curve Psicometriche Principali\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Subplot 1: Confronto diretto MLP vs CNN\n",
    "ax1.plot(noise_levels, accuracies_mlp, 'o-', linewidth=3, markersize=8, \n",
    "         color='blue', label='MLP Ottimale', alpha=0.8)\n",
    "ax1.plot(noise_levels, accuracies_cnn, 's-', linewidth=3, markersize=8, \n",
    "         color='red', label='CNN Ottimale', alpha=0.8)\n",
    "\n",
    "ax1.set_xlabel('Deviazione Standard del Rumore (σ)', fontsize=12)\n",
    "ax1.set_ylabel('Accuratezza', fontsize=12)\n",
    "ax1.set_title('Curve Psicometriche: Robustezza al Rumore\\nMLP vs CNN', fontsize=14)\n",
    "ax1.legend(fontsize=12)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim(0, 1.05)\n",
    "\n",
    "# Annotazioni per punti critici - Soglia 90%\n",
    "for i, (noise, acc_mlp, acc_cnn) in enumerate(zip(noise_levels, accuracies_mlp, accuracies_cnn)):\n",
    "    if acc_mlp < 0.9 and i > 0 and accuracies_mlp[i-1] >= 0.9:\n",
    "        ax1.axvline(x=noise, color='blue', linestyle='--', alpha=0.7)\n",
    "        ax1.text(noise, 0.92, f'MLP<90%\\nσ={noise:.2f}', \n",
    "                ha='center', va='bottom', fontsize=10, color='blue',\n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightblue\", alpha=0.7))\n",
    "        break\n",
    "\n",
    "for i, (noise, acc_mlp, acc_cnn) in enumerate(zip(noise_levels, accuracies_mlp, accuracies_cnn)):\n",
    "    if acc_cnn < 0.9 and i > 0 and accuracies_cnn[i-1] >= 0.9:\n",
    "        ax1.axvline(x=noise, color='red', linestyle='--', alpha=0.7)\n",
    "        ax1.text(noise, 0.85, f'CNN<90%\\nσ={noise:.2f}', \n",
    "                ha='center', va='bottom', fontsize=10, color='red',\n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightcoral\", alpha=0.7))\n",
    "        break\n",
    "\n",
    "# Subplot 2: Degradazione relativa\n",
    "degradazione_mlp = [(accuracies_mlp[0] - acc) / accuracies_mlp[0] * 100 for acc in accuracies_mlp]\n",
    "degradazione_cnn = [(accuracies_cnn[0] - acc) / accuracies_cnn[0] * 100 for acc in accuracies_cnn]\n",
    "\n",
    "ax2.plot(noise_levels, degradazione_mlp, 'o-', linewidth=3, markersize=8, \n",
    "         color='blue', label='MLP Ottimale', alpha=0.8)\n",
    "ax2.plot(noise_levels, degradazione_cnn, 's-', linewidth=3, markersize=8, \n",
    "         color='red', label='CNN Ottimale', alpha=0.8)\n",
    "\n",
    "ax2.set_xlabel('Deviazione Standard del Rumore (σ)', fontsize=12)\n",
    "ax2.set_ylabel('Degradazione Relativa (%)', fontsize=12)\n",
    "ax2.set_title('Degradazione Relativa delle Prestazioni\\n(% rispetto a condizioni pulite)', fontsize=14)\n",
    "ax2.legend(fontsize=12)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Discussione del grafico e riflessione sui risultati\n",
    "\n",
    "\n",
    "\n",
    " Le curve psicometriche rivelano comportamenti distintivi tra le architetture: il confronto diretto mostra come [discussione basata sui risultati specifici]. La degradazione relativa evidenzia [pattern di resilienza specifici]. Le soglie critiche identificate forniscono riferimenti operativi cruciali per deployment in ambienti con livelli di rumore variabili."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Grafico 2: Robustezza per Singola Classe\n",
    "\n",
    "\n",
    "\n",
    " Questo grafico visualizza come ogni cifra (0-9) degrada progressivamente all'aumentare del rumore per entrambe le architetture. La visualizzazione a linee multiple permette di identificare immediatamente le classi più vulnerabili e confrontare i pattern di robustezza classe-specifici tra MLP e CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ANALISI DEGRADAZIONE PER CLASSE:\n",
      "----------------------------------------------------------------------\n",
      "Cifra | MLP: Clean->Final (Δ) | CNN: Clean->Final (Δ) | CNN Vantaggio\n",
      "----------------------------------------------------------------------\n",
      "  0   | 0.985->0.740 (+0.245) | 0.985->0.860 (+0.125) | +0.120\n",
      "  1   | 0.985->0.005 (+0.980) | 0.995->0.210 (+0.785) | +0.195\n",
      "  2   | 0.990->0.710 (+0.280) | 0.990->0.945 (+0.045) | +0.235\n",
      "  3   | 0.990->0.765 (+0.225) | 0.990->0.950 (+0.040) | +0.185\n",
      "  4   | 0.985->0.095 (+0.890) | 0.990->0.870 (+0.120) | +0.770\n",
      "  5   | 0.960->0.850 (+0.110) | 0.990->0.870 (+0.120) | -0.010\n",
      "  6   | 0.965->0.685 (+0.280) | 0.985->0.735 (+0.250) | +0.030\n",
      "  7   | 0.980->0.505 (+0.475) | 0.990->0.770 (+0.220) | +0.255\n",
      "  8   | 0.975->0.620 (+0.355) | 0.995->0.990 (+0.005) | +0.350\n",
      "  9   | 0.980->0.190 (+0.790) | 0.990->0.655 (+0.335) | +0.455\n"
     ]
    }
   ],
   "source": [
    "# Grafico 2: Robustezza per Singola Classe (Line Plot)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7))\n",
    "\n",
    "# Subplot 1: MLP per classe\n",
    "colors_mlp = plt.cm.tab10(np.linspace(0, 1, 10))\n",
    "for digit in range(10):\n",
    "    if digit in robustezza_mlp_per_classe:\n",
    "        ax1.plot(noise_levels, robustezza_mlp_per_classe[digit], \n",
    "                'o-', color=colors_mlp[digit], label=f'Cifra {digit}', \n",
    "                linewidth=2, markersize=5, alpha=0.8)\n",
    "\n",
    "ax1.set_xlabel('Deviazione Standard del Rumore (σ)', fontsize=12)\n",
    "ax1.set_ylabel('Accuratezza per Classe', fontsize=12)\n",
    "ax1.set_title('Robustezza per Classe - MLP Ottimale', fontsize=14)\n",
    "ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim(0, 1.05)\n",
    "\n",
    "# Subplot 2: CNN per classe\n",
    "colors_cnn = plt.cm.tab10(np.linspace(0, 1, 10))\n",
    "for digit in range(10):\n",
    "    if digit in robustezza_cnn_per_classe:\n",
    "        ax2.plot(noise_levels, robustezza_cnn_per_classe[digit], \n",
    "                's-', color=colors_cnn[digit], label=f'Cifra {digit}', \n",
    "                linewidth=2, markersize=5, alpha=0.8)\n",
    "\n",
    "ax2.set_xlabel('Deviazione Standard del Rumore (σ)', fontsize=12)\n",
    "ax2.set_ylabel('Accuratezza per Classe', fontsize=12)\n",
    "ax2.set_title('Robustezza per Classe - CNN Ottimale', fontsize=14)\n",
    "ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_ylim(0, 1.05)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analisi quantitativa degradazione per classe\n",
    "print(\"\\nANALISI DEGRADAZIONE PER CLASSE:\")\n",
    "print(\"-\" * 70)\n",
    "print(\"Cifra | MLP: Clean->Final (Δ) | CNN: Clean->Final (Δ) | CNN Vantaggio\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for digit in range(10):\n",
    "    if digit in robustezza_mlp_per_classe and digit in robustezza_cnn_per_classe:\n",
    "        mlp_clean = robustezza_mlp_per_classe[digit][0]\n",
    "        mlp_final = robustezza_mlp_per_classe[digit][-1]\n",
    "        mlp_deg = mlp_clean - mlp_final\n",
    "        \n",
    "        cnn_clean = robustezza_cnn_per_classe[digit][0]\n",
    "        cnn_final = robustezza_cnn_per_classe[digit][-1]\n",
    "        cnn_deg = cnn_clean - cnn_final\n",
    "        \n",
    "        vantaggio = mlp_deg - cnn_deg\n",
    "        \n",
    "        print(f\"  {digit}   | {mlp_clean:.3f}->{mlp_final:.3f} ({mlp_deg:+.3f}) | \"\n",
    "              f\"{cnn_clean:.3f}->{cnn_final:.3f} ({cnn_deg:+.3f}) | {vantaggio:+.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Discussione del grafico e riflessione sui risultati\n",
    "\n",
    "\n",
    "\n",
    " L'analisi per singola classe rivela pattern di vulnerabilità [specifici in base ai risultati]. Le cifre più problematiche mostrano [descrizione pattern]. La comparazione tra architetture evidenzia che [confronto MLP vs CNN per robustezza classe-specifica]. Questi insights sono cruciali per comprendere quali tipi di errori potrebbero emergere in condizioni di rumore reale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Grafico 3: Esempio Visivo dell'Effetto del Rumore\n",
    "\n",
    "\n",
    "\n",
    " Questa visualizzazione mostra l'effetto progressivo del rumore Gaussiano su un esempio reale, permettendo di comprendere visivamente a quale livello di corruzione le immagini diventano ambigue anche per l'osservatore umano. Include le predizioni di entrambi i modelli per validare l'allineamento con la percezione umana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Grafico 3: Esempio Visivo del Rumore\n",
    "# Selezione di un singolo esempio per visualizzazione\n",
    "esempio_idx = np.where(y_te_subset == 8)[0][0]  # Cifra 8 come esempio\n",
    "esempio_img = x_te_subset[esempio_idx]\n",
    "\n",
    "# Livelli di rumore selezionati per visualizzazione\n",
    "noise_demo_levels = [0.0, 0.1, 0.2, 0.3, 0.4]\n",
    "\n",
    "fig, axes = plt.subplots(1, len(noise_demo_levels), figsize=(15, 3))\n",
    "fig.suptitle('Effetto Progressivo del Rumore Gaussiano (Cifra 8)', fontsize=14, y=1.05)\n",
    "\n",
    "for i, noise_std in enumerate(noise_demo_levels):\n",
    "    if noise_std == 0:\n",
    "        noisy_img = esempio_img\n",
    "    else:\n",
    "        noisy_img = add_gaussian_noise(esempio_img.reshape(1, -1), noise_std)[0]\n",
    "    \n",
    "    # Test predizioni\n",
    "    img_2d = noisy_img.reshape(1, -1)\n",
    "    img_4d = img_2d.reshape(1, 28, 28, 1)\n",
    "    \n",
    "    pred_mlp = mlp_robustezza.predict(img_2d)[0]\n",
    "    prob_mlp = np.max(mlp_robustezza.predict_proba(img_2d))\n",
    "    \n",
    "    pred_cnn = np.argmax(cnn_robustezza.predict(img_4d, verbose=0))\n",
    "    prob_cnn = np.max(cnn_robustezza.predict(img_4d, verbose=0))\n",
    "    \n",
    "    # Visualizzazione\n",
    "    ax = axes[i]\n",
    "    ax.imshow(noisy_img.reshape(28, 28), cmap='gray', vmin=0, vmax=1)\n",
    "    ax.set_title(f'σ = {noise_std:.1f}', fontsize=12, fontweight='bold')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Annotazioni predizioni\n",
    "    status_mlp = \"✓\" if pred_mlp == 8 else \"✗\"\n",
    "    status_cnn = \"✓\" if pred_cnn == 8 else \"✗\"\n",
    "    \n",
    "    ax.text(0.5, -0.1, f'MLP: {pred_mlp}({prob_mlp:.2f}){status_mlp}\\nCNN: {pred_cnn}({prob_cnn:.2f}){status_cnn}', \n",
    "            transform=ax.transAxes, ha='center', va='top', fontsize=10,\n",
    "            bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Discussione del grafico e riflessione sui risultati\n",
    "\n",
    "\n",
    "\n",
    " L'esempio visivo della cifra 8 con rumore progressivo dimostra [allineamento/disallineamento con percezione umana]. Le predizioni dei modelli mostrano [pattern di degradazione delle confidenze]. Il confronto MLP vs CNN rivela [differenze comportamentali specifiche] che si allineano con i risultati quantitativi delle curve psicometriche."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Analisi comparativa robustezza\n",
    "\n",
    "\n",
    "\n",
    " Questa sezione fornisce una valutazione quantitativa sistematica delle differenze di robustezza tra MLP e CNN, identificando soglie critiche e pattern di degradazione per informare decisioni di deployment in ambienti con diversi livelli di rumore atteso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SOGLIE CRITICHE DI DEGRADAZIONE:\n",
      "--------------------------------------------------\n",
      "Accuratezza | MLP σ-critical | CNN σ-critical | Vantaggio CNN\n",
      "--------------------------------------------------\n",
      "     0.9   |      0.2     |      0.35000000000000003     |      +0.15\n",
      "     0.9   |      0.2     |      0.4     |      +0.20\n",
      "     0.8   |      0.30000000000000004     |      0.45     |      +0.15\n",
      "     0.7   |      0.35000000000000003     |      None     |      N/A\n",
      "\n",
      "TASSO DI DEGRADAZIONE (Δ Acc / Δ σ):\n",
      "MLP: 1.0122 acc/σ\n",
      "CNN: 0.4689 acc/σ\n",
      "Rapporto resilienza (MLP/CNN): 2.16x - CNN più robusta\n"
     ]
    }
   ],
   "source": [
    "# Analisi soglie critiche di degradazione\n",
    "def trova_soglie_critiche(noise_levels, accuracies, soglie=[0.95, 0.9, 0.8, 0.7]):\n",
    "    \"\"\"Trova i livelli di rumore corrispondenti a soglie di accuratezza specifiche.\"\"\"\n",
    "    soglie_rumore = {}\n",
    "    for soglia in soglie:\n",
    "        idx_soglia = np.where(np.array(accuracies) < soglia)[0]\n",
    "        if len(idx_soglia) > 0:\n",
    "            soglie_rumore[soglia] = noise_levels[idx_soglia[0]]\n",
    "        else:\n",
    "            soglie_rumore[soglia] = None\n",
    "    return soglie_rumore\n",
    "\n",
    "# Calcolo soglie critiche\n",
    "soglie_mlp = trova_soglie_critiche(noise_levels, accuracies_mlp)\n",
    "soglie_cnn = trova_soglie_critiche(noise_levels, accuracies_cnn)\n",
    "\n",
    "print(\"\\nSOGLIE CRITICHE DI DEGRADAZIONE:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"Accuratezza | MLP σ-critical | CNN σ-critical | Vantaggio CNN\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for soglia in [0.95, 0.9, 0.8, 0.7]:\n",
    "    mlp_noise = soglie_mlp.get(soglia, '>0.45')\n",
    "    cnn_noise = soglie_cnn.get(soglia, '>0.45')\n",
    "    \n",
    "    if isinstance(mlp_noise, (int, float)) and isinstance(cnn_noise, (int, float)):\n",
    "        vantaggio = cnn_noise - mlp_noise\n",
    "        vantaggio_str = f\"{vantaggio:+.2f}\"\n",
    "    else:\n",
    "        vantaggio_str = \"N/A\"\n",
    "    \n",
    "    print(f\"    {soglia:4.1f}   |      {mlp_noise}     |      {cnn_noise}     |      {vantaggio_str}\")\n",
    "\n",
    "# Tasso di degradazione\n",
    "tasso_degradazione_mlp = (accuracies_mlp[0] - accuracies_mlp[-1]) / (noise_levels[-1] - noise_levels[0])\n",
    "tasso_degradazione_cnn = (accuracies_cnn[0] - accuracies_cnn[-1]) / (noise_levels[-1] - noise_levels[0])\n",
    "\n",
    "print(f\"\\nTASSO DI DEGRADAZIONE (Δ Acc / Δ σ):\")\n",
    "print(f\"MLP: {tasso_degradazione_mlp:.4f} acc/σ\")\n",
    "print(f\"CNN: {tasso_degradazione_cnn:.4f} acc/σ\") \n",
    "\n",
    "if tasso_degradazione_cnn < tasso_degradazione_mlp:\n",
    "    rapporto_resilienza = tasso_degradazione_mlp / tasso_degradazione_cnn\n",
    "    print(f\"Rapporto resilienza (MLP/CNN): {rapporto_resilienza:.2f}x - CNN più robusta\")\n",
    "else:\n",
    "    rapporto_resilienza = tasso_degradazione_cnn / tasso_degradazione_mlp  \n",
    "    print(f\"Rapporto resilienza (CNN/MLP): {rapporto_resilienza:.2f}x - MLP più robusta\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Conclusioni del Punto C\n",
    "\n",
    "\n",
    "\n",
    " **Prestazioni baseline identificate:**\n",
    "\n",
    " L'analisi si è basata su architetture ottimali che raggiungono prestazioni di riferimento elevate su dati puliti, fornendo un benchmark affidabile per la valutazione della robustezza.\n",
    "\n",
    "\n",
    "\n",
    " **Pattern di degradazione sistematici:**\n",
    "\n",
    " [I risultati specifici determineranno i pattern osservati]\n",
    "\n",
    "\n",
    "\n",
    " **Vulnerabilità classe-specifiche:**\n",
    "\n",
    " [Identificazione delle cifre più/meno robuste al rumore]\n",
    "\n",
    "\n",
    "\n",
    " **Soglie critiche per deployment:**\n",
    "\n",
    " [Livelli di rumore critici per mantenere prestazioni accettabili]\n",
    "\n",
    "\n",
    "\n",
    " **Raccomandazioni operative:**\n",
    "\n",
    " [Linee guida basate sui risultati sperimentali per applicazioni reali]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Punto D: Effetto della riduzione dei dati di training\n",
    "\n",
    "\n",
    "\n",
    " Analizziamo come le prestazioni degradano quando riduciamo drasticamente la quantità di dati di training disponibili."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test con riduzione dei dati di training...\n",
      "\n",
      "Training con 1% dei dati...\n",
      "Samples utilizzati: 596 su 60000\n",
      "Train acc: 0.9698, Test acc: 0.8661\n",
      "\n",
      "Training con 5% dei dati...\n",
      "Samples utilizzati: 2996 su 60000\n",
      "Train acc: 0.9853, Test acc: 0.9235\n",
      "\n",
      "Training con 10% dei dati...\n",
      "Samples utilizzati: 5996 su 60000\n",
      "Train acc: 0.9945, Test acc: 0.9445\n",
      "\n",
      "Training con 25% dei dati...\n",
      "Samples utilizzati: 14995 su 60000\n",
      "Train acc: 0.9832, Test acc: 0.9556\n",
      "\n",
      "Training con 50% dei dati...\n",
      "Samples utilizzati: 29997 su 60000\n",
      "Train acc: 0.9974, Test acc: 0.9726\n",
      "\n",
      "Training con 75% dei dati...\n",
      "Samples utilizzati: 44995 su 60000\n",
      "Train acc: 0.9968, Test acc: 0.9742\n",
      "\n",
      "Training con 100% dei dati...\n",
      "Samples utilizzati: 60000 su 60000\n",
      "Train acc: 0.9957, Test acc: 0.9784\n"
     ]
    }
   ],
   "source": [
    "# Test con diverse percentuali di dati di training\n",
    "train_percentages = [1, 5, 10, 25, 50, 75, 100]\n",
    "results_data_reduction = []\n",
    "\n",
    "print(\"Test con riduzione dei dati di training...\")\n",
    "for percentage in train_percentages:\n",
    "    print(f\"\\nTraining con {percentage}% dei dati...\")\n",
    "    \n",
    "    # Campionamento stratificato per mantenere bilanciamento classi\n",
    "    indices = []\n",
    "    for digit in range(10):\n",
    "        digit_indices = np.where(mnist_tr_labels == digit)[0]\n",
    "        n_digit_samples = int(len(digit_indices) * percentage / 100)\n",
    "        if n_digit_samples > 0:\n",
    "            selected_indices = np.random.choice(digit_indices, n_digit_samples, replace=False)\n",
    "            indices.extend(selected_indices)\n",
    "    \n",
    "    indices = np.array(indices)\n",
    "    x_tr_reduced = x_tr[indices]\n",
    "    y_tr_reduced = mnist_tr_labels[indices]\n",
    "    \n",
    "    print(f\"Samples utilizzati: {len(indices)} su {len(x_tr)}\")\n",
    "    \n",
    "    # Training MLP\n",
    "    mlp_reduced = MLPClassifier(\n",
    "        hidden_layer_sizes=(100, 100),\n",
    "        max_iter=100,\n",
    "        random_state=42,\n",
    "        early_stopping=True,\n",
    "        validation_fraction=0.1 if len(indices) > 100 else 0.2\n",
    "    )\n",
    "    \n",
    "    start_time = time.time()\n",
    "    mlp_reduced.fit(x_tr_reduced, y_tr_reduced)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    train_acc = mlp_reduced.score(x_tr_reduced, y_tr_reduced)\n",
    "    test_acc = mlp_reduced.score(x_te, mnist_te_labels)\n",
    "    \n",
    "    results_data_reduction.append({\n",
    "        'percentage': percentage,\n",
    "        'n_samples': len(indices),\n",
    "        'train_accuracy': train_acc,\n",
    "        'test_accuracy': test_acc,\n",
    "        'overfitting': train_acc - test_acc,\n",
    "        'training_time': training_time\n",
    "    })\n",
    "    \n",
    "    print(f\"Train acc: {train_acc:.4f}, Test acc: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizzazione effetto riduzione dati\n",
    "df_reduction = pd.DataFrame(results_data_reduction)\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Grafico 1: Accuratezza vs percentuale dati\n",
    "ax1.plot(df_reduction['percentage'], df_reduction['test_accuracy'], 'o-', \n",
    "        linewidth=3, markersize=10, color='darkblue', label='Test')\n",
    "ax1.plot(df_reduction['percentage'], df_reduction['train_accuracy'], 's-', \n",
    "        linewidth=3, markersize=10, color='lightblue', label='Train')\n",
    "ax1.set_xlabel('Percentuale di dati di training utilizzati (%)')\n",
    "ax1.set_ylabel('Accuratezza')\n",
    "ax1.set_title('Effetto della riduzione dei dati di training')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Evidenzio il punto al 10%\n",
    "idx_10 = df_reduction[df_reduction['percentage'] == 10].index[0]\n",
    "ax1.scatter(10, df_reduction.loc[idx_10, 'test_accuracy'], \n",
    "          s=200, color='red', zorder=5)\n",
    "ax1.annotate(f\"10%: {df_reduction.loc[idx_10, 'test_accuracy']:.3f}\", \n",
    "           xy=(10, df_reduction.loc[idx_10, 'test_accuracy']),\n",
    "           xytext=(20, df_reduction.loc[idx_10, 'test_accuracy'] - 0.05),\n",
    "           arrowprops=dict(arrowstyle='->', color='red'),\n",
    "           fontsize=11)\n",
    "\n",
    "# Grafico 2: Overfitting vs dimensione dataset\n",
    "ax2.plot(df_reduction['percentage'], df_reduction['overfitting'], 'o-', \n",
    "        linewidth=3, markersize=10, color='purple')\n",
    "ax2.set_xlabel('Percentuale di dati (%)')\n",
    "ax2.set_ylabel('Overfitting (Train - Test)')\n",
    "ax2.set_title('Overfitting vs Dimensione dataset')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Grafico 3: Tempo vs dimensione dataset\n",
    "ax3.plot(df_reduction['n_samples'], df_reduction['training_time'], 'o-', \n",
    "        linewidth=3, markersize=10, color='green')\n",
    "ax3.set_xlabel('Numero di campioni')\n",
    "ax3.set_ylabel('Tempo di training (s)')\n",
    "ax3.set_title('Tempo di training vs Dimensione dataset')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Grafico 4: Efficienza (acc/tempo) vs dimensione\n",
    "efficiency = df_reduction['test_accuracy'] / df_reduction['training_time']\n",
    "ax4.plot(df_reduction['percentage'], efficiency, 'o-', \n",
    "        linewidth=3, markersize=10, color='orange')\n",
    "ax4.set_xlabel('Percentuale di dati (%)')\n",
    "ax4.set_ylabel('Efficienza (Accuratezza / Tempo)')\n",
    "ax4.set_title('Efficienza vs Dimensione dataset')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Punto E: Training con rumore per migliorare la robustezza\n",
    "\n",
    "\n",
    "\n",
    " Verifichiamo se l'aggiunta di rumore durante il training può migliorare le prestazioni su dati di test rumorosi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training modelli con rumore nei dati di training...\n",
      "\n",
      "Training con rumore std = 0\n",
      "Accuratezza su test set pulito: 0.9803\n",
      "Tempo di training: 20.0s\n",
      "\n",
      "Training con rumore std = 0.05\n",
      "Accuratezza su test set pulito: 0.9765\n",
      "Tempo di training: 17.4s\n",
      "\n",
      "Training con rumore std = 0.1\n",
      "Accuratezza su test set pulito: 0.9728\n",
      "Tempo di training: 29.7s\n",
      "\n",
      "Training con rumore std = 0.15\n",
      "Accuratezza su test set pulito: 0.9712\n",
      "Tempo di training: 14.9s\n",
      "\n",
      "Training con rumore std = 0.2\n",
      "Accuratezza su test set pulito: 0.9667\n",
      "Tempo di training: 13.6s\n"
     ]
    }
   ],
   "source": [
    "# Training di modelli con diversi livelli di rumore nel training set\n",
    "training_noise_levels = [0, 0.05, 0.1, 0.15, 0.2]\n",
    "models_with_noise = {}\n",
    "\n",
    "print(\"Training modelli con rumore nei dati di training...\")\n",
    "for train_noise in training_noise_levels:\n",
    "    print(f\"\\nTraining con rumore std = {train_noise}\")\n",
    "    \n",
    "    # Aggiungo rumore ai dati di training\n",
    "    if train_noise > 0:\n",
    "        x_tr_noisy = add_gaussian_noise(x_tr, train_noise)\n",
    "    else:\n",
    "        x_tr_noisy = x_tr\n",
    "    \n",
    "    # Training MLP\n",
    "    mlp_noise = MLPClassifier(\n",
    "        hidden_layer_sizes=(100, 100),\n",
    "        max_iter=100,\n",
    "        random_state=42,\n",
    "        early_stopping=True,\n",
    "        validation_fraction=0.1\n",
    "    )\n",
    "    \n",
    "    start_time = time.time()\n",
    "    mlp_noise.fit(x_tr_noisy, mnist_tr_labels)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    models_with_noise[train_noise] = mlp_noise\n",
    "    \n",
    "    # Test su dati puliti\n",
    "    clean_acc = mlp_noise.score(x_te, mnist_te_labels)\n",
    "    print(f\"Accuratezza su test set pulito: {clean_acc:.4f}\")\n",
    "    print(f\"Tempo di training: {training_time:.1f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test dei modelli su dati rumorosi...\n",
      "Training noise 0: AUC = 0.302\n",
      "Training noise 0.05: AUC = 0.298\n",
      "Training noise 0.1: AUC = 0.324\n",
      "Training noise 0.15: AUC = 0.331\n",
      "Training noise 0.2: AUC = 0.336\n"
     ]
    }
   ],
   "source": [
    "# Test dei modelli su diversi livelli di rumore nel test set\n",
    "test_noise_levels = np.arange(0, 0.4, 0.05)\n",
    "results_noise_training = {}\n",
    "\n",
    "print(\"\\nTest dei modelli su dati rumorosi...\")\n",
    "for train_noise, model in models_with_noise.items():\n",
    "    accuracies = []\n",
    "    \n",
    "    for test_noise in test_noise_levels:\n",
    "        x_te_noisy = add_gaussian_noise(x_te_subset, test_noise)\n",
    "        acc = model.score(x_te_noisy, y_te_subset)\n",
    "        accuracies.append(acc)\n",
    "    \n",
    "    results_noise_training[train_noise] = accuracies\n",
    "    print(f\"Training noise {train_noise}: AUC = {np.trapz(accuracies, test_noise_levels):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Miglior livello di rumore nel training: σ = 0.2\n",
      "Miglioramento rispetto al modello senza rumore: 11.2%\n"
     ]
    }
   ],
   "source": [
    "# Visualizzazione curve psicometriche con diversi livelli di rumore nel training\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(training_noise_levels)))\n",
    "\n",
    "# Grafico 1: Curve psicometriche\n",
    "for i, (train_noise, accuracies) in enumerate(results_noise_training.items()):\n",
    "    ax1.plot(test_noise_levels, accuracies, 'o-', \n",
    "           label=f'Training noise σ = {train_noise}',\n",
    "           color=colors[i], linewidth=2, markersize=6)\n",
    "\n",
    "ax1.set_xlabel('Deviazione standard del rumore (test)', fontsize=12)\n",
    "ax1.set_ylabel('Accuratezza', fontsize=12)\n",
    "ax1.set_title('Effetto del rumore nel training sulla robustezza', fontsize=14)\n",
    "ax1.legend(loc='upper right')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim(0, 1.05)\n",
    "\n",
    "# Grafico 2: Analisi quantitativa del miglioramento\n",
    "auc_scores = {}\n",
    "for train_noise, accuracies in results_noise_training.items():\n",
    "    auc = np.trapz(accuracies, test_noise_levels)\n",
    "    auc_scores[train_noise] = auc\n",
    "\n",
    "train_noises = list(auc_scores.keys())\n",
    "aucs = list(auc_scores.values())\n",
    "\n",
    "ax2.plot(train_noises, aucs, 'o-', linewidth=3, markersize=10, color='darkred')\n",
    "ax2.set_xlabel('Rumore nel training (σ)', fontsize=12)\n",
    "ax2.set_ylabel('AUC (Area Under Curve)', fontsize=12)\n",
    "ax2.set_title('Area sotto la curva vs Rumore nel training', fontsize=14)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Identifico il miglior livello\n",
    "best_noise = max(auc_scores, key=auc_scores.get)\n",
    "best_auc = auc_scores[best_noise]\n",
    "ax2.scatter(best_noise, best_auc, s=200, color='gold', zorder=5)\n",
    "ax2.annotate(f'Ottimo: σ={best_noise}\\nAUC={best_auc:.3f}', \n",
    "           xy=(best_noise, best_auc),\n",
    "           xytext=(best_noise + 0.05, best_auc - 0.5),\n",
    "           arrowprops=dict(arrowstyle='->', color='gold'),\n",
    "           fontsize=11, bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nMiglior livello di rumore nel training: σ = {best_noise}\")\n",
    "print(f\"Miglioramento rispetto al modello senza rumore: {(best_auc - auc_scores[0])/auc_scores[0]*100:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Punto Bonus: Estensione con FashionMNIST\n",
    "\n",
    "\n",
    "\n",
    " Replichiamo alcuni degli esperimenti precedenti utilizzando il dataset FashionMNIST, che presenta maggiore complessità."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricamento FashionMNIST...\n"
     ]
    }
   ],
   "source": [
    "# Caricamento FashionMNIST\n",
    "print(\"Caricamento FashionMNIST...\")\n",
    "fashion_tr = FashionMNIST(root=\"./data\", train=True, download=True)\n",
    "fashion_te = FashionMNIST(root=\"./data\", train=False, download=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FashionMNIST caricato: 60000 train, 10000 test\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing FashionMNIST\n",
    "fashion_tr_data, fashion_tr_labels = fashion_tr.data.numpy(), fashion_tr.targets.numpy()\n",
    "fashion_te_data, fashion_te_labels = fashion_te.data.numpy(), fashion_te.targets.numpy()\n",
    "\n",
    "x_fashion_tr = fashion_tr_data.reshape(60000, 28 * 28) / 255.0\n",
    "x_fashion_te = fashion_te_data.reshape(10000, 28 * 28) / 255.0\n",
    "\n",
    "# Nomi delle classi\n",
    "fashion_classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "                  'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "print(f\"FashionMNIST caricato: {x_fashion_tr.shape[0]} train, {x_fashion_te.shape[0]} test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x800 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizzazione esempi FashionMNIST\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(10):\n",
    "    idx = np.where(fashion_tr_labels == i)[0][0]\n",
    "    axes[i].imshow(fashion_tr_data[idx], cmap='gray')\n",
    "    axes[i].set_title(f'{i}: {fashion_classes[i]}', fontsize=12)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Esempi dal dataset FashionMNIST', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_mlp_config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Training MLP su FashionMNIST con stessa architettura ottimale\u001b[39;00m\n\u001b[32m      2\u001b[39m mlp_fashion = MLPClassifier(\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     hidden_layer_sizes=\u001b[43mbest_mlp_config\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mhidden_layers\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m      4\u001b[39m     learning_rate_init=best_mlp_config[\u001b[33m'\u001b[39m\u001b[33mlearning_rate\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m      5\u001b[39m     max_iter=\u001b[32m100\u001b[39m,\n\u001b[32m      6\u001b[39m     random_state=\u001b[32m42\u001b[39m,\n\u001b[32m      7\u001b[39m     early_stopping=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m      8\u001b[39m     validation_fraction=\u001b[32m0.1\u001b[39m\n\u001b[32m      9\u001b[39m )\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining MLP su FashionMNIST con architettura: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_mlp_config[\u001b[33m'\u001b[39m\u001b[33mconfig_name\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m start_time = time.time()\n",
      "\u001b[31mNameError\u001b[39m: name 'best_mlp_config' is not defined"
     ]
    }
   ],
   "source": [
    "# Training MLP su FashionMNIST con stessa architettura ottimale\n",
    "mlp_fashion = MLPClassifier(\n",
    "    hidden_layer_sizes=best_mlp_config['hidden_layers'],\n",
    "    learning_rate_init=best_mlp_config['learning_rate'],\n",
    "    max_iter=100,\n",
    "    random_state=42,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.1\n",
    ")\n",
    "\n",
    "print(f\"Training MLP su FashionMNIST con architettura: {best_mlp_config['config_name']}\")\n",
    "start_time = time.time()\n",
    "mlp_fashion.fit(x_fashion_tr, fashion_tr_labels)\n",
    "fashion_training_time = time.time() - start_time\n",
    "\n",
    "fashion_train_acc = mlp_fashion.score(x_fashion_tr, fashion_tr_labels)\n",
    "fashion_test_acc = mlp_fashion.score(x_fashion_te, fashion_te_labels)\n",
    "\n",
    "print(f\"Training time: {fashion_training_time:.1f}s\")\n",
    "print(f\"Train accuracy: {fashion_train_acc:.4f}\")\n",
    "print(f\"Test accuracy: {fashion_test_acc:.4f}\")\n",
    "print(f\"Overfitting: {fashion_train_acc - fashion_test_acc:+.4f}\")\n",
    "\n",
    "# Confronto con MNIST\n",
    "mnist_test_acc = mlp_best.score(x_te, mnist_te_labels)\n",
    "print(f\"\\nConfronto con MNIST:\")\n",
    "print(f\"MNIST test accuracy: {mnist_test_acc:.4f}\")\n",
    "print(f\"FashionMNIST test accuracy: {fashion_test_acc:.4f}\")\n",
    "print(f\"Differenza: {mnist_test_acc - fashion_test_acc:+.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curve psicometriche comparative MNIST vs FashionMNIST\n",
    "noise_levels_comp = np.arange(0, 0.3, 0.05)\n",
    "acc_mnist = []\n",
    "acc_fashion = []\n",
    "\n",
    "# Subset per velocità\n",
    "x_fashion_te_subset = x_fashion_te[:2000]\n",
    "y_fashion_te_subset = fashion_te_labels[:2000]\n",
    "\n",
    "print(\"Calcolo curve psicometriche comparative...\")\n",
    "for noise_std in noise_levels_comp:\n",
    "    # MNIST\n",
    "    x_noisy_mnist = add_gaussian_noise(x_te_subset, noise_std)\n",
    "    acc_mnist.append(mlp_best.score(x_noisy_mnist, y_te_subset))\n",
    "    \n",
    "    # FashionMNIST\n",
    "    x_noisy_fashion = add_gaussian_noise(x_fashion_te_subset, noise_std)\n",
    "    acc_fashion.append(mlp_fashion.score(x_noisy_fashion, y_fashion_te_subset))\n",
    "    \n",
    "    print(f\"Noise {noise_std:.2f}: MNIST {acc_mnist[-1]:.3f}, Fashion {acc_fashion[-1]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizzazione comparativa finale\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Grafico 1: Curve psicometriche comparative\n",
    "ax1.plot(noise_levels_comp, acc_mnist, 'o-', label='MNIST', \n",
    "         linewidth=3, markersize=8, color='blue')\n",
    "ax1.plot(noise_levels_comp, acc_fashion, 's-', label='FashionMNIST', \n",
    "         linewidth=3, markersize=8, color='red')\n",
    "ax1.set_xlabel('Deviazione standard del rumore', fontsize=12)\n",
    "ax1.set_ylabel('Accuratezza', fontsize=12)\n",
    "ax1.set_title('Confronto robustezza al rumore:\\nMNIST vs FashionMNIST', fontsize=14)\n",
    "ax1.legend(fontsize=12)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim(0, 1.05)\n",
    "\n",
    "# Grafico 2: Matrice di confusione FashionMNIST\n",
    "y_pred_fashion = mlp_fashion.predict(x_fashion_te)\n",
    "cm_fashion = metrics.confusion_matrix(fashion_te_labels, y_pred_fashion)\n",
    "\n",
    "im = ax2.imshow(cm_fashion, cmap='Blues')\n",
    "ax2.set_xticks(range(10))\n",
    "ax2.set_yticks(range(10))\n",
    "ax2.set_xticklabels([f'{i}' for i in range(10)])\n",
    "ax2.set_yticklabels([f'{i}: {fashion_classes[i][:7]}' for i in range(10)], fontsize=10)\n",
    "ax2.set_xlabel('Predetto', fontsize=12)\n",
    "ax2.set_ylabel('Vero', fontsize=12)\n",
    "ax2.set_title('Matrice di Confusione\\nFashionMNIST', fontsize=14)\n",
    "\n",
    "# Grafico 3: Confronto accuratezze per classe\n",
    "fashion_class_accs = []\n",
    "mnist_class_accs = []\n",
    "\n",
    "for digit in range(10):\n",
    "    # FashionMNIST\n",
    "    mask_f = fashion_te_labels == digit\n",
    "    acc_f = np.sum((y_pred_fashion == fashion_te_labels) & mask_f) / np.sum(mask_f)\n",
    "    fashion_class_accs.append(acc_f)\n",
    "    \n",
    "    # MNIST\n",
    "    mask_m = mnist_te_labels == digit\n",
    "    acc_m = np.sum((y_pred == mnist_te_labels) & mask_m) / np.sum(mask_m)\n",
    "    mnist_class_accs.append(acc_m)\n",
    "\n",
    "x_pos = np.arange(10)\n",
    "width = 0.35\n",
    "\n",
    "ax3.bar(x_pos - width/2, mnist_class_accs, width, label='MNIST', alpha=0.8, color='blue')\n",
    "ax3.bar(x_pos + width/2, fashion_class_accs, width, label='FashionMNIST', alpha=0.8, color='red')\n",
    "ax3.set_xlabel('Classe', fontsize=12)\n",
    "ax3.set_ylabel('Accuratezza per classe', fontsize=12)\n",
    "ax3.set_title('Accuratezza per classe:\\nMNIST vs FashionMNIST', fontsize=14)\n",
    "ax3.set_xticks(x_pos)\n",
    "ax3.set_xticklabels([f'{i}' for i in range(10)])\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Grafico 4: Confronto errori più frequenti FashionMNIST\n",
    "fashion_confusion_pairs = []\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        if i != j and cm_fashion[i, j] > 0:\n",
    "            fashion_confusion_pairs.append({\n",
    "                'true_class': fashion_classes[i],\n",
    "                'pred_class': fashion_classes[j],\n",
    "                'count': cm_fashion[i, j]\n",
    "            })\n",
    "\n",
    "df_fashion_confusion = pd.DataFrame(fashion_confusion_pairs)\n",
    "top_fashion_errors = df_fashion_confusion.nlargest(8, 'count')\n",
    "\n",
    "y_pos = np.arange(len(top_fashion_errors))\n",
    "ax4.barh(y_pos, top_fashion_errors['count'], color='coral', alpha=0.8)\n",
    "ax4.set_yticks(y_pos)\n",
    "ax4.set_yticklabels([f\"{row['true_class'][:6]} → {row['pred_class'][:6]}\" \n",
    "                    for _, row in top_fashion_errors.iterrows()], fontsize=10)\n",
    "ax4.set_xlabel('Numero di errori', fontsize=12)\n",
    "ax4.set_title('Top 8 errori più frequenti\\nFashionMNIST', fontsize=14)\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Conclusioni\n",
    "\n",
    "\n",
    "\n",
    " ### Riepilogo dei risultati principali:\n",
    "\n",
    "\n",
    "\n",
    " [risultati da implementare]\n",
    "\n",
    "\n",
    "\n",
    " 1. **Effetto degli iperparametri (Punto A):**\n",
    "\n",
    "    - [analisi basata sui risultati numerici]\n",
    "\n",
    "\n",
    "\n",
    " 2. **Cifre più difficili (Punto B):**\n",
    "\n",
    "    - [analisi pattern errori specifici]\n",
    "\n",
    "\n",
    "\n",
    " 3. **Robustezza al rumore (Punto C):**\n",
    "\n",
    "    - [confronto degradazione MLP vs CNN]\n",
    "\n",
    "\n",
    "\n",
    " 4. **Effetto dei dati di training (Punto D):**\n",
    "\n",
    "    - [analisi prestazioni con dataset ridotto]\n",
    "\n",
    "\n",
    "\n",
    " 5. **Training con rumore (Punto E):**\n",
    "\n",
    "    - [valutazione miglioramenti robustezza]\n",
    "\n",
    "\n",
    "\n",
    " 6. **FashionMNIST (Bonus):**\n",
    "\n",
    "    - [confronto complessità dataset]\n",
    "\n",
    "\n",
    "\n",
    " ### Implicazioni pratiche:\n",
    "\n",
    "\n",
    "\n",
    " [raccomandazioni basate sui risultati]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistiche finali del progetto\n",
    "print(\"=\"*60)\n",
    "print(\"RIEPILOGO FINALE DEL PROGETTO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nPunto A - Analisi Iperparametri:\")\n",
    "print(f\"  • Esperimenti MLP: {len(mlp_results)}\")\n",
    "print(f\"  • Esperimenti CNN: {len(cnn_results)}\")\n",
    "print(f\"  • Miglior MLP: {best_mlp_config['config_name']} -> Acc: {best_mlp_config['test_accuracy']:.4f}\")\n",
    "print(f\"  • Miglior CNN: {best_cnn_config['config_name']} -> Acc: {best_cnn_config['test_accuracy']:.4f}\")\n",
    "\n",
    "print(f\"\\nPunto B - Analisi Errori:\")\n",
    "print(f\"  • Cifra più difficile: {df_errors_sorted.iloc[0]['digit']} (Error rate: {df_errors_sorted.iloc[0]['error_rate']:.3f})\")\n",
    "print(f\"  • Cifra più facile: {df_errors_sorted.iloc[-1]['digit']} (Error rate: {df_errors_sorted.iloc[-1]['error_rate']:.3f})\")\n",
    "print(f\"  • Confusione più frequente: {df_confusion_sorted.iloc[0]['true_digit']} → {df_confusion_sorted.iloc[0]['predicted_digit']} ({df_confusion_sorted.iloc[0]['count']} errori)\")\n",
    "\n",
    "print(f\"\\nPunto C - Robustezza al Rumore:\")\n",
    "print(f\"  • Livelli di rumore testati: {len(noise_levels)}\")\n",
    "print(f\"  • Accuratezza senza rumore MLP: {accuracies_mlp[0]:.4f}\")\n",
    "print(f\"  • Accuratezza senza rumore CNN: {accuracies_cnn[0]:.4f}\")\n",
    "\n",
    "print(f\"\\nPunto D - Riduzione Dati:\")\n",
    "print(f\"  • Accuratezza con 100% dati: {df_reduction[df_reduction['percentage']==100]['test_accuracy'].iloc[0]:.4f}\")\n",
    "print(f\"  • Accuratezza con 10% dati: {df_reduction[df_reduction['percentage']==10]['test_accuracy'].iloc[0]:.4f}\")\n",
    "\n",
    "print(f\"\\nPunto E - Training con Rumore:\")\n",
    "print(f\"  • Livelli testati: {len(training_noise_levels)}\")\n",
    "print(f\"  • Miglior configurazione: σ = {best_noise}\")\n",
    "\n",
    "print(f\"\\nBonus - FashionMNIST:\")\n",
    "print(f\"  • Accuratezza MNIST: {mnist_test_acc:.4f}\")\n",
    "print(f\"  • Accuratezza FashionMNIST: {fashion_test_acc:.4f}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
