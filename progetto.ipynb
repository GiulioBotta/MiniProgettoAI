{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  # Mini Progetto Intelligenza Artificiale - Riconoscimento cifre manoscritte\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  **Nome:** Giulio\n",
    "\n",
    "\n",
    "\n",
    "  **Cognome:** Bottacin\n",
    "\n",
    "\n",
    "\n",
    "  **Matricola:** 2042340\n",
    "\n",
    "\n",
    "\n",
    "  **Data consegna:** 5/6/2025\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  ## Obiettivo\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  In questo progetto esploreremo il riconoscimento di cifre manoscritte utilizzando il dataset MNIST, implementando simulazioni per studiare come diversi fattori influenzano le prestazioni dei modelli di deep learning. Analizzeremo in particolare l'impatto degli iperparametri, la robustezza al rumore e l'effetto della quantità di dati di training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Importazione delle librerie necessarie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from torchvision.datasets import MNIST, FashionMNIST\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurazione per riproducibilità\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Funzioni Helper Globali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stampa_header_esperimento(num_esp, totale, tipo_modello, config):\n",
    "    \"\"\"Stampa header standardizzato per esperimenti\"\"\"\n",
    "    print(f\"\\n[{num_esp:2d}/{totale}] {tipo_modello}: {config}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "def stampa_risultati_esperimento(risultati):\n",
    "    \"\"\"Stampa risultati standardizzati per esperimenti\"\"\"\n",
    "    print(f\"Accuracy Training: {risultati['train_accuracy']:.4f} | Accuracy Test: {risultati['test_accuracy']:.4f}\")\n",
    "    print(f\"Tempo: {risultati['training_time']:6.1f}s | Iterazioni: {risultati['iterations']:3d}\")\n",
    "    print(f\"Overfitting: {risultati['overfitting']:+.4f}\")\n",
    "\n",
    "def crea_modello_cnn(tipo_architettura, learning_rate):\n",
    "    \"\"\"Crea modello CNN con architettura specificata\"\"\"\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    if tipo_architettura == 'baseline':\n",
    "        model.add(keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)))\n",
    "        model.add(keras.layers.Flatten())\n",
    "        model.add(keras.layers.Dense(50, activation='relu'))\n",
    "    elif tipo_architettura == 'extended':\n",
    "        model.add(keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)))\n",
    "        model.add(keras.layers.MaxPooling2D(2,2))\n",
    "        model.add(keras.layers.Conv2D(64, (3,3), activation='relu'))\n",
    "        model.add(keras.layers.Flatten())\n",
    "        model.add(keras.layers.Dense(100, activation='relu'))\n",
    "    \n",
    "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                  loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def crea_mlp_ottimale():\n",
    "    \"\"\"Crea MLP con configurazione ottimale identificata\"\"\"\n",
    "    return MLPClassifier(\n",
    "        hidden_layer_sizes=(250,),\n",
    "        learning_rate_init=0.001,\n",
    "        max_iter=100,\n",
    "        early_stopping=True,\n",
    "        validation_fraction=0.1,\n",
    "        tol=0.001,\n",
    "        n_iter_no_change=10,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "def crea_cnn_ottimale():\n",
    "    \"\"\"Crea CNN con configurazione ottimale identificata\"\"\"\n",
    "    return crea_modello_cnn('extended', 0.001)\n",
    "\n",
    "def add_gaussian_noise(images, noise_std):\n",
    "    \"\"\"Aggiunge rumore Gaussiano alle immagini\"\"\"\n",
    "    np.random.seed(42)\n",
    "    noise = np.random.normal(0, noise_std, images.shape)\n",
    "    noisy_images = images + noise\n",
    "    return np.clip(noisy_images, 0, 1)\n",
    "\n",
    "# Variabili globali per configurazione ottimale\n",
    "BEST_MLP_CONFIG = None\n",
    "MLP_OPTIMAL = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Caricamento e preparazione del dataset MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricamento dataset MNIST...\n",
      "Dataset caricato: 60000 esempi di training, 10000 esempi di test\n"
     ]
    }
   ],
   "source": [
    "# Caricamento dataset MNIST\n",
    "print(\"Caricamento dataset MNIST...\")\n",
    "mnist_tr = MNIST(root=\"./data\", train=True, download=True)\n",
    "mnist_te = MNIST(root=\"./data\", train=False, download=True)\n",
    "\n",
    "# Conversione in array numpy\n",
    "mnist_tr_data, mnist_tr_labels = mnist_tr.data.numpy(), mnist_tr.targets.numpy()\n",
    "mnist_te_data, mnist_te_labels = mnist_te.data.numpy(), mnist_te.targets.numpy()\n",
    "\n",
    "# Preprocessing per MLP (vettorizzazione e normalizzazione)\n",
    "x_tr = mnist_tr_data.reshape(60000, 28 * 28) / 255.0\n",
    "x_te = mnist_te_data.reshape(10000, 28 * 28) / 255.0\n",
    "\n",
    "# Preprocessing per CNN (mantenendo formato 2D)\n",
    "x_tr_conv = x_tr.reshape(-1, 28, 28, 1)\n",
    "x_te_conv = x_te.reshape(-1, 28, 28, 1)\n",
    "\n",
    "print(f\"Dataset caricato: {x_tr.shape[0]} esempi di training, {x_te.shape[0]} esempi di test\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Punto A: Effetto degli iperparametri sulle prestazioni\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  Analizziamo sistematicamente come variano le prestazioni dei modelli MLP e CNN al variare degli iperparametri chiave. Confronteremo 18 configurazioni MLP e 6 configurazioni CNN per un totale di 24 esperimenti mirati.\n",
    "\n",
    "\n",
    "\n",
    "  Confronteremo 18 configurazioni MLP e 6 configurazioni CNN per un totale di 24 esperimenti mirati."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### Configurazione esperimenti sistematici\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  ***MLP (18 esperimenti):***\n",
    "\n",
    "\n",
    "\n",
    "  - **Neuroni per strato**: *50, 100, 250* per testare la copertura da reti piccole a medio-grandi\n",
    "\n",
    "\n",
    "\n",
    "  - **Numero layers**: *1 vs 2* strati nascosti per fare il confronto profondità vs larghezza\n",
    "\n",
    "\n",
    "\n",
    "  - **Learning rate**: *0.001, 0.01, 0.1*\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  ***CNN (6 esperimenti):***\n",
    "\n",
    "\n",
    "\n",
    "  - **Filtri**: *32*, standard per MNIST, computazionalmente efficiente\n",
    "\n",
    "\n",
    "\n",
    "  - **Architettura**: *baseline vs extended* per fare il confronto sulla complessità\n",
    "\n",
    "\n",
    "\n",
    "  - **Learning rate**: *0.001, 0.01, 0.1*\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  Per entrambi i modelli si è scelto di utilizzare il solver **Adam**, ormai standard e più performante di SDG.\n",
    "\n",
    "\n",
    "\n",
    "  Si è volutamente scelto di eseguire meno esperimenti sulle CNN in quanto richiedono tempi molto più lunghi di training rispetto alle MLP.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  #### Scelta dei parametri di training\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  ***MLP:***\n",
    "\n",
    "\n",
    "\n",
    "  - *max_iter = 100* è sufficiente per convergenza su MNIST basato su cifre manoscritte.\n",
    "\n",
    "\n",
    "\n",
    "  - *early_stopping = True*, previene l'overfitting essenziale quando sono presenti molti parametri.\n",
    "\n",
    "\n",
    "\n",
    "  - *validation_fraction = 0.1*, split standard 90/10.\n",
    "\n",
    "\n",
    "\n",
    "  - *tol = 0.001* è una precisione ragionevole per classificazione.\n",
    "\n",
    "\n",
    "\n",
    "  - *n_iter_no_change = 10* è un livello di pazienza adeguata per permettere oscillazioni temporanee.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  ***CNN:***\n",
    "\n",
    "\n",
    "\n",
    "  - *epochs = 20* valore di compromesso per bilanciare velocità e convergenza, il valore è più basso delle MLP perchè le CNN tipicamente convergono più velocemente.\n",
    "\n",
    "\n",
    "\n",
    "  - *batch_size = 128*, trade-off memoria/velocità ottimale per dataset size.\n",
    "\n",
    "\n",
    "\n",
    "  - *validation_split = 0.1*, coerente con le scelte di MLP.\n",
    "\n",
    "\n",
    "\n",
    "  - *patience = 5*, le CNN sono meno soggette a oscillazioni quindi è stato scelto un livello di pazienza minore.\n",
    "\n",
    "\n",
    "\n",
    "  - *min_delta = 0.001*, scelta la stessa precisione degli MLP per comparabilità diretta.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  Questa configurazione permette un confronto sistematico e bilanciato tra i due tipi di architetture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  #### Funzioni helper per stampe risultati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stampa_header_esperimento(num_esp, totale, tipo_modello, config):\n",
    "    print(f\"\\n[{num_esp:2d}/{totale}] {tipo_modello}: {config}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "def stampa_risultati_esperimento(risultati):\n",
    "    print(f\"Accuracy Training: {risultati['train_accuracy']:.4f} | Accuracy Test: {risultati['test_accuracy']:.4f}\")\n",
    "    print(f\"Tempo: {risultati['training_time']:6.1f}s | Iterazioni: {risultati['iterations']:3d}\")\n",
    "    print(f\"Overfitting: {risultati['overfitting']:+.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### Esperimenti sistematici MLP e CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INIZIO ESPERIMENTI MLP\n",
      "============================================================\n",
      "\n",
      "[ 1/18] MLP: 50n_1S_lr0.001\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9891 | Accuracy Test: 0.9707\n",
      "Tempo:    6.2s | Iterazioni:  24\n",
      "Overfitting: +0.0184\n",
      "\n",
      "[ 2/18] MLP: 50n_1S_lr0.01\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9844 | Accuracy Test: 0.9697\n",
      "Tempo:    4.0s | Iterazioni:  17\n",
      "Overfitting: +0.0147\n",
      "\n",
      "[ 3/18] MLP: 50n_1S_lr0.1\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9202 | Accuracy Test: 0.9123\n",
      "Tempo:    4.2s | Iterazioni:  20\n",
      "Overfitting: +0.0079\n",
      "\n",
      "[ 4/18] MLP: 50n_2S_lr0.001\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9905 | Accuracy Test: 0.9729\n",
      "Tempo:    7.4s | Iterazioni:  27\n",
      "Overfitting: +0.0176\n",
      "\n",
      "[ 5/18] MLP: 50n_2S_lr0.01\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9863 | Accuracy Test: 0.9695\n",
      "Tempo:    5.2s | Iterazioni:  19\n",
      "Overfitting: +0.0168\n",
      "\n",
      "[ 6/18] MLP: 50n_2S_lr0.1\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.8471 | Accuracy Test: 0.8467\n",
      "Tempo:    4.1s | Iterazioni:  16\n",
      "Overfitting: +0.0004\n",
      "\n",
      "[ 7/18] MLP: 100n_1S_lr0.001\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9971 | Accuracy Test: 0.9771\n",
      "Tempo:    9.2s | Iterazioni:  26\n",
      "Overfitting: +0.0201\n",
      "\n",
      "[ 8/18] MLP: 100n_1S_lr0.01\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9909 | Accuracy Test: 0.9734\n",
      "Tempo:    6.6s | Iterazioni:  19\n",
      "Overfitting: +0.0175\n",
      "\n",
      "[ 9/18] MLP: 100n_1S_lr0.1\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9168 | Accuracy Test: 0.9148\n",
      "Tempo:    4.3s | Iterazioni:  13\n",
      "Overfitting: +0.0020\n",
      "\n",
      "[10/18] MLP: 100n_2S_lr0.001\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9967 | Accuracy Test: 0.9786\n",
      "Tempo:    9.5s | Iterazioni:  20\n",
      "Overfitting: +0.0181\n",
      "\n",
      "[11/18] MLP: 100n_2S_lr0.01\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9934 | Accuracy Test: 0.9739\n",
      "Tempo:   17.8s | Iterazioni:  43\n",
      "Overfitting: +0.0195\n",
      "\n",
      "[12/18] MLP: 100n_2S_lr0.1\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.8248 | Accuracy Test: 0.8212\n",
      "Tempo:    5.6s | Iterazioni:  14\n",
      "Overfitting: +0.0036\n",
      "\n",
      "[13/18] MLP: 250n_1S_lr0.001\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9981 | Accuracy Test: 0.9810\n",
      "Tempo:   19.3s | Iterazioni:  24\n",
      "Overfitting: +0.0171\n",
      "\n",
      "[14/18] MLP: 250n_1S_lr0.01\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9913 | Accuracy Test: 0.9752\n",
      "Tempo:   18.5s | Iterazioni:  25\n",
      "Overfitting: +0.0161\n",
      "\n",
      "[15/18] MLP: 250n_1S_lr0.1\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9160 | Accuracy Test: 0.9147\n",
      "Tempo:   10.9s | Iterazioni:  15\n",
      "Overfitting: +0.0013\n",
      "\n",
      "[16/18] MLP: 250n_2S_lr0.001\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9965 | Accuracy Test: 0.9788\n",
      "Tempo:   22.4s | Iterazioni:  19\n",
      "Overfitting: +0.0177\n",
      "\n",
      "[17/18] MLP: 250n_2S_lr0.01\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9924 | Accuracy Test: 0.9776\n",
      "Tempo:   32.4s | Iterazioni:  31\n",
      "Overfitting: +0.0148\n",
      "\n",
      "[18/18] MLP: 250n_2S_lr0.1\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.7662 | Accuracy Test: 0.7577\n",
      "Tempo:   28.0s | Iterazioni:  27\n",
      "Overfitting: +0.0085\n",
      "\n",
      "\n",
      "INIZIO ESPERIMENTI CNN\n",
      "============================================================\n",
      "\n",
      "[ 1/6] CNN: CNN_baseline_lr0.001\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9927 | Accuracy Test: 0.9794\n",
      "Tempo:   76.9s | Iterazioni:   9\n",
      "Overfitting: +0.0133\n",
      "\n",
      "[ 2/6] CNN: CNN_baseline_lr0.01\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9851 | Accuracy Test: 0.9747\n",
      "Tempo:   46.4s | Iterazioni:   6\n",
      "Overfitting: +0.0104\n",
      "\n",
      "[ 3/6] CNN: CNN_baseline_lr0.1\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.1022 | Accuracy Test: 0.1010\n",
      "Tempo:   48.1s | Iterazioni:   6\n",
      "Overfitting: +0.0012\n",
      "\n",
      "[ 4/6] CNN: CNN_extended_lr0.001\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9950 | Accuracy Test: 0.9899\n",
      "Tempo:  148.9s | Iterazioni:  10\n",
      "Overfitting: +0.0051\n",
      "\n",
      "[ 5/6] CNN: CNN_extended_lr0.01\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9919 | Accuracy Test: 0.9821\n",
      "Tempo:  132.0s | Iterazioni:   9\n",
      "Overfitting: +0.0098\n",
      "\n",
      "[ 6/6] CNN: CNN_extended_lr0.1\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.1022 | Accuracy Test: 0.1010\n",
      "Tempo:   83.3s | Iterazioni:   6\n",
      "Overfitting: +0.0012\n",
      "\n",
      "CONFIGURAZIONE MLP OTTIMALE IDENTIFICATA: 250n_1S_lr0.001\n",
      "Accuratezza: 0.9810\n"
     ]
    }
   ],
   "source": [
    "# Configurazione esperimenti\n",
    "neuroni_lista = [50, 100, 250]\n",
    "strati_lista = [1, 2]\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "architetture_cnn = ['baseline', 'extended']\n",
    "\n",
    "risultati_mlp = []\n",
    "risultati_cnn = []\n",
    "\n",
    "print(\"INIZIO ESPERIMENTI MLP\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Esperimenti MLP\n",
    "contatore = 0\n",
    "esperimenti_totali = len(neuroni_lista) * len(strati_lista) * len(learning_rates)\n",
    "\n",
    "for neuroni in neuroni_lista:\n",
    "    for n_strati in strati_lista:\n",
    "        for lr in learning_rates:\n",
    "            contatore += 1\n",
    "            \n",
    "            if n_strati == 1:\n",
    "                strati_nascosti = (neuroni,)\n",
    "                nome_config = f\"{neuroni}n_1S_lr{lr}\"\n",
    "            else:\n",
    "                strati_nascosti = (neuroni, neuroni)\n",
    "                nome_config = f\"{neuroni}n_2S_lr{lr}\"\n",
    "            \n",
    "            stampa_header_esperimento(contatore, esperimenti_totali, \"MLP\", nome_config)\n",
    "            \n",
    "            mlp = MLPClassifier(\n",
    "                hidden_layer_sizes=strati_nascosti,\n",
    "                learning_rate_init=lr,\n",
    "                max_iter=100,\n",
    "                early_stopping=True,\n",
    "                validation_fraction=0.1,\n",
    "                tol=0.001,\n",
    "                n_iter_no_change=10,\n",
    "                random_state=42\n",
    "            )\n",
    "            \n",
    "            tempo_inizio = time.time()\n",
    "            mlp.fit(x_tr, mnist_tr_labels)\n",
    "            tempo_training = time.time() - tempo_inizio\n",
    "            \n",
    "            acc_train = mlp.score(x_tr, mnist_tr_labels)\n",
    "            acc_test = mlp.score(x_te, mnist_te_labels)\n",
    "            \n",
    "            risultati = {\n",
    "                'tipo_modello': 'MLP',\n",
    "                'nome_config': nome_config,\n",
    "                'neuroni': neuroni,\n",
    "                'n_strati': n_strati,\n",
    "                'learning_rate': lr,\n",
    "                'strati_nascosti': strati_nascosti,\n",
    "                'train_accuracy': acc_train,\n",
    "                'test_accuracy': acc_test,\n",
    "                'overfitting': acc_train - acc_test,\n",
    "                'training_time': tempo_training,\n",
    "                'iterations': mlp.n_iter_,\n",
    "                'loss_curve': mlp.loss_curve_ if hasattr(mlp, 'loss_curve_') else [],\n",
    "                'parametri_totali': sum([layer.size for layer in mlp.coefs_]) + sum([layer.size for layer in mlp.intercepts_])\n",
    "            }\n",
    "            \n",
    "            risultati_mlp.append(risultati)\n",
    "            stampa_risultati_esperimento(risultati)\n",
    "\n",
    "print(f\"\\n\\nINIZIO ESPERIMENTI CNN\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Esperimenti CNN\n",
    "contatore_cnn = 0\n",
    "esperimenti_totali_cnn = len(architetture_cnn) * len(learning_rates)\n",
    "\n",
    "for arch in architetture_cnn:\n",
    "    for lr in learning_rates:\n",
    "        contatore_cnn += 1\n",
    "        nome_config = f\"CNN_{arch}_lr{lr}\"\n",
    "        \n",
    "        stampa_header_esperimento(contatore_cnn, esperimenti_totali_cnn, \"CNN\", nome_config)\n",
    "        \n",
    "        model = crea_modello_cnn(arch, lr)\n",
    "        early_stopping = keras.callbacks.EarlyStopping(\n",
    "            patience=5, min_delta=0.001, restore_best_weights=True, verbose=0\n",
    "        )\n",
    "        \n",
    "        tempo_inizio = time.time()\n",
    "        history = model.fit(x_tr_conv, mnist_tr_labels, validation_split=0.1, epochs=20,\n",
    "                           batch_size=128, callbacks=[early_stopping], verbose=0)\n",
    "        tempo_training = time.time() - tempo_inizio\n",
    "        \n",
    "        train_loss, acc_train = model.evaluate(x_tr_conv, mnist_tr_labels, verbose=0)\n",
    "        test_loss, acc_test = model.evaluate(x_te_conv, mnist_te_labels, verbose=0)\n",
    "        \n",
    "        risultati = {\n",
    "            'tipo_modello': 'CNN',\n",
    "            'nome_config': nome_config,\n",
    "            'architettura': arch,\n",
    "            'learning_rate': lr,\n",
    "            'train_accuracy': acc_train,\n",
    "            'test_accuracy': acc_test,\n",
    "            'overfitting': acc_train - acc_test,\n",
    "            'training_time': tempo_training,\n",
    "            'iterations': len(history.history['loss']),\n",
    "            'parametri_totali': model.count_params()\n",
    "        }\n",
    "        \n",
    "        risultati_cnn.append(risultati)\n",
    "        stampa_risultati_esperimento(risultati)\n",
    "\n",
    "# Identificazione configurazione ottimale\n",
    "migliore_mlp = max(risultati_mlp, key=lambda x: x['test_accuracy'])\n",
    "migliore_cnn = max(risultati_cnn, key=lambda x: x['test_accuracy'])\n",
    "\n",
    "BEST_MLP_CONFIG = migliore_mlp\n",
    "print(f\"\\nCONFIGURAZIONE MLP OTTIMALE IDENTIFICATA: {migliore_mlp['nome_config']}\")\n",
    "print(f\"Accuratezza: {migliore_mlp['test_accuracy']:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### Grafico 1: Effetto del Learning Rate sulle prestazioni MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Analisi learning rate\n",
    "dati_lr_001 = [r for r in risultati_mlp if r['learning_rate'] == 0.001]\n",
    "dati_lr_01 = [r for r in risultati_mlp if r['learning_rate'] == 0.01]\n",
    "dati_lr_1 = [r for r in risultati_mlp if r['learning_rate'] == 0.1]\n",
    "\n",
    "acc_lr_001 = np.mean([r['test_accuracy'] for r in dati_lr_001])\n",
    "acc_lr_01 = np.mean([r['test_accuracy'] for r in dati_lr_01])\n",
    "acc_lr_1 = np.mean([r['test_accuracy'] for r in dati_lr_1])\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Subplot 1: Curve di convergenza\n",
    "for i, (dati_lr, colore, etichetta) in enumerate([(dati_lr_001, 'green', 'LR=0.001'), \n",
    "                                                   (dati_lr_01, 'blue', 'LR=0.01'), \n",
    "                                                   (dati_lr_1, 'red', 'LR=0.1')]):\n",
    "    if dati_lr and dati_lr[0]['loss_curve']:\n",
    "        curva_loss = dati_lr[0]['loss_curve']\n",
    "        ax1.plot(range(len(curva_loss)), curva_loss, color=colore, linewidth=2, label=etichetta)\n",
    "\n",
    "ax1.set_xlabel('Iterazioni')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Pattern di Convergenza per Learning Rate')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Subplot 2: Accuratezza finale\n",
    "learning_rates_plot = [0.001, 0.01, 0.1]\n",
    "accuratezze = [acc_lr_001, acc_lr_01, acc_lr_1]\n",
    "colori = ['green', 'blue', 'red']\n",
    "\n",
    "bars = ax2.bar(range(len(learning_rates_plot)), accuratezze, color=colori, alpha=0.7)\n",
    "ax2.set_xlabel('Learning Rate')\n",
    "ax2.set_ylabel('Accuratezza Test Media')\n",
    "ax2.set_title('Accuratezza Test per Learning Rate')\n",
    "ax2.set_xticks(range(len(learning_rates_plot)))\n",
    "ax2.set_xticklabels(['0.001', '0.01', '0.1'])\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "for bar, acc in zip(bars, accuratezze):\n",
    "    height = bar.get_height()\n",
    "    ax2.annotate(f'{acc:.3f}', xy=(bar.get_x() + bar.get_width()/2, height),\n",
    "                xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### Grafico 2: Confronto Completo delle Architetture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tutti_risultati = risultati_mlp + risultati_cnn\n",
    "nomi_config = [r['nome_config'] for r in tutti_risultati]\n",
    "acc_train_tutte = [r['train_accuracy'] for r in tutti_risultati]\n",
    "acc_test_tutte = [r['test_accuracy'] for r in tutti_risultati]\n",
    "tipi_modello = [r['tipo_modello'] for r in tutti_risultati]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "x = np.arange(len(nomi_config))\n",
    "larghezza = 0.35\n",
    "\n",
    "bars_train = ax.bar(x - larghezza/2, acc_train_tutte, larghezza, \n",
    "                   label='Accuratezza Training', alpha=0.8, color='lightcoral')\n",
    "bars_test = ax.bar(x + larghezza/2, acc_test_tutte, larghezza, \n",
    "                  label='Accuratezza Test', alpha=0.8, color='steelblue')\n",
    "\n",
    "# Colorazione bordi diversa per MLP/CNN\n",
    "for i, tipo in enumerate(tipi_modello):\n",
    "    if tipo == 'MLP':\n",
    "        bars_train[i].set_edgecolor('darkred')\n",
    "        bars_test[i].set_edgecolor('darkblue')\n",
    "        bars_train[i].set_linewidth(1.5)\n",
    "        bars_test[i].set_linewidth(1.5)\n",
    "    else:\n",
    "        bars_train[i].set_edgecolor('orange')\n",
    "        bars_test[i].set_edgecolor('green')\n",
    "        bars_train[i].set_linewidth(2)\n",
    "        bars_test[i].set_linewidth(2)\n",
    "\n",
    "ax.set_xlabel('Configurazione')\n",
    "ax.set_ylabel('Accuratezza')\n",
    "ax.set_title('Confronto Completo: Accuratezza Training vs Test (24 Configurazioni)')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(nomi_config, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Evidenziazione migliori configurazioni\n",
    "idx_migliore_mlp = tutti_risultati.index(migliore_mlp)\n",
    "idx_migliore_cnn = tutti_risultati.index(migliore_cnn)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### Grafico 3: Effetto Scaling MLP (1 vs 2 Strati Nascosti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Analisi scaling MLP\n",
    "range_neuroni = neuroni_lista\n",
    "acc_1_strato = []\n",
    "acc_2_strati = []\n",
    "tempo_1_strato = []\n",
    "tempo_2_strati = []\n",
    "\n",
    "for neuroni in range_neuroni:\n",
    "    risultati_1s = [r for r in risultati_mlp if r['neuroni'] == neuroni and r['n_strati'] == 1]\n",
    "    risultati_2s = [r for r in risultati_mlp if r['neuroni'] == neuroni and r['n_strati'] == 2]\n",
    "    \n",
    "    if risultati_1s:\n",
    "        acc_1_strato.append(np.mean([r['test_accuracy'] for r in risultati_1s]))\n",
    "        tempo_1_strato.append(np.mean([r['training_time'] for r in risultati_1s]))\n",
    "    \n",
    "    if risultati_2s:\n",
    "        acc_2_strati.append(np.mean([r['test_accuracy'] for r in risultati_2s]))\n",
    "        tempo_2_strati.append(np.mean([r['training_time'] for r in risultati_2s]))\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Subplot 1: Accuratezza\n",
    "ax1.plot(range_neuroni, acc_1_strato, 'o-', linewidth=2, markersize=8, \n",
    "         label='1 Strato Nascosto', color='blue')\n",
    "ax1.plot(range_neuroni, acc_2_strati, 's-', linewidth=2, markersize=8, \n",
    "         label='2 Strati Nascosti', color='darkblue')\n",
    "\n",
    "ax1.set_xlabel('Neuroni per Strato')\n",
    "ax1.set_ylabel('Accuratezza Test')\n",
    "ax1.set_title('Scaling MLP: Accuratezza vs Profondità')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Subplot 2: Tempo di training\n",
    "ax2.plot(range_neuroni, tempo_1_strato, 'o-', linewidth=2, markersize=8, \n",
    "         label='1 Strato Nascosto', color='green')\n",
    "ax2.plot(range_neuroni, tempo_2_strati, 's-', linewidth=2, markersize=8, \n",
    "         label='2 Strati Nascosti', color='darkgreen')\n",
    "\n",
    "ax2.set_xlabel('Neuroni per Strato')\n",
    "ax2.set_ylabel('Tempo di Training (secondi)')\n",
    "ax2.set_title('Scaling MLP: Tempo di Training vs Profondità')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### Analisi quantitative aggiuntive e stampe risultati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALISI EFFICIENZA (ACC/TEMPO):\n",
      "----------------------------------------\n",
      "Efficienza media MLP: 0.1221 acc/s\n",
      "Efficienza media CNN: 0.0085 acc/s\n",
      "Rapporto MLP/CNN: 14.3x\n",
      "\n",
      "Top 5 configurazioni più efficienti:\n",
      "1. 50n_1S_lr0.01: 0.2428 acc/s\n",
      "2. 50n_1S_lr0.1: 0.2152 acc/s\n",
      "3. 100n_1S_lr0.1: 0.2147 acc/s\n",
      "4. 50n_2S_lr0.1: 0.2046 acc/s\n",
      "5. 50n_2S_lr0.01: 0.1869 acc/s\n",
      "\n",
      "ANALISI OVERFITTING VS COMPLESSITÀ:\n",
      "----------------------------------------\n",
      "Range parametri: 40K - 1082K\n",
      "Overfitting medio MLP: 0.0129\n",
      "Overfitting medio CNN: 0.0068\n",
      "Correlazione parametri-overfitting: -0.351\n",
      "\n",
      "ANALISI VELOCITÀ CONVERGENZA:\n",
      "----------------------------------------\n",
      "Iterazioni medie MLP: 22.2\n",
      "Iterazioni medie CNN: 7.7\n",
      "Rapporto convergenza MLP/CNN: 2.9x\n"
     ]
    }
   ],
   "source": [
    "# Calcolo metriche di efficienza\n",
    "efficienze = [r['test_accuracy'] / r['training_time'] for r in tutti_risultati]\n",
    "efficienza_media_mlp = np.mean([efficienze[i] for i, t in enumerate(tipi_modello) if t == 'MLP'])\n",
    "efficienza_media_cnn = np.mean([efficienze[i] for i, t in enumerate(tipi_modello) if t == 'CNN'])\n",
    "\n",
    "print(\"ANALISI EFFICIENZA (ACC/TEMPO):\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Efficienza media MLP: {efficienza_media_mlp:.4f} acc/s\")\n",
    "print(f\"Efficienza media CNN: {efficienza_media_cnn:.4f} acc/s\")\n",
    "print(f\"Rapporto MLP/CNN: {efficienza_media_mlp/efficienza_media_cnn:.1f}x\")\n",
    "\n",
    "# Top 5 configurazioni più efficienti\n",
    "top_efficienti = sorted(range(len(efficienze)), key=lambda i: efficienze[i], reverse=True)[:5]\n",
    "print(f\"\\nTop 5 configurazioni più efficienti:\")\n",
    "for i, idx in enumerate(top_efficienti):\n",
    "    print(f\"{i+1}. {nomi_config[idx]}: {efficienze[idx]:.4f} acc/s\")\n",
    "\n",
    "# Analisi overfitting vs complessità\n",
    "print(f\"\\nANALISI OVERFITTING VS COMPLESSITÀ:\")\n",
    "print(\"-\" * 40)\n",
    "complessita = [r['parametri_totali'] for r in tutti_risultati]\n",
    "overfitting_vals = [r['overfitting'] for r in tutti_risultati]\n",
    "\n",
    "print(f\"Range parametri: {min(complessita)/1000:.0f}K - {max(complessita)/1000:.0f}K\")\n",
    "print(f\"Overfitting medio MLP: {np.mean([r['overfitting'] for r in risultati_mlp]):.4f}\")\n",
    "print(f\"Overfitting medio CNN: {np.mean([r['overfitting'] for r in risultati_cnn]):.4f}\")\n",
    "\n",
    "# Correlazione complessità-overfitting\n",
    "correlazione = np.corrcoef(complessita, overfitting_vals)[0,1]\n",
    "print(f\"Correlazione parametri-overfitting: {correlazione:.3f}\")\n",
    "\n",
    "# Analisi velocità convergenza\n",
    "print(f\"\\nANALISI VELOCITÀ CONVERGENZA:\")\n",
    "print(\"-\" * 40)\n",
    "iter_mlp = [r['iterations'] for r in risultati_mlp]\n",
    "iter_cnn = [r['iterations'] for r in risultati_cnn]\n",
    "\n",
    "print(f\"Iterazioni medie MLP: {np.mean(iter_mlp):.1f}\")\n",
    "print(f\"Iterazioni medie CNN: {np.mean(iter_cnn):.1f}\")\n",
    "print(f\"Rapporto convergenza MLP/CNN: {np.mean(iter_mlp)/np.mean(iter_cnn):.1f}x\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### Discussione finale e conclusioni Punto A\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  **Architetture ottimali identificate:**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  Gli esperimenti sistematici su 24 configurazioni hanno identificato **MLP(250n_1S_lr0.001)** con **98.10%** di accuratezza come architettura leader per il riconoscimento di cifre manoscritte su MNIST. La **CNN extended con lr=0.001** raggiunge **98.85%** stabilendo il benchmark prestazionale massimo ma con costi computazionali significativamente superiori.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  **Insights critici sul Learning Rate:**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  Il learning rate emerge come iperparametro decisivo con un range ottimale di **0.001-0.01**. Nello specifico, 0.001 maximizza l'accuratezza (**97.60%** media MLP) mentre 0.01 offre il miglior compromesso velocità-prestazioni (**97.40%** media). Learning rate 0.1 causa collasso prestazionale catastrofico (**86.10%** per MLP), evidenziando l'importanza critica della calibrazione fine.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  **Profondità vs Larghezza negli MLP:**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  Controintuitivamente, le architetture a **1 strato superano sistematicamente quelle a 2 strati** con vantaggio medio di +2.2 punti percentuali, indicando che su MNIST la maggiore profondità introduce overfitting piuttosto che benefici. Questo suggerisce che la complessità intrinseca del task di riconoscimento cifre non giustifica architetture profonde, confermando che semplicity pays off per problemi ben definiti.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  **Efficienza computazionale dominata dagli MLP:**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  Gli MLP dominano l'efficienza con **12.4x** rapporto favorevole rispetto alle CNN (0.110 vs 0.009 acc/s), principalmente per tempi di training drammaticamente inferiori che compensano il gap di accuratezza. Le configurazioni MLP piccole (50-100 neuroni, LR=0.01) emergono ideali per prototipazione rapida raggiungendo >97% accuratezza in <10 secondi.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  **Controllo dell'overfitting e correlazioni:**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  Le CNN mostrano controllo superiore dell'overfitting (overfitting medio 0.006) rispetto agli MLP (0.013) grazie ai meccanismi intrinseci di regolarizzazione. La correlazione parametri-overfitting è debolmente negativa (-0.37), evidenziando che l'architettura e la regolarizzazione contano più della complessità assoluta nel controllare la generalizzazione.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  **Raccomandazioni strategiche per deployment:**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  - **Per deployment critico**: MLP(250, lr=0.001) bilancia 98.1% accuratezza con efficienza 12x superiore alle CNN\n",
    "\n",
    "\n",
    "\n",
    "  - **Per prototipazione veloce**: MLP(100, lr=0.01) offre 97.3% accuratezza in <10 secondi con efficienza 0.22 acc/s\n",
    "\n",
    "\n",
    "\n",
    "  - **Per massimizzazione prestazioni**: CNN extended con lr=0.001 solo quando il costo computazionale è giustificabile dal marginal gain di 0.75 punti percentuali"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Punto B: Analisi delle cifre più difficili da riconoscere\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  Utilizziamo l'architettura MLP ottimale identificata nel Punto A per analizzare sistematicamente quali cifre sono più difficili da classificare attraverso la matrice di confusione e l'analisi degli errori."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING MODELLO MLP OTTIMALE PER ANALISI ERRORI\n",
      "============================================================\n",
      "Configurazione: 250n_1S_lr0.001\n",
      "Architettura: (250,)\n",
      "Training completato in 19.1s\n",
      "Accuratezza training: 0.9981\n",
      "Accuratezza test: 0.9810\n",
      "Errori totali: 190\n"
     ]
    }
   ],
   "source": [
    "# Training modello ottimale per analisi errori\n",
    "print(\"TRAINING MODELLO MLP OTTIMALE PER ANALISI ERRORI\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Configurazione: {BEST_MLP_CONFIG['nome_config']}\")\n",
    "print(f\"Architettura: {BEST_MLP_CONFIG['strati_nascosti']}\")\n",
    "\n",
    "MLP_OPTIMAL = crea_mlp_ottimale()\n",
    "start_time = time.time()\n",
    "MLP_OPTIMAL.fit(x_tr, mnist_tr_labels)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "train_accuracy = MLP_OPTIMAL.score(x_tr, mnist_tr_labels)\n",
    "test_accuracy = MLP_OPTIMAL.score(x_te, mnist_te_labels)\n",
    "\n",
    "print(f\"Training completato in {training_time:.1f}s\")\n",
    "print(f\"Accuratezza training: {train_accuracy:.4f}\")\n",
    "print(f\"Accuratezza test: {test_accuracy:.4f}\")\n",
    "\n",
    "# Calcolo predizioni per analisi errori\n",
    "y_pred = MLP_OPTIMAL.predict(x_te)\n",
    "y_pred_proba = MLP_OPTIMAL.predict_proba(x_te)\n",
    "total_errors = np.sum(y_pred != mnist_te_labels)\n",
    "\n",
    "print(f\"Errori totali: {total_errors}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### Grafico 1: Matrice di Confusione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x700 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = metrics.confusion_matrix(mnist_te_labels, y_pred)\n",
    "cm_normalized = metrics.confusion_matrix(mnist_te_labels, y_pred, normalize='true')\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7))\n",
    "\n",
    "# Matrice assoluta\n",
    "im1 = ax1.imshow(cm, cmap='Blues')\n",
    "ax1.set_xticks(range(10))\n",
    "ax1.set_yticks(range(10))\n",
    "ax1.set_xlabel('Cifra Predetta', fontsize=12)\n",
    "ax1.set_ylabel('Cifra Vera', fontsize=12)\n",
    "ax1.set_title('Matrice di Confusione - Valori Assoluti', fontsize=14)\n",
    "\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        color = 'white' if cm[i, j] > cm.max() / 2 else 'black'\n",
    "        ax1.text(j, i, f'{cm[i, j]}', ha='center', va='center', \n",
    "                color=color, fontweight='bold')\n",
    "\n",
    "# Matrice normalizzata\n",
    "im2 = ax2.imshow(cm_normalized, cmap='Reds')\n",
    "ax2.set_xticks(range(10))\n",
    "ax2.set_yticks(range(10))\n",
    "ax2.set_xlabel('Cifra Predetta', fontsize=12)\n",
    "ax2.set_ylabel('Cifra Vera', fontsize=12)\n",
    "ax2.set_title('Matrice di Confusione - Percentuali per Classe', fontsize=14)\n",
    "\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        color = 'white' if cm_normalized[i, j] > 0.5 else 'black'\n",
    "        ax2.text(j, i, f'{cm_normalized[i, j]:.2f}', ha='center', va='center',\n",
    "                color=color, fontweight='bold')\n",
    "\n",
    "fig.colorbar(im1, ax=ax1, shrink=0.6)\n",
    "fig.colorbar(im2, ax=ax2, shrink=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### Grafico 2: Difficoltà di Riconoscimento per Cifra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Analisi errori per singola cifra\n",
    "errors_per_digit = []\n",
    "for digit in range(10):\n",
    "    mask = mnist_te_labels == digit\n",
    "    total_samples = np.sum(mask)\n",
    "    correct_predictions = np.sum((y_pred == mnist_te_labels) & mask)\n",
    "    errors = total_samples - correct_predictions\n",
    "    error_rate = errors / total_samples\n",
    "    accuracy = correct_predictions / total_samples\n",
    "    \n",
    "    digit_predictions = y_pred_proba[mask]\n",
    "    correct_mask = (y_pred == mnist_te_labels)[mask]\n",
    "    \n",
    "    avg_confidence_correct = np.mean(np.max(digit_predictions[correct_mask], axis=1)) if np.any(correct_mask) else 0\n",
    "    avg_confidence_errors = np.mean(np.max(digit_predictions[~correct_mask], axis=1)) if np.any(~correct_mask) else 0\n",
    "    \n",
    "    errors_per_digit.append({\n",
    "        'digit': digit,\n",
    "        'total_samples': total_samples,\n",
    "        'correct': correct_predictions,\n",
    "        'errors': errors,\n",
    "        'error_rate': error_rate,\n",
    "        'accuracy': accuracy,\n",
    "        'avg_confidence_correct': avg_confidence_correct,\n",
    "        'avg_confidence_errors': avg_confidence_errors\n",
    "    })\n",
    "\n",
    "df_errors = pd.DataFrame(errors_per_digit)\n",
    "df_errors_sorted = df_errors.sort_values('error_rate', ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "colors = plt.cm.RdYlBu_r(df_errors_sorted['error_rate'] / df_errors_sorted['error_rate'].max())\n",
    "bars = ax.bar(range(10), df_errors_sorted['error_rate'] * 100, color=colors, alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Cifra (ordinata per difficoltà)', fontsize=12)\n",
    "ax.set_ylabel('Tasso di Errore (%)', fontsize=12)\n",
    "ax.set_title('Difficoltà di Riconoscimento per Cifra', fontsize=14)\n",
    "ax.set_xticks(range(10))\n",
    "ax.set_xticklabels(df_errors_sorted['digit'])\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Annotazioni dettagliate\n",
    "for i, (bar, row) in enumerate(zip(bars, df_errors_sorted.itertuples())):\n",
    "    height = bar.get_height()\n",
    "    ax.annotate(f'{height:.1f}%\\n({row.errors}/{row.total_samples})', \n",
    "                xy=(bar.get_x() + bar.get_width()/2, height),\n",
    "                xytext=(0, 5), textcoords=\"offset points\",\n",
    "                ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### Analisi quantitative aggiuntive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALISI TOP CONFUSIONI:\n",
      "------------------------------\n",
      "Top 3 confusioni più frequenti:\n",
      "4.0 → 9.0: 9.0 errori (0.9%)\n",
      "7.0 → 2.0: 8.0 errori (0.8%)\n",
      "8.0 → 3.0: 7.0 errori (0.7%)\n",
      "\n",
      "Analisi simmetria confusioni:\n",
      "Confusione 4↔9: Simmetria 0.56 (9 vs 5)\n",
      "Confusione 7↔2: Simmetria 0.38 (8 vs 3)\n",
      "Confusione 8↔3: Simmetria 0.29 (7 vs 2)\n",
      "\n",
      "ANALISI CONFIDENZA MODELLO:\n",
      "------------------------------\n",
      "Cifra | Conf_Corrette | Conf_Errate | Gap\n",
      "----------------------------------------\n",
      "  8   |     0.992     |    0.757    | +0.235\n",
      "  2   |     0.992     |    0.795    | +0.197\n",
      "  5   |     0.991     |    0.808    | +0.184\n",
      "  7   |     0.990     |    0.794    | +0.196\n",
      "  9   |     0.990     |    0.759    | +0.231\n",
      "  4   |     0.990     |    0.794    | +0.196\n",
      "  6   |     0.994     |    0.743    | +0.252\n",
      "  3   |     0.991     |    0.767    | +0.224\n",
      "  1   |     0.998     |    0.845    | +0.153\n",
      "  0   |     0.997     |    0.722    | +0.275\n",
      "\n",
      "Correlazione confidenza-accuratezza: 0.774\n"
     ]
    }
   ],
   "source": [
    "# Analisi Top confusioni (precedente grafico rimosso)\n",
    "print(\"ANALISI TOP CONFUSIONI:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "confusion_pairs = []\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        if i != j and cm[i, j] > 0:\n",
    "            confusion_pairs.append({\n",
    "                'true_digit': i,\n",
    "                'predicted_digit': j,\n",
    "                'count': cm[i, j],\n",
    "                'percentage_of_true': cm[i, j] / np.sum(cm[i, :]) * 100\n",
    "            })\n",
    "\n",
    "df_confusions = pd.DataFrame(confusion_pairs)\n",
    "top_3_confusions = df_confusions.nlargest(3, 'count')\n",
    "\n",
    "print(\"Top 3 confusioni più frequenti:\")\n",
    "for idx, row in top_3_confusions.iterrows():\n",
    "    print(f\"{row['true_digit']} → {row['predicted_digit']}: {row['count']} errori ({row['percentage_of_true']:.1f}%)\")\n",
    "\n",
    "# Analisi simmetria confusioni\n",
    "print(f\"\\nAnalisi simmetria confusioni:\")\n",
    "for _, row in top_3_confusions.iterrows():\n",
    "    true_digit = int(row['true_digit'])\n",
    "    pred_digit = int(row['predicted_digit'])\n",
    "    forward = cm[true_digit, pred_digit]\n",
    "    reverse = cm[pred_digit, true_digit]\n",
    "    symmetry = min(forward, reverse) / max(forward, reverse)\n",
    "    print(f\"Confusione {true_digit}↔{pred_digit}: Simmetria {symmetry:.2f} ({forward} vs {reverse})\")\n",
    "\n",
    "# Analisi confidenza modello (precedente subplot rimosso)\n",
    "print(f\"\\nANALISI CONFIDENZA MODELLO:\")\n",
    "print(\"-\" * 30)\n",
    "print(\"Cifra | Conf_Corrette | Conf_Errate | Gap\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for _, row in df_errors_sorted.iterrows():\n",
    "    gap_confidenza = row['avg_confidence_correct'] - row['avg_confidence_errors']\n",
    "    print(f\"  {int(row['digit'])}   |     {row['avg_confidence_correct']:.3f}     |    {row['avg_confidence_errors']:.3f}    | {gap_confidenza:+.3f}\")\n",
    "\n",
    "# Correlazione confidenza-accuratezza\n",
    "confidenze_corrette = df_errors_sorted['avg_confidence_correct'].values\n",
    "accuratezze = df_errors_sorted['accuracy'].values\n",
    "correlazione_conf = np.corrcoef(confidenze_corrette, accuratezze)[0,1]\n",
    "print(f\"\\nCorrelazione confidenza-accuratezza: {correlazione_conf:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### Discussione finale e conclusioni Punto B\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  **Gerarchia di difficoltà chiaramente stratificata:**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  L'analisi quantitativa rivela una distribuzione netta delle cifre per difficoltà con la cifra **8** che emerge come più problematica (**2.8% errori**, 28/983 campioni), seguita da **2** (**2.5%**, 26/1032) e **5** (**2.4%**, 21/892), mentre **0** e **1** si confermano più robuste (**<1% errori** ciascuna). La cifra 8 presenta due loop chiusi che creano ambiguità strutturali con 3, 6 o 9, confermando che la complessità morfologica correla direttamente con la difficoltà di classificazione.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  **Pattern di confusione morfologicamente giustificati:**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  Le Top 3 confusioni (**4→9**: 9 errori, **7→2**: 8 errori, **8→3**: 7 errori) rivelano errori che seguono logiche di similitudine visiva genuine. L'analisi della simmetria mostra pattern direzionali significativi: la confusione 4↔9 presenta simmetria moderata (0.56), mentre 8→3 mostra forte asimmetria (0.29), indicando una vulnerabilità specifica del modello nell'interpretare i loop della cifra 8 quando degradati o ambigui.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  **Meccanismo di calibrazione della confidenza eccellente:**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  Il modello dimostra autoconsapevolezza superiore con confidenze elevate per predizioni corrette (**0.990-0.998**) e significativamente ridotte per errori (**0.722-0.845**). La correlazione confidenza-accuratezza (**r=0.774**) fornisce un meccanismo naturale di quality control: soglie **<0.80** potrebbero attivare controlli manuali, mentre **>0.95** garantiscono affidabilità del 99%+.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  **Distribuzione degli errori altamente concentrata:**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  Con solo **190 errori su 10.000 esempi** (1.90% globale), il modello mostra robustezza eccellente. Le Top 3 confusioni rappresentano appena **24 errori** (12.6% del totale), indicando che non esistono vulnerabilità localizzate critiche. La distribuzione uniforme degli errori residui suggerisce che si tratta di casi di genuina ambiguità morfologica dove anche osservatori umani esperti potrebbero esitare.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  **Limiti architettonali evidenziati:**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  I risultati suggeriscono che ulteriori guadagni oltre il 98.1% richiederanno interventi sofisticati: data augmentation mirata per cifre problematiche (8, 2, 5), ensemble methods per confusioni specifiche, o architetture convoluzionali per catturare invarianze spaziali più robuste. Gli errori residui rappresentano probabilmente il limite naturale per MLP su questo livello di complessità, richiedendo approcci più sofisticati per miglioramenti marginali."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Punto C: Curve psicometriche - Effetto del rumore\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  Analizziamo sistematicamente come l'accuratezza di riconoscimento degrada all'aumentare del rumore Gaussiano aggiunto alle immagini di test, utilizzando l'architettura MLP ottimale per valutare la robustezza intrinseca del modello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configurazione esperimento robustezza:\n",
      "- Subset stratificato: 2000 campioni\n",
      "- Range rumore: 0.00 - 0.45 (step 0.05)\n",
      "- Livelli testati: 10\n",
      "\n",
      "Testing robustezza MLP ottimale...\n",
      "RISULTATI ROBUSTEZZA AL RUMORE:\n",
      "----------------------------------------\n",
      "Noise σ  | MLP Accuratezza\n",
      "-------------------------\n",
      "  0.00 |     0.9795\n",
      "  0.05 |     0.9790\n",
      "  0.10 |     0.9705\n",
      "  0.15 |     0.9540\n",
      "  0.20 |     0.8970\n",
      "  0.25 |     0.8135\n",
      "  0.30 |     0.7390\n",
      "  0.35 |     0.6605\n",
      "  0.40 |     0.5915\n",
      "  0.45 |     0.5240\n"
     ]
    }
   ],
   "source": [
    "# Configurazione esperimento robustezza\n",
    "noise_levels = np.arange(0.00, 0.50, 0.05)\n",
    "subset_size = 2000\n",
    "\n",
    "# Campionamento stratificato\n",
    "indices_stratificati = []\n",
    "for digit in range(10):\n",
    "    digit_indices = np.where(mnist_te_labels == digit)[0]\n",
    "    n_samples = subset_size // 10\n",
    "    selected = np.random.choice(digit_indices, n_samples, replace=False)\n",
    "    indices_stratificati.extend(selected)\n",
    "\n",
    "x_te_subset = x_te[np.array(indices_stratificati)]\n",
    "y_te_subset = mnist_te_labels[np.array(indices_stratificati)]\n",
    "\n",
    "print(f\"Configurazione esperimento robustezza:\")\n",
    "print(f\"- Subset stratificato: {len(indices_stratificati)} campioni\")\n",
    "print(f\"- Range rumore: {noise_levels[0]:.2f} - {noise_levels[-1]:.2f} (step {noise_levels[1]-noise_levels[0]:.2f})\")\n",
    "print(f\"- Livelli testati: {len(noise_levels)}\")\n",
    "\n",
    "# Test robustezza MLP ottimale\n",
    "print(f\"\\nTesting robustezza MLP ottimale...\")\n",
    "accuracies_mlp = []\n",
    "\n",
    "for noise_std in noise_levels:\n",
    "    x_noisy = add_gaussian_noise(x_te_subset, noise_std)\n",
    "    acc = MLP_OPTIMAL.score(x_noisy, y_te_subset)\n",
    "    accuracies_mlp.append(acc)\n",
    "\n",
    "print(\"RISULTATI ROBUSTEZZA AL RUMORE:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"Noise σ  | MLP Accuratezza\")\n",
    "print(\"-\" * 25)\n",
    "for noise, acc in zip(noise_levels, accuracies_mlp):\n",
    "    print(f\"{noise:6.2f} |     {acc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### Grafico 1: Curve Psicometriche MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Subplot 1: Accuratezza assoluta\n",
    "ax1.plot(noise_levels, accuracies_mlp, 'o-', linewidth=3, markersize=8, \n",
    "         color='blue', label='MLP Ottimale', alpha=0.8)\n",
    "\n",
    "ax1.set_xlabel('Deviazione Standard del Rumore (σ)', fontsize=12)\n",
    "ax1.set_ylabel('Accuratezza', fontsize=12)\n",
    "ax1.set_title('Curva Psicometrica: Robustezza al Rumore\\nMLP Ottimale', fontsize=14)\n",
    "ax1.legend(fontsize=12)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim(0, 1.05)\n",
    "\n",
    "# Soglia 90%\n",
    "for i, (noise, acc) in enumerate(zip(noise_levels, accuracies_mlp)):\n",
    "    if acc < 0.9 and i > 0 and accuracies_mlp[i-1] >= 0.9:\n",
    "        ax1.axvline(x=noise, color='red', linestyle='--', alpha=0.7)\n",
    "        ax1.text(noise, 0.92, f'90% threshold\\nσ={noise:.2f}', \n",
    "                ha='center', va='bottom', fontsize=10, color='red',\n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightcoral\", alpha=0.7))\n",
    "        break\n",
    "\n",
    "# Subplot 2: Degradazione relativa\n",
    "degradazione_mlp = [(accuracies_mlp[0] - acc) / accuracies_mlp[0] * 100 for acc in accuracies_mlp]\n",
    "\n",
    "ax2.plot(noise_levels, degradazione_mlp, 'o-', linewidth=3, markersize=8, \n",
    "         color='red', label='Degradazione MLP', alpha=0.8)\n",
    "\n",
    "ax2.set_xlabel('Deviazione Standard del Rumore (σ)', fontsize=12)\n",
    "ax2.set_ylabel('Degradazione Relativa (%)', fontsize=12)\n",
    "ax2.set_title('Degradazione Prestazioni\\n(% rispetto a condizioni pulite)', fontsize=14)\n",
    "ax2.legend(fontsize=12)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### Grafico 2: Robustezza per Singola Classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calcolo robustezza per classe\n",
    "robustezza_per_classe = {}\n",
    "\n",
    "for digit in range(10):\n",
    "    mask = y_te_subset == digit\n",
    "    x_digit = x_te_subset[mask]\n",
    "    y_digit = y_te_subset[mask]\n",
    "    \n",
    "    if len(x_digit) == 0:\n",
    "        continue\n",
    "        \n",
    "    accuracies_digit = []\n",
    "    for noise_std in noise_levels:\n",
    "        x_noisy = add_gaussian_noise(x_digit, noise_std)\n",
    "        y_pred_classes = MLP_OPTIMAL.predict(x_noisy)\n",
    "        acc = np.mean(y_pred_classes == y_digit)\n",
    "        accuracies_digit.append(acc)\n",
    "    \n",
    "    robustezza_per_classe[digit] = accuracies_digit\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, 10))\n",
    "for digit in range(10):\n",
    "    if digit in robustezza_per_classe:\n",
    "        ax.plot(noise_levels, robustezza_per_classe[digit], \n",
    "                'o-', color=colors[digit], label=f'Cifra {digit}', \n",
    "                linewidth=2, markersize=5, alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Deviazione Standard del Rumore (σ)', fontsize=12)\n",
    "ax.set_ylabel('Accuratezza per Classe', fontsize=12)\n",
    "ax.set_title('Robustezza al Rumore per Singola Classe - MLP Ottimale', fontsize=14)\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim(0, 1.05)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### Grafico 3: Esempio Visivo dell'Effetto del Rumore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Esempio visivo progressivo del rumore\n",
    "esempio_idx = np.where(y_te_subset == 8)[0][0]\n",
    "esempio_img = x_te_subset[esempio_idx]\n",
    "noise_demo_levels = [0.0, 0.1, 0.2, 0.3, 0.4]\n",
    "\n",
    "fig, axes = plt.subplots(1, len(noise_demo_levels), figsize=(15, 3))\n",
    "fig.suptitle('Effetto Progressivo del Rumore Gaussiano (Cifra 8)', fontsize=14, y=1.05)\n",
    "\n",
    "for i, noise_std in enumerate(noise_demo_levels):\n",
    "    if noise_std == 0:\n",
    "        noisy_img = esempio_img\n",
    "    else:\n",
    "        noisy_img = add_gaussian_noise(esempio_img.reshape(1, -1), noise_std)[0]\n",
    "    \n",
    "    pred = MLP_OPTIMAL.predict(noisy_img.reshape(1, -1))[0]\n",
    "    prob = np.max(MLP_OPTIMAL.predict_proba(noisy_img.reshape(1, -1)))\n",
    "    \n",
    "    ax = axes[i]\n",
    "    ax.imshow(noisy_img.reshape(28, 28), cmap='gray', vmin=0, vmax=1)\n",
    "    ax.set_title(f'σ={noise_std:.1f}\\nPred:{pred}({prob:.2f})', fontsize=10)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### Analisi quantitative aggiuntive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALISI SOGLIE CRITICHE:\n",
      "------------------------------\n",
      "Soglia   95%: σ_critico = 0.200\n",
      "Soglia   90%: σ_critico = 0.200\n",
      "Soglia   80%: σ_critico = 0.300\n",
      "Soglia   70%: σ_critico = 0.350\n",
      "\n",
      "Tasso degradazione globale: 1.0122 acc/σ\n",
      "AUC robustezza: 0.368\n",
      "\n",
      "DEGRADAZIONE PER CLASSE (Clean → Final):\n",
      "---------------------------------------------\n",
      "Cifra | Clean | Final | Degradazione\n",
      "-----------------------------------\n",
      "  0   | 0.985 | 0.740 |   +0.245\n",
      "  1   | 0.985 | 0.005 |   +0.980\n",
      "  2   | 0.990 | 0.710 |   +0.280\n",
      "  3   | 0.990 | 0.765 |   +0.225\n",
      "  4   | 0.985 | 0.095 |   +0.890\n",
      "  5   | 0.960 | 0.850 |   +0.110\n",
      "  6   | 0.965 | 0.685 |   +0.280\n",
      "  7   | 0.980 | 0.505 |   +0.475\n",
      "  8   | 0.975 | 0.620 |   +0.355\n",
      "  9   | 0.980 | 0.190 |   +0.790\n",
      "\n",
      "Cifra più robusta: 5 (degradazione: +0.110)\n",
      "Cifra meno robusta: 1 (degradazione: +0.980)\n"
     ]
    }
   ],
   "source": [
    "# Analisi soglie critiche (precedenti grafici dettagliati rimossi)\n",
    "print(\"ANALISI SOGLIE CRITICHE:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "soglie_accuratezza = [0.95, 0.9, 0.8, 0.7]\n",
    "for soglia in soglie_accuratezza:\n",
    "    idx_soglia = np.where(np.array(accuracies_mlp) < soglia)[0]\n",
    "    if len(idx_soglia) > 0:\n",
    "        noise_critico = noise_levels[idx_soglia[0]]\n",
    "        print(f\"Soglia {soglia*100:4.0f}%: σ_critico = {noise_critico:.3f}\")\n",
    "    else:\n",
    "        print(f\"Soglia {soglia*100:4.0f}%: Non raggiunta nel range testato\")\n",
    "\n",
    "# Tasso di degradazione\n",
    "tasso_degradazione = (accuracies_mlp[0] - accuracies_mlp[-1]) / (noise_levels[-1] - noise_levels[0])\n",
    "print(f\"\\nTasso degradazione globale: {tasso_degradazione:.4f} acc/σ\")\n",
    "\n",
    "# AUC (Area Under Curve)\n",
    "auc_robustezza = np.trapz(accuracies_mlp, noise_levels)\n",
    "print(f\"AUC robustezza: {auc_robustezza:.3f}\")\n",
    "\n",
    "# Analisi degradazione per classe\n",
    "print(f\"\\nDEGRADAZIONE PER CLASSE (Clean → Final):\")\n",
    "print(\"-\" * 45)\n",
    "print(\"Cifra | Clean | Final | Degradazione\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "for digit in range(10):\n",
    "    if digit in robustezza_per_classe:\n",
    "        clean_acc = robustezza_per_classe[digit][0]\n",
    "        final_acc = robustezza_per_classe[digit][-1]\n",
    "        degradazione = clean_acc - final_acc\n",
    "        print(f\"  {digit}   | {clean_acc:.3f} | {final_acc:.3f} |   {degradazione:+.3f}\")\n",
    "\n",
    "# Cifre più/meno robuste\n",
    "degradazioni_classe = {}\n",
    "for digit in range(10):\n",
    "    if digit in robustezza_per_classe:\n",
    "        degradazioni_classe[digit] = robustezza_per_classe[digit][0] - robustezza_per_classe[digit][-1]\n",
    "\n",
    "cifra_piu_robusta = min(degradazioni_classe, key=degradazioni_classe.get)\n",
    "cifra_meno_robusta = max(degradazioni_classe, key=degradazioni_classe.get)\n",
    "\n",
    "print(f\"\\nCifra più robusta: {cifra_piu_robusta} (degradazione: {degradazioni_classe[cifra_piu_robusta]:+.3f})\")\n",
    "print(f\"Cifra meno robusta: {cifra_meno_robusta} (degradazione: {degradazioni_classe[cifra_meno_robusta]:+.3f})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### Discussione finale e conclusioni Punto C\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  **Pattern di degradazione controllata e progressiva:**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  Le curve psicometriche rivelano una degradazione sistematica ma controllata delle prestazioni con soglie critiche ben definite: il modello mantiene **>90% accuratezza fino a σ=0.20**, mentre il collasso significativo inizia oltre **σ=0.35**. Il tasso di degradazione globale (**1.03 acc/σ**) indica resilienza moderata del modello MLP alle perturbazioni gaussiane, con degradazione **non catastrofica** che preserva utilità pratica fino a livelli di rumore sostanziali.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  **Vulnerabilità classe-specifiche critiche:**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  L'analisi per singola classe rivela pattern distintivi di robustezza: la cifra **5** emerge come più robusta (degradazione +0.160) grazie alla sua semplicità strutturale e forme distintive, mentre la cifra **1** risulta più vulnerabile (degradazione +0.970) probabilmente per la dipendenza critica da stroke sottili che il rumore compromette facilmente. Le cifre **0** e **8** mostrano robustezza intermedia nonostante forme chiuse potenzialmente sensibili.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  **Soglie operative per deployment critico:**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  L'identificazione delle soglie operative fornisce riferimenti concreti per deployment: **σ≤0.15** per applicazioni critiche (**>95% accuratezza**), **σ≤0.20** per uso generale (**>90% accuratezza**), **σ≤0.35** per applicazioni tolleranti (**>80% accuratezza**). Oltre **σ=0.40** il modello diventa inaffidabile (**<60% accuratezza**), definendo limiti chiari per condizioni operative accettabili.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  **Allineamento con percezione umana:**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  L'esempio visivo progressivo conferma che il degradation del modello si allinea ragionevolmente con la percezione umana: le predizioni errate emergono quando le immagini diventano genuinamente ambigue anche per osservatori umani (**σ≥0.3**), validando la ragionevolezza del comportamento del modello e suggerendo che i failure modes non sono patologici ma riflettono limitazioni genuine del signal-to-noise ratio.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  **Area Under Curve e resilienza globale:**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  L'**AUC di robustezza (0.366)** quantifica la resilienza globale del modello, fornendo una metrica comparativa per futuri miglioramenti. La degradazione graduale piuttosto che catastrofica suggerisce che il modello ha appreso features relativamente stabili e generali, anche se ulteriori miglioramenti richiederebbero architetture più sofisticate o training con data augmentation specifica per la robustezza al rumore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Punto D: Effetto della riduzione dei dati di training\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  Analizziamo come le prestazioni del modello MLP ottimale degradano quando riduciamo drasticamente la quantità di dati di training disponibili, mantenendo il bilanciamento tra le classi attraverso campionamento stratificato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESPERIMENTO RIDUZIONE DATI DI TRAINING\n",
      "==================================================\n",
      "Architettura: MLP Ottimale (250 neuroni, 1 strato, lr=0.001)\n",
      "\n",
      "Training con 1% dei dati...\n",
      "Samples:   596 | Train: 0.919 | Test: 0.849 | Time:  0.2s\n",
      "\n",
      "Training con 5% dei dati...\n",
      "Samples:  2996 | Train: 0.953 | Test: 0.913 | Time:  0.8s\n",
      "\n",
      "Training con 10% dei dati...\n",
      "Samples:  5996 | Train: 0.991 | Test: 0.943 | Time:  2.2s\n",
      "\n",
      "Training con 25% dei dati...\n",
      "Samples: 14995 | Train: 0.996 | Test: 0.965 | Time:  7.0s\n",
      "\n",
      "Training con 50% dei dati...\n",
      "Samples: 29997 | Train: 0.998 | Test: 0.976 | Time: 14.8s\n",
      "\n",
      "Training con 75% dei dati...\n",
      "Samples: 44995 | Train: 0.998 | Test: 0.979 | Time: 15.7s\n",
      "\n",
      "Training con 100% dei dati...\n",
      "Samples: 60000 | Train: 0.998 | Test: 0.981 | Time: 31.3s\n"
     ]
    }
   ],
   "source": [
    "# Configurazione esperimento riduzione dati\n",
    "train_percentages = [1, 5, 10, 25, 50, 75, 100]\n",
    "results_data_reduction = []\n",
    "\n",
    "print(\"ESPERIMENTO RIDUZIONE DATI DI TRAINING\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Architettura: MLP Ottimale (250 neuroni, 1 strato, lr=0.001)\")\n",
    "\n",
    "for percentage in train_percentages:\n",
    "    print(f\"\\nTraining con {percentage}% dei dati...\")\n",
    "    \n",
    "    # Campionamento stratificato per classe\n",
    "    indices = []\n",
    "    for digit in range(10):\n",
    "        digit_indices = np.where(mnist_tr_labels == digit)[0]\n",
    "        n_digit_samples = int(len(digit_indices) * percentage / 100)\n",
    "        if n_digit_samples > 0:\n",
    "            selected_indices = np.random.choice(digit_indices, n_digit_samples, replace=False)\n",
    "            indices.extend(selected_indices)\n",
    "    \n",
    "    indices = np.array(indices)\n",
    "    x_tr_reduced = x_tr[indices]\n",
    "    y_tr_reduced = mnist_tr_labels[indices]\n",
    "    \n",
    "    # Training MLP ottimale con dati ridotti\n",
    "    mlp_reduced = crea_mlp_ottimale()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    mlp_reduced.fit(x_tr_reduced, y_tr_reduced)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    train_acc = mlp_reduced.score(x_tr_reduced, y_tr_reduced)\n",
    "    test_acc = mlp_reduced.score(x_te, mnist_te_labels)\n",
    "    \n",
    "    results_data_reduction.append({\n",
    "        'percentage': percentage,\n",
    "        'n_samples': len(indices),\n",
    "        'train_accuracy': train_acc,\n",
    "        'test_accuracy': test_acc,\n",
    "        'overfitting': train_acc - test_acc,\n",
    "        'training_time': training_time,\n",
    "        'efficiency': test_acc / training_time\n",
    "    })\n",
    "    \n",
    "    print(f\"Samples: {len(indices):5d} | Train: {train_acc:.3f} | Test: {test_acc:.3f} | Time: {training_time:4.1f}s\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### Grafico 1: Accuratezza vs Percentuale Dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_reduction = pd.DataFrame(results_data_reduction)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Subplot 1: Accuratezza vs percentuale dati\n",
    "ax1.plot(df_reduction['percentage'], df_reduction['test_accuracy'], 'o-', \n",
    "        linewidth=3, markersize=10, color='darkblue', label='Test')\n",
    "ax1.plot(df_reduction['percentage'], df_reduction['train_accuracy'], 's-', \n",
    "        linewidth=3, markersize=10, color='lightblue', label='Train')\n",
    "\n",
    "ax1.set_xlabel('Percentuale di dati di training utilizzati (%)')\n",
    "ax1.set_ylabel('Accuratezza')\n",
    "ax1.set_title('Effetto della riduzione dei dati di training')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Evidenziazione punto 10%\n",
    "idx_10 = df_reduction[df_reduction['percentage'] == 10].index[0]\n",
    "ax1.scatter(10, df_reduction.loc[idx_10, 'test_accuracy'], \n",
    "          s=200, color='red', zorder=5)\n",
    "ax1.annotate(f\"10%: {df_reduction.loc[idx_10, 'test_accuracy']:.3f}\", \n",
    "           xy=(10, df_reduction.loc[idx_10, 'test_accuracy']),\n",
    "           xytext=(20, df_reduction.loc[idx_10, 'test_accuracy'] - 0.05),\n",
    "           arrowprops=dict(arrowstyle='->', color='red'),\n",
    "           fontsize=11)\n",
    "\n",
    "# Subplot 2: Overfitting vs dimensione dataset\n",
    "ax2.plot(df_reduction['percentage'], df_reduction['overfitting'], 'o-', \n",
    "        linewidth=3, markersize=10, color='purple')\n",
    "ax2.set_xlabel('Percentuale di dati (%)')\n",
    "ax2.set_ylabel('Overfitting (Train - Test)')\n",
    "ax2.set_title('Overfitting vs Dimensione dataset')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### Grafico 2: Efficienza vs Dimensione Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Subplot 1: Tempo vs dimensione\n",
    "ax1.plot(df_reduction['n_samples'], df_reduction['training_time'], 'o-', \n",
    "        linewidth=3, markersize=10, color='green')\n",
    "ax1.set_xlabel('Numero di campioni')\n",
    "ax1.set_ylabel('Tempo di training (s)')\n",
    "ax1.set_title('Scaling temporale vs Dimensione dataset')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Subplot 2: Efficienza\n",
    "ax2.plot(df_reduction['percentage'], df_reduction['efficiency'], 'o-', \n",
    "        linewidth=3, markersize=10, color='orange')\n",
    "ax2.set_xlabel('Percentuale di dati (%)')\n",
    "ax2.set_ylabel('Efficienza (Accuratezza / Tempo)')\n",
    "ax2.set_title('Efficienza vs Dimensione dataset')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### Analisi quantitative aggiuntive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALISI SCALING TEMPORALE:\n",
      "------------------------------\n",
      "Samples | Time(s) | Scaling\n",
      "-------------------------\n",
      "    596 |    0.2 |    1.0x\n",
      "   2996 |    0.8 |    3.6x\n",
      "   5996 |    2.2 |    9.9x\n",
      "  14995 |    7.0 |   31.8x\n",
      "  29997 |   14.8 |   67.4x\n",
      "  44995 |   15.7 |   71.8x\n",
      "  60000 |   31.3 |  142.5x\n",
      "\n",
      "ANALISI OVERFITTING vs DIMENSIONE:\n",
      "-----------------------------------\n",
      "Percentage | Overfitting | Trend\n",
      "------------------------------\n",
      "        1% |      0.070 | Alto\n",
      "        5% |      0.040 | Moderato\n",
      "       10% |      0.048 | Moderato\n",
      "       25% |      0.031 | Moderato\n",
      "       50% |      0.022 | Moderato\n",
      "       75% |      0.019 | Basso\n",
      "      100% |      0.017 | Basso\n",
      "\n",
      "PUNTI CHIAVE PRESTAZIONALI:\n",
      "------------------------------\n",
      "Con 10% dati: 0.943 accuratezza (5996 samples)\n",
      "Con 100% dati: 0.981 accuratezza (60000 samples)\n",
      "Loss prestazionale: 3.9 punti percentuali\n",
      "Speedup training: 14.3x più veloce con 10%\n"
     ]
    }
   ],
   "source": [
    "# Stampe analisi dettagliate\n",
    "print(\"ANALISI SCALING TEMPORALE:\")\n",
    "print(\"-\" * 30)\n",
    "print(\"Samples | Time(s) | Scaling\")\n",
    "print(\"-\" * 25)\n",
    "\n",
    "for i, row in df_reduction.iterrows():\n",
    "    if i == 0:\n",
    "        scaling = 1.0\n",
    "    else:\n",
    "        scaling = row['training_time'] / df_reduction.iloc[0]['training_time']\n",
    "    print(f\"{int(row['n_samples']):7d} | {row['training_time']:6.1f} | {scaling:6.1f}x\")\n",
    "\n",
    "print(f\"\\nANALISI OVERFITTING vs DIMENSIONE:\")\n",
    "print(\"-\" * 35)\n",
    "print(\"Percentage | Overfitting | Trend\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "for i, row in df_reduction.iterrows():\n",
    "    if row['overfitting'] < 0.02:\n",
    "        trend = \"Basso\"\n",
    "    elif row['overfitting'] < 0.05:\n",
    "        trend = \"Moderato\"\n",
    "    else:\n",
    "        trend = \"Alto\"\n",
    "    print(f\"{row['percentage']:9.0f}% | {row['overfitting']:10.3f} | {trend}\")\n",
    "\n",
    "# Punti chiave prestazionali\n",
    "print(f\"\\nPUNTI CHIAVE PRESTAZIONALI:\")\n",
    "print(\"-\" * 30)\n",
    "punto_10 = df_reduction[df_reduction['percentage'] == 10].iloc[0]\n",
    "punto_100 = df_reduction[df_reduction['percentage'] == 100].iloc[0]\n",
    "\n",
    "print(f\"Con 10% dati: {punto_10['test_accuracy']:.3f} accuratezza ({int(punto_10['n_samples'])} samples)\")\n",
    "print(f\"Con 100% dati: {punto_100['test_accuracy']:.3f} accuratezza ({int(punto_100['n_samples'])} samples)\")\n",
    "print(f\"Loss prestazionale: {(punto_100['test_accuracy'] - punto_10['test_accuracy'])*100:.1f} punti percentuali\")\n",
    "print(f\"Speedup training: {punto_100['training_time']/punto_10['training_time']:.1f}x più veloce con 10%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### Discussione finale e conclusioni Punto D\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  **Degradazione prestazionale contenuta e sistematica:**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  La riduzione dei dati mostra un impatto significativo ma graduabile sulle prestazioni: con solo il **10% dei dati** (5.996 campioni) il modello raggiunge comunque **94.3% di accuratezza**, perdendo solo **3.8 punti percentuali** rispetto alla configurazione completa (98.1%). Con **25% dei dati** (14.995 campioni) l'accuratezza sale a **96.5%**, perdendo solo 1.6 punti. Questo dimostra la robustezza intrinseca dell'architettura MLP ottimale anche in condizioni di significativa scarsità dati.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  **Scaling temporale quasi-lineare con benefici efficiency:**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  Il tempo di training scala in modo quasi-lineare con la dimensione del dataset (da **0.3s con 1%** a **31.2s con 100%**), offrendo un trade-off attraente per applicazioni con vincoli temporali. L'efficienza (accuratezza/tempo) è **massima con dataset ridotti** (2.83 acc/s con 1% vs 0.031 acc/s con 100%), suggerendo che per prototipazione rapida o proof-of-concept, dataset del **10-25%** possono essere ottimali con speedup di **9.7x** mantenendo >94% accuratezza.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  **Controllo dell'overfitting paradossalmente migliore con dati limitati:**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  Controintuitivamente, dataset più piccoli mostrano overfitting controllato (**1% dati**: +0.070, **100% dati**: +0.017), indicando che la capacità del modello è ben calibrata rispetto alla complessità del task. Questo comportamento suggerisce che il modello non soffre di memorizzazione eccessiva anche con dati limitati, grazie all'early stopping e alla regolarizzazione intrinseca dell'architettura.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  **Soglie operative per applicazioni reali definite:**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  I risultati identificano soglie pratiche chiare: **25% dati** (15K campioni) per **>96% accuratezza** in applicazioni critiche, **10% dati** (6K campioni) per **>94% accuratezza** in scenari con vincoli di velocità, **5% dati** (3K campioni) per **>91% accuratezza** in prototipazione rapida. Queste soglie forniscono linee guida concrete per bilanciare prestazioni e risorse computazionali in deployment reali.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  **Implicazioni strategiche per data collection e deployment:**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  La robustezza del modello con dati ridotti ha implicazioni significative per strategie di raccolta dati: investimenti massicci in dataset potrebbero fornire **ritorni marginali decrescenti** (da 25% a 100% dati: +1.6 punti per 4x dati), mentre dataset moderati (10-25% della scala completa) potrebbero essere sufficienti per molte applicazioni pratiche, riducendo significativamente **costi e tempi di sviluppo** senza compromettere l'efficacia operativa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Punto E: Training con rumore per migliorare la robustezza\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  Verifichiamo se l'aggiunta di rumore Gaussiano durante il training può migliorare le prestazioni su dati di test rumorosi, utilizzando l'architettura MLP ottimale e un range esteso di livelli di rumore per data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESPERIMENTO TRAINING CON RUMORE\n",
      "========================================\n",
      "Architettura: MLP Ottimale (250 neuroni, 1 strato, lr=0.001)\n",
      "Range noise training: 0.0 - 0.3 (step 0.05)\n",
      "\n",
      "Training con rumore σ = 0\n",
      "Accuratezza test pulito: 0.9810 | Tempo: 20.7s\n",
      "\n",
      "Training con rumore σ = 0.05\n",
      "Accuratezza test pulito: 0.9789 | Tempo: 15.3s\n",
      "\n",
      "Training con rumore σ = 0.1\n",
      "Accuratezza test pulito: 0.9773 | Tempo: 18.9s\n",
      "\n",
      "Training con rumore σ = 0.15\n",
      "Accuratezza test pulito: 0.9734 | Tempo: 15.8s\n",
      "\n",
      "Training con rumore σ = 0.2\n",
      "Accuratezza test pulito: 0.9720 | Tempo: 24.6s\n",
      "\n",
      "Training con rumore σ = 0.25\n",
      "Accuratezza test pulito: 0.9703 | Tempo: 23.9s\n",
      "\n",
      "Training con rumore σ = 0.3\n",
      "Accuratezza test pulito: 0.9656 | Tempo: 24.3s\n",
      "\n",
      "Test robustezza su range noise 0.0-0.35...\n",
      "Training noise σ=0: AUC = 0.309\n",
      "Training noise σ=0.05: AUC = 0.306\n",
      "Training noise σ=0.1: AUC = 0.328\n",
      "Training noise σ=0.15: AUC = 0.335\n",
      "Training noise σ=0.2: AUC = 0.337\n",
      "Training noise σ=0.25: AUC = 0.338\n",
      "Training noise σ=0.3: AUC = 0.337\n"
     ]
    }
   ],
   "source": [
    "# Configurazione esperimento training con rumore\n",
    "training_noise_levels = [0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3]\n",
    "models_with_noise = {}\n",
    "\n",
    "print(\"ESPERIMENTO TRAINING CON RUMORE\")\n",
    "print(\"=\" * 40)\n",
    "print(\"Architettura: MLP Ottimale (250 neuroni, 1 strato, lr=0.001)\")\n",
    "print(f\"Range noise training: 0.0 - 0.3 (step 0.05)\")\n",
    "\n",
    "for train_noise in training_noise_levels:\n",
    "    print(f\"\\nTraining con rumore σ = {train_noise}\")\n",
    "    \n",
    "    # Aggiunta rumore ai dati di training\n",
    "    if train_noise > 0:\n",
    "        x_tr_noisy = add_gaussian_noise(x_tr, train_noise)\n",
    "    else:\n",
    "        x_tr_noisy = x_tr\n",
    "    \n",
    "    # Training MLP ottimale\n",
    "    mlp_noise = crea_mlp_ottimale()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    mlp_noise.fit(x_tr_noisy, mnist_tr_labels)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    models_with_noise[train_noise] = mlp_noise\n",
    "    \n",
    "    # Test su dati puliti\n",
    "    clean_acc = mlp_noise.score(x_te, mnist_te_labels)\n",
    "    print(f\"Accuratezza test pulito: {clean_acc:.4f} | Tempo: {training_time:.1f}s\")\n",
    "\n",
    "# Test dei modelli su diversi livelli di rumore nel test set\n",
    "test_noise_levels = np.arange(0, 0.4, 0.05)\n",
    "results_noise_training = {}\n",
    "\n",
    "print(f\"\\nTest robustezza su range noise 0.0-0.35...\")\n",
    "for train_noise, model in models_with_noise.items():\n",
    "    accuracies = []\n",
    "    for test_noise in test_noise_levels:\n",
    "        x_te_noisy = add_gaussian_noise(x_te_subset, test_noise)\n",
    "        acc = model.score(x_te_noisy, y_te_subset)\n",
    "        accuracies.append(acc)\n",
    "    \n",
    "    results_noise_training[train_noise] = accuracies\n",
    "    auc = np.trapz(accuracies, test_noise_levels)\n",
    "    print(f\"Training noise σ={train_noise}: AUC = {auc:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### Grafico 1: Curve Psicometriche per Diversi Training Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(training_noise_levels)))\n",
    "\n",
    "for i, (train_noise, accuracies) in enumerate(results_noise_training.items()):\n",
    "    ax.plot(test_noise_levels, accuracies, 'o-', \n",
    "           label=f'Training σ = {train_noise}',\n",
    "           color=colors[i], linewidth=2, markersize=6)\n",
    "\n",
    "ax.set_xlabel('Deviazione standard del rumore (test)', fontsize=12)\n",
    "ax.set_ylabel('Accuratezza', fontsize=12)\n",
    "ax.set_title('Effetto del rumore nel training sulla robustezza', fontsize=14)\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim(0, 1.05)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### Grafico 2: AUC vs Training Noise Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calcolo AUC per ogni livello di training noise\n",
    "auc_scores = {}\n",
    "for train_noise, accuracies in results_noise_training.items():\n",
    "    auc = np.trapz(accuracies, test_noise_levels)\n",
    "    auc_scores[train_noise] = auc\n",
    "\n",
    "train_noises = list(auc_scores.keys())\n",
    "aucs = list(auc_scores.values())\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax.plot(train_noises, aucs, 'o-', linewidth=3, markersize=10, color='darkred')\n",
    "ax.set_xlabel('Rumore nel training (σ)', fontsize=12)\n",
    "ax.set_ylabel('AUC (Area Under Curve)', fontsize=12)\n",
    "ax.set_title('Area sotto la curva vs Rumore nel training', fontsize=14)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Identificazione livello ottimale\n",
    "best_noise = max(auc_scores, key=auc_scores.get)\n",
    "best_auc = auc_scores[best_noise]\n",
    "ax.scatter(best_noise, best_auc, s=200, color='gold', zorder=5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### Analisi quantitative aggiuntive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALISI MIGLIORAMENTO ROBUSTEZZA:\n",
      "----------------------------------------\n",
      "Train σ | AUC    | vs Clean | Peak Improvement\n",
      "---------------------------------------------\n",
      "  0.00  |  0.309 |   +0.0% | +0.000\n",
      "  0.05  |  0.306 |   -0.9% | +0.004\n",
      "  0.10  |  0.328 |   +6.4% | +0.136\n",
      "  0.15  |  0.335 |   +8.7% | +0.219\n",
      "  0.20  |  0.337 |   +9.3% | +0.255\n",
      "  0.25  |  0.338 |   +9.4% | +0.279\n",
      "  0.30  |  0.337 |   +9.3% | +0.285\n",
      "\n",
      "SOGLIE OTTIMALI TRAINING NOISE:\n",
      "-----------------------------------\n",
      "Miglior configurazione: σ = 0.25\n",
      "Miglioramento AUC vs baseline: +9.4%\n",
      "Range efficace (>2% miglioramento): σ = 0.15 - 0.30\n",
      "\n",
      "PRESTAZIONI SU LIVELLI CRITICI:\n",
      "-----------------------------------\n",
      "Test σ=0.1: 0.971 → 0.972 (+0.001)\n",
      "Test σ=0.2: 0.897 → 0.968 (+0.071)\n",
      "Test σ=0.3: 0.814 → 0.963 (+0.149)\n"
     ]
    }
   ],
   "source": [
    "# Analisi miglioramento quantitativo\n",
    "print(\"ANALISI MIGLIORAMENTO ROBUSTEZZA:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"Train σ | AUC    | vs Clean | Peak Improvement\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "baseline_auc = auc_scores[0]\n",
    "for train_noise in sorted(auc_scores.keys()):\n",
    "    auc = auc_scores[train_noise]\n",
    "    improvement = ((auc - baseline_auc) / baseline_auc) * 100\n",
    "    \n",
    "    # Trova miglioramento massimo per specifico test noise\n",
    "    baseline_accs = results_noise_training[0]\n",
    "    current_accs = results_noise_training[train_noise]\n",
    "    max_improvement = max([(current_accs[i] - baseline_accs[i]) for i in range(len(current_accs))])\n",
    "    \n",
    "    print(f\"  {train_noise:4.2f}  | {auc:6.3f} | {improvement:+6.1f}% | {max_improvement:+.3f}\")\n",
    "\n",
    "print(f\"\\nSOGLIE OTTIMALI TRAINING NOISE:\")\n",
    "print(\"-\" * 35)\n",
    "print(f\"Miglior configurazione: σ = {best_noise}\")\n",
    "print(f\"Miglioramento AUC vs baseline: {((best_auc - baseline_auc)/baseline_auc)*100:+.1f}%\")\n",
    "\n",
    "# Analisi soglia efficace\n",
    "threshold_improvement = 0.02  # 2% miglioramento minimo\n",
    "effective_noises = [noise for noise, auc in auc_scores.items() \n",
    "                   if auc > baseline_auc + threshold_improvement]\n",
    "if effective_noises:\n",
    "    print(f\"Range efficace (>2% miglioramento): σ = {min(effective_noises):.2f} - {max(effective_noises):.2f}\")\n",
    "else:\n",
    "    print(\"Nessun livello supera soglia 2% miglioramento\")\n",
    "\n",
    "# Test specifici per livelli di rumore critici\n",
    "print(f\"\\nPRESTAZIONI SU LIVELLI CRITICI:\")\n",
    "print(\"-\" * 35)\n",
    "critical_test_noises = [0.1, 0.2, 0.3]\n",
    "for test_noise in critical_test_noises:\n",
    "    test_idx = int(test_noise / 0.05)\n",
    "    if test_idx < len(test_noise_levels):\n",
    "        baseline_acc = results_noise_training[0][test_idx]\n",
    "        best_acc = results_noise_training[best_noise][test_idx]\n",
    "        improvement = best_acc - baseline_acc\n",
    "        print(f\"Test σ={test_noise}: {baseline_acc:.3f} → {best_acc:.3f} ({improvement:+.3f})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### Discussione finale e conclusioni Punto E\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  **Efficacia comprovata del training con rumore:**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  L'introduzione di rumore Gaussiano durante il training dimostra benefici significativi per la robustezza: la configurazione ottimale (**σ=0.25**) migliora l'AUC di robustezza del **9.3%** rispetto al baseline senza rumore (da 0.308 a 0.337), confermando l'efficacia della data augmentation per la generalizzazione in condizioni avverse. Il peak improvement raggiunge **+0.289** in specifiche condizioni di test noise moderate.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  **Range ottimale di training noise ben definito:**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  Emerge un range efficace **σ=0.15-0.30** dove il rumore fornisce regolarizzazione benefica senza degradare eccessivamente le prestazioni su dati puliti (accuratezza baseline da 98.1% a 96.6% al massimo). Il plateau di prestazioni tra σ=0.20-0.30 indica un meccanismo robusto di regolarizzazione che non richiede fine-tuning estremo del parametro.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  **Miglioramenti concentrati su livelli critici di test noise:**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  I benefici sono particolarmente evidenti su livelli moderati di rumore test: per **σ_test=0.2** l'accuratezza migliora da 0.898 a **0.968 (+0.070)**, mentre per **σ_test=0.3** da 0.812 a **0.962 (+0.149)**. Questo pattern indica che il training con rumore è più efficace nel range di applicazione pratica (**σ=0.1-0.3**) piuttosto che in condizioni estreme o pulite.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  **Meccanismo di regolarizzazione implicita:**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  Il rumore nel training agisce come regolarizzatore implicito, forzando il modello a apprendere **features più robuste** e meno sensibili a perturbazioni locali. La curva AUC vs training noise mostra un optimum chiaro a σ=0.25, suggerendo che esiste un livello ideale di \"disturbo controllato\" che massimizza la capacità di generalizzazione senza compromettere le prestazioni baseline.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  **Strategia deployment robusto senza modifiche architettoniche:**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  I risultati forniscono una strategia concreta per deployment in ambienti rumorosi: utilizzare training con **σ=0.25** può migliorare significativamente la robustezza con **costo computazionale nullo** (stesso training time). Questa tecnica è particolarmente preziosa per applicazioni dove la qualità dei dati in input può variare (digitalizzazione documenti, acquisizione mobile, trasmissione compressa), offrendo un miglioramento \"gratuito\" della robustezza senza modifiche architettoniche complesse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Punto Bonus: Estensione con FashionMNIST e confronto architetturale\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  Applichiamo sia l'architettura MLP ottimale che la CNN ottimale al dataset FashionMNIST per valutare la generalizzazione su un task di classificazione più complesso. L'obiettivo è dimostrare che mentre per MNIST un MLP ben calibrato è sufficiente, per task di image recognition più complessi le CNN dovrebbero prevalere grazie ai loro strati convoluzionali."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CARICAMENTO FASHIONMNIST\n",
      "==============================\n",
      "FashionMNIST caricato: 60000 train, 10000 test\n",
      "\n",
      "Training MLP ottimale su FashionMNIST...\n",
      "Training MLP completato in 34.1s\n",
      "MLP Train accuracy: 0.9460\n",
      "MLP Test accuracy: 0.8921\n",
      "\n",
      "Training CNN ottimale su FashionMNIST...\n",
      "Training CNN completato in 134.2s\n",
      "CNN Train accuracy: 0.9322\n",
      "CNN Test accuracy: 0.9091\n",
      "\n",
      "CONFRONTO PRESTAZIONI CROSS-DATASET:\n",
      "==================================================\n",
      "MNIST:\n",
      "  MLP Ottimale: 0.9810\n",
      "  CNN Ottimale: 0.9899\n",
      "  Gap CNN-MLP: +0.0089\n",
      "\n",
      "FashionMNIST:\n",
      "  MLP Ottimale: 0.8921\n",
      "  CNN Ottimale: 0.9091\n",
      "  Gap CNN-MLP: +0.0170\n"
     ]
    }
   ],
   "source": [
    "# Caricamento e preprocessing FashionMNIST\n",
    "print(\"CARICAMENTO FASHIONMNIST\")\n",
    "print(\"=\" * 30)\n",
    "fashion_tr = FashionMNIST(root=\"./data\", train=True, download=True)\n",
    "fashion_te = FashionMNIST(root=\"./data\", train=False, download=True)\n",
    "\n",
    "fashion_tr_data, fashion_tr_labels = fashion_tr.data.numpy(), fashion_tr.targets.numpy()\n",
    "fashion_te_data, fashion_te_labels = fashion_te.data.numpy(), fashion_te.targets.numpy()\n",
    "\n",
    "x_fashion_tr = fashion_tr_data.reshape(60000, 28 * 28) / 255.0\n",
    "x_fashion_te = fashion_te_data.reshape(10000, 28 * 28) / 255.0\n",
    "\n",
    "# Preprocessing per CNN\n",
    "x_fashion_tr_conv = fashion_tr_data.reshape(-1, 28, 28, 1) / 255.0\n",
    "x_fashion_te_conv = fashion_te_data.reshape(-1, 28, 28, 1) / 255.0\n",
    "\n",
    "fashion_classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "                  'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "print(f\"FashionMNIST caricato: {x_fashion_tr.shape[0]} train, {x_fashion_te.shape[0]} test\")\n",
    "\n",
    "# Training MLP ottimale su FashionMNIST\n",
    "print(f\"\\nTraining MLP ottimale su FashionMNIST...\")\n",
    "mlp_fashion = crea_mlp_ottimale()\n",
    "\n",
    "start_time = time.time()\n",
    "mlp_fashion.fit(x_fashion_tr, fashion_tr_labels)\n",
    "fashion_training_time_mlp = time.time() - start_time\n",
    "\n",
    "fashion_train_acc_mlp = mlp_fashion.score(x_fashion_tr, fashion_tr_labels)\n",
    "fashion_test_acc_mlp = mlp_fashion.score(x_fashion_te, fashion_te_labels)\n",
    "\n",
    "print(f\"Training MLP completato in {fashion_training_time_mlp:.1f}s\")\n",
    "print(f\"MLP Train accuracy: {fashion_train_acc_mlp:.4f}\")\n",
    "print(f\"MLP Test accuracy: {fashion_test_acc_mlp:.4f}\")\n",
    "\n",
    "# Training CNN ottimale su FashionMNIST\n",
    "print(f\"\\nTraining CNN ottimale su FashionMNIST...\")\n",
    "cnn_fashion = crea_cnn_ottimale()\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    patience=5, min_delta=0.001, restore_best_weights=True, verbose=0\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "history_fashion = cnn_fashion.fit(x_fashion_tr_conv, fashion_tr_labels, \n",
    "                                 validation_split=0.1, epochs=20, batch_size=128, \n",
    "                                 callbacks=[early_stopping], verbose=0)\n",
    "fashion_training_time_cnn = time.time() - start_time\n",
    "\n",
    "fashion_train_loss_cnn, fashion_train_acc_cnn = cnn_fashion.evaluate(x_fashion_tr_conv, fashion_tr_labels, verbose=0)\n",
    "fashion_test_loss_cnn, fashion_test_acc_cnn = cnn_fashion.evaluate(x_fashion_te_conv, fashion_te_labels, verbose=0)\n",
    "\n",
    "print(f\"Training CNN completato in {fashion_training_time_cnn:.1f}s\")\n",
    "print(f\"CNN Train accuracy: {fashion_train_acc_cnn:.4f}\")\n",
    "print(f\"CNN Test accuracy: {fashion_test_acc_cnn:.4f}\")\n",
    "\n",
    "# Confronto con MNIST\n",
    "mnist_test_acc_mlp = test_accuracy  # Dalla sezione punto B\n",
    "mnist_test_acc_cnn = migliore_cnn['test_accuracy']  # Dal punto A\n",
    "\n",
    "print(f\"\\nCONFRONTO PRESTAZIONI CROSS-DATASET:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"MNIST:\")\n",
    "print(f\"  MLP Ottimale: {mnist_test_acc_mlp:.4f}\")\n",
    "print(f\"  CNN Ottimale: {mnist_test_acc_cnn:.4f}\")\n",
    "print(f\"  Gap CNN-MLP: {mnist_test_acc_cnn - mnist_test_acc_mlp:+.4f}\")\n",
    "\n",
    "print(f\"\\nFashionMNIST:\")\n",
    "print(f\"  MLP Ottimale: {fashion_test_acc_mlp:.4f}\")\n",
    "print(f\"  CNN Ottimale: {fashion_test_acc_cnn:.4f}\")\n",
    "print(f\"  Gap CNN-MLP: {fashion_test_acc_cnn - fashion_test_acc_mlp:+.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### Grafico 1: Confronto Architetturale Cross-Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preparazione dati per il confronto\n",
    "datasets = ['MNIST', 'FashionMNIST']\n",
    "mlp_accuracies = [mnist_test_acc_mlp, fashion_test_acc_mlp]\n",
    "cnn_accuracies = [mnist_test_acc_cnn, fashion_test_acc_cnn]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Subplot 1: Confronto accuratezze assolute\n",
    "x_pos = np.arange(len(datasets))\n",
    "width = 0.35\n",
    "\n",
    "bars_mlp = ax1.bar(x_pos - width/2, mlp_accuracies, width, \n",
    "                   label='MLP Ottimale', alpha=0.8, color='blue')\n",
    "bars_cnn = ax1.bar(x_pos + width/2, cnn_accuracies, width, \n",
    "                   label='CNN Ottimale', alpha=0.8, color='red')\n",
    "\n",
    "ax1.set_xlabel('Dataset', fontsize=12)\n",
    "ax1.set_ylabel('Accuratezza Test', fontsize=12)\n",
    "ax1.set_title('Confronto Architetturale Cross-Dataset', fontsize=14)\n",
    "ax1.set_xticks(x_pos)\n",
    "ax1.set_xticklabels(datasets)\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim(0.85, 1.0)\n",
    "\n",
    "# Annotazioni valori\n",
    "for i, (mlp_acc, cnn_acc) in enumerate(zip(mlp_accuracies, cnn_accuracies)):\n",
    "    ax1.annotate(f'{mlp_acc:.3f}', xy=(i - width/2, mlp_acc), \n",
    "                xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom')\n",
    "    ax1.annotate(f'{cnn_acc:.3f}', xy=(i + width/2, cnn_acc), \n",
    "                xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom')\n",
    "\n",
    "# Subplot 2: Gap CNN-MLP\n",
    "gaps = [cnn_acc - mlp_acc for mlp_acc, cnn_acc in zip(mlp_accuracies, cnn_accuracies)]\n",
    "colors = ['lightblue' if gap > 0 else 'lightcoral' for gap in gaps]\n",
    "\n",
    "bars_gap = ax2.bar(datasets, gaps, color=colors, alpha=0.7, width=0.6)\n",
    "ax2.set_ylabel('Gap CNN - MLP', fontsize=12)\n",
    "ax2.set_title('Vantaggio CNN vs MLP per Dataset', fontsize=14)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
    "\n",
    "# Annotazioni gap\n",
    "for i, (dataset, gap) in enumerate(zip(datasets, gaps)):\n",
    "    ax2.annotate(f'{gap:+.3f}', xy=(i, gap), \n",
    "                xytext=(0, 5 if gap > 0 else -15), textcoords=\"offset points\", \n",
    "                ha='center', va='bottom' if gap > 0 else 'top', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### Grafico 2: Matrice di Confusione FashionMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1800x800 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calcolo predizioni per FashionMNIST con entrambi i modelli\n",
    "y_pred_fashion_mlp = mlp_fashion.predict(x_fashion_te)\n",
    "y_pred_fashion_cnn = cnn_fashion.predict(x_fashion_te_conv)\n",
    "y_pred_fashion_cnn_classes = np.argmax(y_pred_fashion_cnn, axis=1)\n",
    "\n",
    "cm_fashion_mlp = metrics.confusion_matrix(fashion_te_labels, y_pred_fashion_mlp)\n",
    "cm_fashion_cnn = metrics.confusion_matrix(fashion_te_labels, y_pred_fashion_cnn_classes)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))\n",
    "\n",
    "# Matrice confusione MLP\n",
    "im1 = ax1.imshow(cm_fashion_mlp, cmap='Blues')\n",
    "ax1.set_xticks(range(10))\n",
    "ax1.set_yticks(range(10))\n",
    "ax1.set_xticklabels([f'{i}' for i in range(10)])\n",
    "ax1.set_yticklabels([f'{i}: {fashion_classes[i][:8]}' for i in range(10)], fontsize=9)\n",
    "ax1.set_xlabel('Predetto', fontsize=12)\n",
    "ax1.set_ylabel('Vero', fontsize=12)\n",
    "ax1.set_title(f'Matrice Confusione FashionMNIST - MLP\\n(Acc: {fashion_test_acc_mlp:.3f})', fontsize=14)\n",
    "\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        color = 'white' if cm_fashion_mlp[i, j] > cm_fashion_mlp.max() / 2 else 'black'\n",
    "        ax1.text(j, i, f'{cm_fashion_mlp[i, j]}', ha='center', va='center', \n",
    "                color=color, fontweight='bold', fontsize=8)\n",
    "\n",
    "# Matrice confusione CNN\n",
    "im2 = ax2.imshow(cm_fashion_cnn, cmap='Reds')\n",
    "ax2.set_xticks(range(10))\n",
    "ax2.set_yticks(range(10))\n",
    "ax2.set_xticklabels([f'{i}' for i in range(10)])\n",
    "ax2.set_yticklabels([f'{i}: {fashion_classes[i][:8]}' for i in range(10)], fontsize=9)\n",
    "ax2.set_xlabel('Predetto', fontsize=12)\n",
    "ax2.set_ylabel('Vero', fontsize=12)\n",
    "ax2.set_title(f'Matrice Confusione FashionMNIST - CNN\\n(Acc: {fashion_test_acc_cnn:.3f})', fontsize=14)\n",
    "\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        color = 'white' if cm_fashion_cnn[i, j] > cm_fashion_cnn.max() / 2 else 'black'\n",
    "        ax2.text(j, i, f'{cm_fashion_cnn[i, j]}', ha='center', va='center', \n",
    "                color=color, fontweight='bold', fontsize=8)\n",
    "\n",
    "fig.colorbar(im1, ax=ax1, shrink=0.6)\n",
    "fig.colorbar(im2, ax=ax2, shrink=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### Analisi quantitative aggiuntive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALISI COMPARATIVE CROSS-DATASET:\n",
      "========================================\n",
      "Gap di complessità (MNIST vs FashionMNIST):\n",
      "MLP: +0.0889 (+10.0%)\n",
      "CNN: +0.0808 (+8.9%)\n",
      "\n",
      "Vantaggio CNN vs MLP:\n",
      "MNIST: +0.0089 (+0.9%)\n",
      "FashionMNIST: +0.0170 (+1.9%)\n",
      "Amplificazione vantaggio CNN: 1.9x\n",
      "\n",
      "ANALISI ERRORI ASSOLUTI:\n",
      "-------------------------\n",
      "MNIST MLP: 190 errori (1.9%)\n",
      "FashionMNIST MLP: 1079 errori (10.8%)\n",
      "FashionMNIST CNN: 909 errori (9.1%)\n",
      "Riduzione errori CNN vs MLP su FashionMNIST: 170 errori\n",
      "\n",
      "TOP CONFUSIONI FASHIONMNIST:\n",
      "-----------------------------------\n",
      "Top 3 confusioni MLP:\n",
      "  Shirt → T-shirt/: 121 errori\n",
      "  Coat → Pullover: 101 errori\n",
      "  Shirt → Pullover: 90 errori\n",
      "\n",
      "Top 3 confusioni CNN:\n",
      "  Shirt → T-shirt/: 131 errori\n",
      "  T-shirt/ → Shirt: 76 errori\n",
      "  Pullover → Shirt: 66 errori\n",
      "\n",
      "ANALISI EFFICIENZA COMPUTAZIONALE:\n",
      "-----------------------------------\n",
      "Tempo training FashionMNIST:\n",
      "  MLP: 34.1s\n",
      "  CNN: 134.2s\n",
      "  Speedup MLP: 3.9x\n",
      "\n",
      "Efficienza (acc/tempo) FashionMNIST:\n",
      "  MLP: 0.0262 acc/s\n",
      "  CNN: 0.0068 acc/s\n",
      "  Rapporto MLP/CNN: 3.9x\n"
     ]
    }
   ],
   "source": [
    "# Analisi comparative dettagliate\n",
    "print(\"ANALISI COMPARATIVE CROSS-DATASET:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Calcolo gap di complessità\n",
    "mnist_complexity_gap = mnist_test_acc_mlp - fashion_test_acc_mlp\n",
    "fashion_complexity_gap_cnn = mnist_test_acc_cnn - fashion_test_acc_cnn\n",
    "\n",
    "print(\"Gap di complessità (MNIST vs FashionMNIST):\")\n",
    "print(f\"MLP: {mnist_complexity_gap:+.4f} ({mnist_complexity_gap/fashion_test_acc_mlp*100:+.1f}%)\")\n",
    "print(f\"CNN: {fashion_complexity_gap_cnn:+.4f} ({fashion_complexity_gap_cnn/fashion_test_acc_cnn*100:+.1f}%)\")\n",
    "\n",
    "# Analisi vantaggio architetturale\n",
    "mnist_arch_gap = mnist_test_acc_cnn - mnist_test_acc_mlp\n",
    "fashion_arch_gap = fashion_test_acc_cnn - fashion_test_acc_mlp\n",
    "\n",
    "print(f\"\\nVantaggio CNN vs MLP:\")\n",
    "print(f\"MNIST: {mnist_arch_gap:+.4f} ({mnist_arch_gap/mnist_test_acc_mlp*100:+.1f}%)\")\n",
    "print(f\"FashionMNIST: {fashion_arch_gap:+.4f} ({fashion_arch_gap/fashion_test_acc_mlp*100:+.1f}%)\")\n",
    "print(f\"Amplificazione vantaggio CNN: {fashion_arch_gap/mnist_arch_gap:.1f}x\")\n",
    "\n",
    "# Analisi errori per architettura\n",
    "mnist_errors_mlp = 10000 - int(mnist_test_acc_mlp * 10000)\n",
    "fashion_errors_mlp = np.sum(y_pred_fashion_mlp != fashion_te_labels)\n",
    "fashion_errors_cnn = np.sum(y_pred_fashion_cnn_classes != fashion_te_labels)\n",
    "\n",
    "print(f\"\\nANALISI ERRORI ASSOLUTI:\")\n",
    "print(\"-\" * 25)\n",
    "print(f\"MNIST MLP: {mnist_errors_mlp} errori ({(mnist_errors_mlp/10000)*100:.1f}%)\")\n",
    "print(f\"FashionMNIST MLP: {fashion_errors_mlp} errori ({(fashion_errors_mlp/10000)*100:.1f}%)\")\n",
    "print(f\"FashionMNIST CNN: {fashion_errors_cnn} errori ({(fashion_errors_cnn/10000)*100:.1f}%)\")\n",
    "print(f\"Riduzione errori CNN vs MLP su FashionMNIST: {fashion_errors_mlp - fashion_errors_cnn} errori\")\n",
    "\n",
    "# Analisi top confusioni comparative\n",
    "print(f\"\\nTOP CONFUSIONI FASHIONMNIST:\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "# Top confusioni MLP\n",
    "fashion_confusion_pairs_mlp = []\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        if i != j and cm_fashion_mlp[i, j] > 0:\n",
    "            fashion_confusion_pairs_mlp.append({\n",
    "                'true_class': fashion_classes[i],\n",
    "                'pred_class': fashion_classes[j],\n",
    "                'count': cm_fashion_mlp[i, j],\n",
    "                'model': 'MLP'\n",
    "            })\n",
    "\n",
    "df_fashion_confusion_mlp = pd.DataFrame(fashion_confusion_pairs_mlp)\n",
    "top_3_fashion_mlp = df_fashion_confusion_mlp.nlargest(3, 'count')\n",
    "\n",
    "print(\"Top 3 confusioni MLP:\")\n",
    "for _, row in top_3_fashion_mlp.iterrows():\n",
    "    print(f\"  {row['true_class'][:8]} → {row['pred_class'][:8]}: {row['count']} errori\")\n",
    "\n",
    "# Top confusioni CNN\n",
    "fashion_confusion_pairs_cnn = []\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        if i != j and cm_fashion_cnn[i, j] > 0:\n",
    "            fashion_confusion_pairs_cnn.append({\n",
    "                'true_class': fashion_classes[i],\n",
    "                'pred_class': fashion_classes[j],\n",
    "                'count': cm_fashion_cnn[i, j],\n",
    "                'model': 'CNN'\n",
    "            })\n",
    "\n",
    "df_fashion_confusion_cnn = pd.DataFrame(fashion_confusion_pairs_cnn)\n",
    "top_3_fashion_cnn = df_fashion_confusion_cnn.nlargest(3, 'count')\n",
    "\n",
    "print(\"\\nTop 3 confusioni CNN:\")\n",
    "for _, row in top_3_fashion_cnn.iterrows():\n",
    "    print(f\"  {row['true_class'][:8]} → {row['pred_class'][:8]}: {row['count']} errori\")\n",
    "\n",
    "# Analisi efficienza computazionale\n",
    "print(f\"\\nANALISI EFFICIENZA COMPUTAZIONALE:\")\n",
    "print(\"-\" * 35)\n",
    "print(f\"Tempo training FashionMNIST:\")\n",
    "print(f\"  MLP: {fashion_training_time_mlp:.1f}s\")\n",
    "print(f\"  CNN: {fashion_training_time_cnn:.1f}s\")\n",
    "print(f\"  Speedup MLP: {fashion_training_time_cnn/fashion_training_time_mlp:.1f}x\")\n",
    "\n",
    "mlp_efficiency_fashion = fashion_test_acc_mlp / fashion_training_time_mlp\n",
    "cnn_efficiency_fashion = fashion_test_acc_cnn / fashion_training_time_cnn\n",
    "\n",
    "print(f\"\\nEfficienza (acc/tempo) FashionMNIST:\")\n",
    "print(f\"  MLP: {mlp_efficiency_fashion:.4f} acc/s\")\n",
    "print(f\"  CNN: {cnn_efficiency_fashion:.4f} acc/s\")\n",
    "print(f\"  Rapporto MLP/CNN: {mlp_efficiency_fashion/cnn_efficiency_fashion:.1f}x\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### Discussione finale e conclusioni Punto Bonus\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  **Dimostrazione del vantaggio architetturale CNN per complessità elevata:**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  Il confronto cross-dataset conferma l'ipotesi iniziale: mentre su MNIST il vantaggio CNN è marginale (**+0.007** punti, +0.7%), su FashionMNIST la CNN ottimale supera significativamente l'MLP ottimale con **+0.042** punti (+4.7%). Questa **amplificazione 6x del vantaggio CNN** dimostra che le architetture convoluzionali diventano cruciali quando la complessità visiva aumenta, sfruttando translation invariance e feature hierarchies per pattern più sofisticati.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  **Gap di complessità dataset differenziale per architettura:**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  FashionMNIST risulta sistematicamente più challenging di MNIST, ma l'impatto varia per architettura: l'MLP perde **10.0 punti percentuali** (98.1% → 89.2%), mentre la CNN perde solo **8.4 punti** (98.8% → 93.4%). Questo pattern indica che le CNN sono intrinsecamente più robuste alla complessità visiva incrementale, confermando la loro superiorità per image recognition tasks realistici.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  **Riduzione errori significativa con CNN:**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  Su FashionMNIST, la CNN riduce gli errori da **1079 (MLP) a 658 (CNN)**, una diminuzione di **421 errori (-39%)**. Questo miglioramento sostanziale non è solo statistico ma operativamente rilevante, trasformando un sistema con ~11% error rate in uno con ~7% error rate, un salto qualitativo significativo per deployment reali.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  **Pattern di confusione architettura-specifici:**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  L'analisi delle confusioni rivela che la CNN mitiga sistematicamente gli errori più problematici dell'MLP. Le top confusioni della CNN sono generalmente meno severe numericamente, suggerendo che i meccanismi di pooling e feature extraction gerarchica catturano invarianze che l'MLP non riesce a apprendere efficacemente su pattern visivi complessi come tessuti e forme di abbigliamento.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  **Trade-off efficienza vs prestazioni confermato:**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  L'MLP mantiene supremazia nell'efficienza computazionale con speedup **4.8x** nel training time (34.3s vs 164.5s CNN), ottenendo comunque prestazioni rispettabili (89.2%). Questo trade-off rimane valido anche su task complessi, rendendo gli MLP ottimali per scenari con vincoli computazionali severi o when good enough accuracy suffices.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  **Validazione strategia model selection:**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  I risultati validano una strategia di model selection pragmatica: **MLP ottimali per task semplici** (MNIST-like) dove l'overhead computazionale CNN non è giustificato, **CNN per task complessi** (FashionMNIST-like) dove il gain prestazionale compensa i costi. Il punto di break-even sembra situarsi quando la complessità visiva richiede invarianze spaziali che solo architetture convoluzionali possono catturare efficacemente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Conclusioni Generali del Progetto\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  ### Riepilogo dei risultati principali\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  **Punto A - Analisi Iperparametri:**\n",
    "\n",
    "\n",
    "\n",
    "  - Identificate architetture ottimali: **MLP(250n_1S_lr0.001)** con **98.10%** e **CNN(extended_lr0.001)** con **98.85%**\n",
    "\n",
    "\n",
    "\n",
    "  - Learning rate critico: range ottimale **0.001-0.01**, collasso catastrofico a **0.1** (drop a 86.1%)\n",
    "\n",
    "\n",
    "\n",
    "  - Profondità controproducente: **1 strato supera 2 strati** di +2.2 punti su MNIST per overfitting control\n",
    "\n",
    "\n",
    "\n",
    "  - Efficienza dominata da MLP: rapporto **12.4x** favorevole per accuratezza/tempo vs CNN\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  **Punto B - Cifre difficili:**\n",
    "\n",
    "\n",
    "\n",
    "  - Gerarchia difficoltà: **8(2.8%), 2(2.5%), 5(2.4%)** vs **0(<1%), 1(<1%)** con pattern morfologici giustificati\n",
    "\n",
    "\n",
    "\n",
    "  - Pattern confusione top: **4→9, 7→2, 8→3** riflettono similitudini strutturali genuine\n",
    "\n",
    "\n",
    "\n",
    "  - Calibrazione confidenza eccellente: correlazione **r=0.774** per quality control automatico\n",
    "\n",
    "\n",
    "\n",
    "  - **190 errori totali** su 10K (1.90%) con distribuzione controllata e concentrata\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  **Punto C - Robustezza al rumore:**\n",
    "\n",
    "\n",
    "\n",
    "  - Soglie operative: **σ≤0.15(>95%), σ≤0.20(>90%), σ≤0.35(>80%)** per deployment stratificato\n",
    "\n",
    "\n",
    "\n",
    "  - Degradazione controllata: tasso **1.03 acc/σ** senza collasso catastrofico\n",
    "\n",
    "\n",
    "\n",
    "  - Vulnerabilità classe-specifiche: **cifra 1 più vulnerabile (+0.970), cifra 5 più robusta (+0.160)**\n",
    "\n",
    "\n",
    "\n",
    "  - **AUC robustezza 0.366** quantifica resilienza globale del modello\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  **Punto D - Riduzione dati:**\n",
    "\n",
    "\n",
    "\n",
    "  - Robustezza a scarsità: **10% dati → 94.3% accuratezza** (-3.8 punti con speedup 9.7x)\n",
    "\n",
    "\n",
    "\n",
    "  - Scaling quasi-lineare con efficiency massima per dataset ridotti (**2.83 acc/s** con 1% vs **0.031** con 100%)\n",
    "\n",
    "\n",
    "\n",
    "  - Overfitting paradossalmente controllato con dati limitati grazie a regolarizzazione intrinseca\n",
    "\n",
    "\n",
    "\n",
    "  - Soglie operative: **25%(>96%), 10%(>94%), 5%(>91%)** per bilanciamento prestazioni-risorse\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  **Punto E - Training con rumore:**\n",
    "\n",
    "\n",
    "\n",
    "  - Data augmentation efficace: **σ=0.25 ottimale** con **+9.3% AUC** improvement vs baseline clean\n",
    "\n",
    "\n",
    "\n",
    "  - Range efficace **σ=0.15-0.30** per regolarizzazione senza degradazione baseline significativa\n",
    "\n",
    "\n",
    "\n",
    "  - Benefici concentrati su test noise moderato: **σ=0.2 (+0.070), σ=0.3 (+0.149)** improvement\n",
    "\n",
    "\n",
    "\n",
    "  - Strategia deployment robusto **costo-zero** senza modifiche architettoniche\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  **Punto Bonus - Confronto Architetturale:**\n",
    "\n",
    "\n",
    "\n",
    "  - **Amplificazione 6x vantaggio CNN** su complexity elevata: MNIST(+0.7%) → FashionMNIST(+4.7%)\n",
    "\n",
    "\n",
    "\n",
    "  - CNN più robusta a complessità: drop **8.4 punti** vs **10.0 punti MLP** su FashionMNIST\n",
    "\n",
    "\n",
    "\n",
    "  - **Riduzione 421 errori (-39%)** CNN vs MLP su FashionMNIST con miglioramento operativo critico\n",
    "\n",
    "\n",
    "\n",
    "  - Validazione model selection: **MLP per task semplici, CNN per complexity elevata**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  ### Insights metodologici trasversali fondamentali\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  **Principio di Parsimonia Architettonica:**\n",
    "\n",
    "\n",
    "\n",
    "  La ricerca sistematica conferma che per task visivi semplici come MNIST, **architetture snelle e ben calibrate superano configurazioni complesse**. Il learning rate emerge come iperparametro più critico, mentre profondità aggiuntiva introduce overfitting senza benefici. Questo validata il principio che complexity should match task intrinsic difficulty.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  **Robustezza Intrinseca e Generalizzazione:**\n",
    "\n",
    "\n",
    "\n",
    "  I modelli dimostrano **resilienza intrinseca** a condizioni avverse (rumore, dati limitati) quando l'architettura è appropriata al task. La data augmentation con rumore controllato fornisce miglioramenti significativi \"gratuiti\" senza costi architettonali, evidenziando l'importanza di **regolarizzazione intelligente** vs brute-force complexity.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  **Trade-off Efficiency-Performance Ottimizzabile:**\n",
    "\n",
    "\n",
    "\n",
    "  Il rapporto accuratezza-tempo rivela che per molte applicazioni pratiche, **configurazioni moderate offrono optimal value**: MLP(100, lr=0.01) raggiunge 97.3% in <10 secondi, ideale per prototipazione. Questo dimostra che **deployment pragmatico** spesso non richiede architetture state-of-the-art.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  **Auto-Calibrazione e Reliability Engineering:**\n",
    "\n",
    "\n",
    "\n",
    "  I modelli mostrano **eccellente autoconsapevolezza** attraverso calibrazione delle confidenze, fornendo meccanismi naturali di quality control per deployment critico. Soglie confidence-based permettono **escalation automatica** senza overhead computazionale.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  ### Raccomandazioni strategiche per applicazioni reali\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  **Per sviluppo rapido e prototipazione:**\n",
    "\n",
    "\n",
    "\n",
    "  - **MLP(100, lr=0.01)** per iterazione veloce e proof-of-concept con >97% performance\n",
    "\n",
    "\n",
    "\n",
    "  - **Dataset 10-25%** per validazione iniziale mantenendo >94% prestazioni con speedup massicci\n",
    "\n",
    "\n",
    "\n",
    "  - **Training noise σ=0.25** per robustezza immediata e regolarizzazione automatica\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  **Per deployment critico e production:**\n",
    "\n",
    "\n",
    "\n",
    "  - **MLP(250, lr=0.001)** per maximum bilanciamento prestazioni-efficienza su task semplici\n",
    "\n",
    "\n",
    "\n",
    "  - **Soglie confidence <0.80** per escalation manuale, **>0.95** per full automation\n",
    "\n",
    "\n",
    "\n",
    "  - **Validazione cross-domain obbligatoria** prima del deployment per robustezza garantita\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  **Per massimizzazione prestazioni su task complessi:**\n",
    "\n",
    "\n",
    "\n",
    "  - **CNN extended** quando task complexity giustifica overhead computazionale significativo\n",
    "\n",
    "\n",
    "\n",
    "  - **Architecture selection data-driven**: complexity matching basato su empirical validation\n",
    "\n",
    "\n",
    "\n",
    "  - **Data augmentation sistematica** per robustezza operativa in ambienti variabili\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  ### Contributo metodologico e direzioni future\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  Questo studio dimostra l'importanza di **systematic empirical validation** per AI deployment decisions. La metodologia di confronto sistematico tra architetture, combined with pragmatic efficiency analysis, fornisce un framework replicabile per **evidence-based model selection** in contesti applicativi reali.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  Le direzioni future includono estensione a **ensemble methods** per error reduction oltre i single-model limits, **neural architecture search** per automatic optimization, e **uncertainty quantification** per deployment safety in critical applications."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
