{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d77f4b15",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Mini Progetto Intelligenza Artificiale - Riconoscimento cifre manoscritte\n",
    "\n",
    "**Nome:** Giulio    \n",
    "**Cognome:** Bottacin    \n",
    "**Matricola:** 2042340    \n",
    "**Data consegna:** 5/6/2025  \n",
    "\n",
    "## Obiettivo\n",
    "\n",
    "In questo progetto esploreremo il riconoscimento di cifre manoscritte utilizzando il dataset MNIST, implementando simulazioni per studiare come diversi fattori influenzano le prestazioni dei modelli di deep learning. Analizzeremo in particolare l'impatto degli iperparametri, la robustezza al rumore e l'effetto della quantità di dati di training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44abb844",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Importazione delle librerie necessarie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe329e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from torchvision.datasets import MNIST, FashionMNIST\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurazione per riproducibilità\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dae275",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Caricamento e preparazione del dataset MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175256c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricamento dataset MNIST...\n"
     ]
    }
   ],
   "source": [
    "# Caricamento dataset MNIST\n",
    "print(\"Caricamento dataset MNIST...\")\n",
    "mnist_tr = MNIST(root=\"./data\", train=True, download=True)\n",
    "mnist_te = MNIST(root=\"./data\", train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0cae14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversione in array numpy\n",
    "mnist_tr_data, mnist_tr_labels = mnist_tr.data.numpy(), mnist_tr.targets.numpy()\n",
    "mnist_te_data, mnist_te_labels = mnist_te.data.numpy(), mnist_te.targets.numpy()\n",
    "\n",
    "# Preprocessing per MLP (vettorizzazione e normalizzazione)\n",
    "x_tr = mnist_tr_data.reshape(60000, 28 * 28) / 255.0\n",
    "x_te = mnist_te_data.reshape(10000, 28 * 28) / 255.0\n",
    "\n",
    "# Preprocessing per CNN (mantenendo formato 2D)\n",
    "x_tr_conv = x_tr.reshape(-1, 28, 28, 1)\n",
    "x_te_conv = x_te.reshape(-1, 28, 28, 1)\n",
    "\n",
    "print(f\"Dataset caricato: {x_tr.shape[0]} esempi di training, {x_te.shape[0]} esempi di test\")\n",
    "print(f\"Forma dati MLP: {x_tr.shape}\")\n",
    "print(f\"Forma dati CNN: {x_tr_conv.shape}\")\n",
    "\n",
    "# Visualizzazione esempi del dataset\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 6))\n",
    "fig.suptitle('Dataset MNIST - Esempi per Cifra', fontsize=14)\n",
    "\n",
    "for digit in range(10):\n",
    "    idx = np.where(mnist_tr_labels == digit)[0][0]\n",
    "    ax = axes[digit//5, digit%5]\n",
    "    ax.imshow(mnist_tr_data[idx], cmap='gray')\n",
    "    ax.set_title(f'Cifra {digit}')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5242b1b3",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Punto A: Effetto degli iperparametri sulle prestazioni\n",
    "\n",
    "Analizziamo sistematicamente come variano le prestazioni dei modelli MLP e CNN al variare degli iperparametri chiave.  \n",
    "Confronteremo 18 configurazioni MLP e 6 configurazioni CNN per un totale di 24 esperimenti mirati."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7af60f",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 1
   },
   "source": [
    "### Configurazione esperimenti sistematici\n",
    "\n",
    "***MLP (18 esperimenti):***\n",
    "- **Neuroni per strato**: *50, 100, 250* per testare la copertura da reti piccole a medio-grandi\n",
    "- **Numero layers**: *1 vs 2* strati nascosti per fare il confronto profondità vs larghezza\n",
    "- **Learning rate**: *0.001, 0.01, 0.1*\n",
    "\n",
    "***CNN (6 esperimenti):***\n",
    "- **Filtri**: *32*, standard per MNIST, computazionalmente efficiente\n",
    "- **Architettura**: *baseline vs extended* per fare il confronto sulla complessità\n",
    "- **Learning rate**: *0.001, 0.01, 0.1*\n",
    "\n",
    "Per entrambi i modelli si è scelto di utilizzare il solver **Adam**, ormai standard e più performante di SDG.  \n",
    "Si è volutamente scelto di eseguire meno esperimenti sulle CNN in quanto richiedono tempi molto più lunghi di training rispetto alle MLP.\n",
    "\n",
    "#### Scelta dei parametri di training\n",
    "\n",
    "***MLP:***\n",
    "- *max_iter = 100* è sufficiente per convergenza su MNIST basato su cifre manoscritte. \n",
    "- *early_stopping = True*, previene l'overfitting essenziale quando sono presenti molti parametri.\n",
    "- *validation_fraction = 0.1*, split standard 90/10.\n",
    "- *tol = 0.001* è una precisione ragionevole per classificazione.\n",
    "- *n_iter_no_change = 10* è un livello di pazienza adeguata per permettere oscillazioni temporanee.\n",
    "\n",
    "***CNN:*** \n",
    "- *epochs = 20* valore di compromesso per bilanciare velocità e convergenza, il valore è più basso delle MLP perchè le CNN tipicamente convergono più velocemente.\n",
    "- *batch_size = 128*, trade-off memoria/velocità ottimale per dataset size.\n",
    "- *validation_split = 0.1*, coerente con le scelte di MLP.\n",
    "- *patience = 5*, le CNN sono meno soggette a oscillazioni quindi è stato scelto un livello di pazienza minore.\n",
    "- *min_delta = 0.001*, scelta la stessa precisione degli MLP per comparabilità diretta.\n",
    "\n",
    "Questa configurazione permette un confronto sistematico e bilanciato tra i due tipi di architetture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dc0d98",
   "metadata": {},
   "source": [
    "#### Funzioni helper per stampe risultati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924122e4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def stampa_header_esperimento(num_esp, totale, tipo_modello, config):\n",
    "    print(f\"\\n[{num_esp:2d}/{totale}] {tipo_modello}: {config}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "def stampa_risultati_esperimento(risultati):\n",
    "    print(f\"Accuracy Training: {risultati['train_accuracy']:.4f} | Accuracy Test: {risultati['test_accuracy']:.4f}\")\n",
    "    print(f\"Tempo: {risultati['training_time']:6.1f}s | Iterazioni: {risultati['iterations']:3d}\")\n",
    "    print(f\"Overfitting: {risultati['overfitting']:+.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37445b1",
   "metadata": {},
   "source": [
    "#### Esperimenti MLP (16 configurazioni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84403193",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INIZIO ESPERIMENTI MLP\n",
      "============================================================\n",
      "\n",
      "[ 1/18] MLP: 50n_1S_lr0.001\n",
      "--------------------------------------------------\n",
      "Acc Training: 0.9891 | Acc Test: 0.9707\n",
      "Tempo:    9.0s | Iterazioni:  24\n",
      "Overfitting: +0.0184\n",
      "\n",
      "[ 2/18] MLP: 50n_1S_lr0.01\n",
      "--------------------------------------------------\n",
      "Acc Training: 0.9844 | Acc Test: 0.9697\n",
      "Tempo:    5.2s | Iterazioni:  17\n",
      "Overfitting: +0.0147\n",
      "\n",
      "[ 3/18] MLP: 50n_1S_lr0.1\n",
      "--------------------------------------------------\n",
      "Acc Training: 0.9202 | Acc Test: 0.9123\n",
      "Tempo:    5.8s | Iterazioni:  20\n",
      "Overfitting: +0.0079\n",
      "\n",
      "[ 4/18] MLP: 50n_2S_lr0.001\n",
      "--------------------------------------------------\n",
      "Acc Training: 0.9905 | Acc Test: 0.9729\n",
      "Tempo:    9.4s | Iterazioni:  27\n",
      "Overfitting: +0.0176\n",
      "\n",
      "[ 5/18] MLP: 50n_2S_lr0.01\n",
      "--------------------------------------------------\n",
      "Acc Training: 0.9863 | Acc Test: 0.9695\n",
      "Tempo:    6.3s | Iterazioni:  19\n",
      "Overfitting: +0.0168\n",
      "\n",
      "[ 6/18] MLP: 50n_2S_lr0.1\n",
      "--------------------------------------------------\n",
      "Acc Training: 0.8471 | Acc Test: 0.8467\n",
      "Tempo:    5.5s | Iterazioni:  16\n",
      "Overfitting: +0.0004\n",
      "\n",
      "[ 7/18] MLP: 100n_1S_lr0.001\n",
      "--------------------------------------------------\n",
      "Acc Training: 0.9971 | Acc Test: 0.9771\n",
      "Tempo:   13.3s | Iterazioni:  26\n",
      "Overfitting: +0.0201\n",
      "\n",
      "[ 8/18] MLP: 100n_1S_lr0.01\n",
      "--------------------------------------------------\n",
      "Acc Training: 0.9909 | Acc Test: 0.9734\n",
      "Tempo:   10.0s | Iterazioni:  19\n",
      "Overfitting: +0.0175\n",
      "\n",
      "[ 9/18] MLP: 100n_1S_lr0.1\n",
      "--------------------------------------------------\n",
      "Acc Training: 0.9168 | Acc Test: 0.9148\n",
      "Tempo:    5.8s | Iterazioni:  13\n",
      "Overfitting: +0.0020\n",
      "\n",
      "[10/18] MLP: 100n_2S_lr0.001\n",
      "--------------------------------------------------\n",
      "Acc Training: 0.9967 | Acc Test: 0.9786\n",
      "Tempo:   11.3s | Iterazioni:  20\n",
      "Overfitting: +0.0181\n",
      "\n",
      "[11/18] MLP: 100n_2S_lr0.01\n",
      "--------------------------------------------------\n",
      "Acc Training: 0.9934 | Acc Test: 0.9739\n",
      "Tempo:   24.0s | Iterazioni:  43\n",
      "Overfitting: +0.0195\n",
      "\n",
      "[12/18] MLP: 100n_2S_lr0.1\n",
      "--------------------------------------------------\n",
      "Acc Training: 0.8248 | Acc Test: 0.8212\n",
      "Tempo:    7.8s | Iterazioni:  14\n",
      "Overfitting: +0.0036\n",
      "\n",
      "[13/18] MLP: 250n_1S_lr0.001\n",
      "--------------------------------------------------\n",
      "Acc Training: 0.9981 | Acc Test: 0.9810\n",
      "Tempo:   26.3s | Iterazioni:  24\n",
      "Overfitting: +0.0171\n",
      "\n",
      "[14/18] MLP: 250n_1S_lr0.01\n",
      "--------------------------------------------------\n",
      "Acc Training: 0.9913 | Acc Test: 0.9752\n",
      "Tempo:   25.1s | Iterazioni:  25\n",
      "Overfitting: +0.0161\n",
      "\n",
      "[15/18] MLP: 250n_1S_lr0.1\n",
      "--------------------------------------------------\n",
      "Acc Training: 0.9160 | Acc Test: 0.9147\n",
      "Tempo:   15.4s | Iterazioni:  15\n",
      "Overfitting: +0.0013\n",
      "\n",
      "[16/18] MLP: 250n_2S_lr0.001\n",
      "--------------------------------------------------\n",
      "Acc Training: 0.9965 | Acc Test: 0.9788\n",
      "Tempo:   30.2s | Iterazioni:  19\n",
      "Overfitting: +0.0177\n",
      "\n",
      "[17/18] MLP: 250n_2S_lr0.01\n",
      "--------------------------------------------------\n",
      "Acc Training: 0.9924 | Acc Test: 0.9776\n",
      "Tempo:   49.0s | Iterazioni:  31\n",
      "Overfitting: +0.0148\n",
      "\n",
      "[18/18] MLP: 250n_2S_lr0.1\n",
      "--------------------------------------------------\n",
      "Acc Training: 0.7662 | Acc Test: 0.7577\n",
      "Tempo:   41.1s | Iterazioni:  27\n",
      "Overfitting: +0.0085\n",
      "\n",
      "ESPERIMENTI MLP COMPLETATI: 18 configurazioni testate\n"
     ]
    }
   ],
   "source": [
    "neuroni_lista = [50, 100, 250] # numero di neuroni per strato\n",
    "strati_lista = [1, 2]  # numero di strati nascosti\n",
    "learning_rates = [0.001, 0.01, 0.1] # learning rates \n",
    "\n",
    "risultati_mlp = []\n",
    "contatore_esperimenti = 0\n",
    "esperimenti_totali = len(neuroni_lista) * len(strati_lista) * len(learning_rates)\n",
    "\n",
    "print(\"INIZIO ESPERIMENTI MLP\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for neuroni in neuroni_lista:\n",
    "    for n_strati in strati_lista:\n",
    "        for lr in learning_rates:\n",
    "            contatore_esperimenti += 1\n",
    "            \n",
    "            # Configurazione architettura\n",
    "            if n_strati == 1:\n",
    "                strati_nascosti = (neuroni,)\n",
    "                nome_config = f\"{neuroni}n_1S_lr{lr}\"\n",
    "            else:\n",
    "                strati_nascosti = (neuroni, neuroni)\n",
    "                nome_config = f\"{neuroni}n_2S_lr{lr}\"\n",
    "            \n",
    "            stampa_header_esperimento(contatore_esperimenti, esperimenti_totali, \"MLP\", nome_config)\n",
    "            \n",
    "            # Training MLP\n",
    "            mlp = MLPClassifier(\n",
    "                hidden_layer_sizes=strati_nascosti,\n",
    "                learning_rate_init=lr,\n",
    "                max_iter=100,\n",
    "                early_stopping=True,\n",
    "                validation_fraction=0.1,\n",
    "                tol=0.001,\n",
    "                n_iter_no_change=10,\n",
    "                random_state=42\n",
    "            )\n",
    "            \n",
    "            tempo_inizio = time.time()\n",
    "            mlp.fit(x_tr, mnist_tr_labels)\n",
    "            tempo_training = time.time() - tempo_inizio\n",
    "            \n",
    "            acc_train = mlp.score(x_tr, mnist_tr_labels)\n",
    "            acc_test = mlp.score(x_te, mnist_te_labels)\n",
    "            \n",
    "            risultati = {\n",
    "                'tipo_modello': 'MLP',\n",
    "                'nome_config': nome_config,\n",
    "                'neuroni': neuroni,\n",
    "                'n_strati': n_strati,\n",
    "                'learning_rate': lr,\n",
    "                'strati_nascosti': strati_nascosti,\n",
    "                'train_accuracy': acc_train,\n",
    "                'test_accuracy': acc_test,\n",
    "                'overfitting': acc_train - acc_test,\n",
    "                'training_time': tempo_training,\n",
    "                'iterations': mlp.n_iter_,\n",
    "                'loss_curve': mlp.loss_curve_ if hasattr(mlp, 'loss_curve_') else [],\n",
    "                'parametri_totali': sum([layer.size for layer in mlp.coefs_]) + sum([layer.size for layer in mlp.intercepts_])\n",
    "            }\n",
    "            \n",
    "            risultati_mlp.append(risultati)\n",
    "            stampa_risultati_esperimento(risultati)\n",
    "\n",
    "print(f\"\\nESPERIMENTI MLP COMPLETATI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebb1437",
   "metadata": {},
   "source": [
    "#### Funzioni helper per esperimenti CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7f9a89",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def crea_modello_cnn(tipo_architettura, learning_rate):\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    if tipo_architettura == 'baseline':\n",
    "        # Architettura baseline\n",
    "        model.add(keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)))\n",
    "        model.add(keras.layers.Flatten())\n",
    "        model.add(keras.layers.Dense(50, activation='relu'))\n",
    "        \n",
    "    elif tipo_architettura == 'extended':\n",
    "        # Architettura estesa con pooling e più strati\n",
    "        model.add(keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)))\n",
    "        model.add(keras.layers.MaxPooling2D(2,2))\n",
    "        model.add(keras.layers.Conv2D(64, (3,3), activation='relu'))\n",
    "        model.add(keras.layers.Flatten())\n",
    "        model.add(keras.layers.Dense(100, activation='relu'))\n",
    "    \n",
    "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "    \n",
    "    # Configurazione optimizer\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e02fe32",
   "metadata": {},
   "source": [
    "#### Esperimenti CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b325f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "INIZIO ESPERIMENTI CNN\n",
      "============================================================\n",
      "\n",
      "[ 1/6] CNN: CNN_baseline_lr0.001\n",
      "--------------------------------------------------\n",
      "Acc Training: 0.9914 | Acc Test: 0.9805\n",
      "Tempo:   68.4s | Iterazioni:   8\n",
      "Overfitting: +0.0109\n",
      "\n",
      "[ 2/6] CNN: CNN_baseline_lr0.01\n",
      "--------------------------------------------------\n",
      "Acc Training: 0.9890 | Acc Test: 0.9765\n",
      "Tempo:   61.4s | Iterazioni:   7\n",
      "Overfitting: +0.0125\n",
      "\n",
      "[ 3/6] CNN: CNN_baseline_lr0.1\n",
      "--------------------------------------------------\n",
      "Acc Training: 0.1022 | Acc Test: 0.1010\n",
      "Tempo:   55.1s | Iterazioni:   6\n",
      "Overfitting: +0.0012\n",
      "\n",
      "[ 4/6] CNN: CNN_extended_lr0.001\n",
      "--------------------------------------------------\n",
      "Acc Training: 0.9920 | Acc Test: 0.9893\n",
      "Tempo:  107.7s | Iterazioni:   7\n",
      "Overfitting: +0.0027\n",
      "\n",
      "[ 5/6] CNN: CNN_extended_lr0.01\n",
      "--------------------------------------------------\n",
      "Acc Training: 0.9876 | Acc Test: 0.9804\n",
      "Tempo:  108.9s | Iterazioni:   7\n",
      "Overfitting: +0.0072\n",
      "\n",
      "[ 6/6] CNN: CNN_extended_lr0.1\n",
      "--------------------------------------------------\n",
      "Acc Training: 0.1022 | Acc Test: 0.1010\n",
      "Tempo:   98.8s | Iterazioni:   6\n",
      "Overfitting: +0.0012\n",
      "\n",
      "ESPERIMENTI CNN COMPLETATI: 6 configurazioni testate\n"
     ]
    }
   ],
   "source": [
    "architetture = ['baseline', 'extended']\n",
    "learning_rates_cnn = [0.001, 0.01, 0.1]\n",
    "\n",
    "risultati_cnn = []\n",
    "contatore_esperimenti_cnn = 0\n",
    "esperimenti_totali_cnn = len(architetture) * len(learning_rates_cnn)\n",
    "\n",
    "print(\"\\n\\nINIZIO ESPERIMENTI CNN\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for arch in architetture:\n",
    "    for lr in learning_rates_cnn:\n",
    "        contatore_esperimenti_cnn += 1\n",
    "        nome_config = f\"CNN_{arch}_lr{lr}\"\n",
    "        \n",
    "        stampa_header_esperimento(contatore_esperimenti_cnn, esperimenti_totali_cnn, \"CNN\", nome_config)\n",
    "        \n",
    "        # Creazione e training CNN\n",
    "        model = crea_modello_cnn(arch, lr)\n",
    "        \n",
    "        # Early stopping callback\n",
    "        early_stopping = keras.callbacks.EarlyStopping(\n",
    "            patience=5,\n",
    "            min_delta=0.001,\n",
    "            restore_best_weights=True,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        tempo_inizio = time.time()\n",
    "        history = model.fit(\n",
    "            x_tr_conv, mnist_tr_labels,\n",
    "            validation_split=0.1,\n",
    "            epochs=20,\n",
    "            batch_size=128,\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=0\n",
    "        )\n",
    "        tempo_training = time.time() - tempo_inizio\n",
    "        \n",
    "        # Valutazione\n",
    "        train_loss, acc_train = model.evaluate(x_tr_conv, mnist_tr_labels, verbose=0)\n",
    "        test_loss, acc_test = model.evaluate(x_te_conv, mnist_te_labels, verbose=0)\n",
    "        \n",
    "        risultati = {\n",
    "            'tipo_modello': 'CNN',\n",
    "            'nome_config': nome_config,\n",
    "            'architettura': arch,\n",
    "            'learning_rate': lr,\n",
    "            'train_accuracy': acc_train,\n",
    "            'test_accuracy': acc_test,\n",
    "            'overfitting': acc_train - acc_test,\n",
    "            'training_time': tempo_training,\n",
    "            'iterations': len(history.history['loss']),\n",
    "            'loss_curve': history.history['loss'],\n",
    "            'val_loss_curve': history.history['val_loss'],\n",
    "            'parametri_totali': model.count_params()\n",
    "        }\n",
    "        \n",
    "        risultati_cnn.append(risultati)\n",
    "        stampa_risultati_esperimento(risultati)\n",
    "\n",
    "print(f\"\\nESPERIMENTI CNN COMPLETATI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82de5349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinazione risultati per analisi\n",
    "tutti_risultati = risultati_mlp + risultati_cnn\n",
    "df_risultati = pd.DataFrame(tutti_risultati)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad25ef4c",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "### Grafico 1: Effetto del Learning Rate sulle prestazioni MLP\n",
    "\n",
    "Questo grafico analizza l'impatto critico del learning rate sulla convergenza e stabilità del training per le reti MLP. Il learning rate controlla la dimensione dei passi durante l'ottimizzazione: valori troppo alti causano instabilità e divergenza, mentre valori troppo bassi rallentano eccessivamente la convergenza. L'analisi delle curve di loss e delle accuratezze finali permette di identificare il range ottimale per il dataset MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b30d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparazione dati per analisi learning rate\n",
    "dati_lr_001 = [r for r in risultati_mlp if r['learning_rate'] == 0.001]\n",
    "dati_lr_01 = [r for r in risultati_mlp if r['learning_rate'] == 0.01]\n",
    "dati_lr_1 = [r for r in risultati_mlp if r['learning_rate'] == 0.1]\n",
    "\n",
    "# Calcolo medie per ogni learning rate\n",
    "acc_lr_001 = np.mean([r['test_accuracy'] for r in dati_lr_001])\n",
    "acc_lr_01 = np.mean([r['test_accuracy'] for r in dati_lr_01])\n",
    "acc_lr_1 = np.mean([r['test_accuracy'] for r in dati_lr_1])\n",
    "\n",
    "tempo_lr_001 = np.mean([r['training_time'] for r in dati_lr_001])\n",
    "tempo_lr_01 = np.mean([r['training_time'] for r in dati_lr_01])\n",
    "tempo_lr_1 = np.mean([r['training_time'] for r in dati_lr_1])\n",
    "\n",
    "# Visualizzazione curve di loss rappresentative\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Subplot 1: Curve di loss\n",
    "for i, (dati_lr, colore, etichetta) in enumerate([(dati_lr_001, 'green', 'LR=0.001'), \n",
    "                                           (dati_lr_01, 'blue', 'LR=0.01'), \n",
    "                                           (dati_lr_1, 'red', 'LR=0.1')]):\n",
    "    if dati_lr and dati_lr[0]['loss_curve']:\n",
    "        curva_loss = dati_lr[0]['loss_curve']  # Primo esempio rappresentativo\n",
    "        ax1.plot(range(len(curva_loss)), curva_loss, color=colore, linewidth=2, label=etichetta)\n",
    "\n",
    "ax1.set_xlabel('Iterazioni')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Pattern di Convergenza per Learning Rate')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Subplot 2: Accuratezza vs Learning Rate\n",
    "learning_rates_plot = [0.001, 0.01, 0.1]\n",
    "accuratezze = [acc_lr_001, acc_lr_01, acc_lr_1]\n",
    "colori = ['green', 'blue', 'red']\n",
    "\n",
    "bars = ax2.bar(range(len(learning_rates_plot)), accuratezze, color=colori, alpha=0.7)\n",
    "ax2.set_xlabel('Learning Rate')\n",
    "ax2.set_ylabel('Accuratezza Test Media')\n",
    "ax2.set_title('Accuratezza Test per Learning Rate')\n",
    "ax2.set_xticks(range(len(learning_rates_plot)))\n",
    "ax2.set_xticklabels(['0.001', '0.01', '0.1'])\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Annotazioni valori\n",
    "for bar, acc in zip(bars, accuratezze):\n",
    "    height = bar.get_height()\n",
    "    ax2.annotate(f'{acc:.3f}', xy=(bar.get_x() + bar.get_width()/2, height),\n",
    "                xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"DATI ANALISI LEARNING RATE:\")\n",
    "print(f\"LR=0.001: Accuratezza={acc_lr_001:.4f}, Tempo={tempo_lr_001:.1f}s\")\n",
    "print(f\"LR=0.01:  Accuratezza={acc_lr_01:.4f}, Tempo={tempo_lr_01:.1f}s\") \n",
    "print(f\"LR=0.1:   Accuratezza={acc_lr_1:.4f}, Tempo={tempo_lr_1:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6743384a",
   "metadata": {},
   "source": [
    "#### Discussione del grafico e riflessione sui risultati\n",
    "I risultati mostrano chiaramente l'effetto critico del learning rate sulle prestazioni: \n",
    "- **LR = 0.001** raggiunge la migliore accuratezza media (97.65%) con convergenza stabile ma lenta\n",
    "- **LR = 0.01** mantiene prestazioni competitive (97.32%) con convergenza più rapida rappresentando il miglior compromesso velocità-accuratezza\n",
    "- **LR = 0.1** causa un drammatico crollo delle prestazioni (86.12%) indicando instabilità nell'ottimizzazione e possibili oscillazioni eccessive. \n",
    "\n",
    "Dal punto di vista tecnico, learning rate alti causano passi troppo grandi che fanno \"saltare\" oltre i minimi locali, mentre valori troppo bassi intrappolano l'ottimizzazione in plateau prolungati. \n",
    "\n",
    "Per applicazioni pratiche, si raccomanda l'uso di LR=0.01 come punto di partenza per MLP su MNIST, con possibile fine-tuning verso 0.001 se il tempo di training non è critico e si desidera massimizzare l'accuratezza finale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d5f62c",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "### Grafico 2: Confronto Completo delle Architetture (Training vs Test)\n",
    "Questo grafico presenta un confronto esaustivo di tutte le 24 configurazioni testate, mostrando affiancate le accuratezze di training e test per identificare immediatamente pattern di overfitting.  \n",
    "La visualizzazione simultanea di train e test accuracy permette di valutare sia le prestazioni massime raggiungibili che la capacità di generalizzazione di ogni configurazione, elemento fondamentale per la selezione del modello ottimale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0515c449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selezione migliori configurazioni per evidenziazione\n",
    "migliore_mlp = max(risultati_mlp, key=lambda x: x['test_accuracy'])\n",
    "migliore_cnn = max(risultati_cnn, key=lambda x: x['test_accuracy'])\n",
    "\n",
    "# Preparazione dati per tutte le configurazioni\n",
    "nomi_config = [r['nome_config'] for r in tutti_risultati]\n",
    "acc_train_tutte = [r['train_accuracy'] for r in tutti_risultati]\n",
    "acc_test_tutte = [r['test_accuracy'] for r in tutti_risultati]\n",
    "tipi_modello = [r['tipo_modello'] for r in tutti_risultati]\n",
    "\n",
    "# Separazione indici MLP e CNN\n",
    "indici_mlp = [i for i, t in enumerate(tipi_modello) if t == 'MLP']\n",
    "indici_cnn = [i for i, t in enumerate(tipi_modello) if t == 'CNN']\n",
    "\n",
    "# Visualizzazione\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "# Posizioni delle barre\n",
    "x = np.arange(len(nomi_config))\n",
    "larghezza = 0.35\n",
    "\n",
    "# Barre per accuratezza training e test\n",
    "bars_train = ax.bar(x - larghezza/2, acc_train_tutte, larghezza, \n",
    "                   label='Accuratezza Training', alpha=0.8, color='lightcoral')\n",
    "bars_test = ax.bar(x + larghezza/2, acc_test_tutte, larghezza, \n",
    "                  label='Accuratezza Test', alpha=0.8, color='steelblue')\n",
    "\n",
    "# Colorazione diversa per MLP e CNN sui bordi\n",
    "for i in indici_mlp:\n",
    "    bars_train[i].set_edgecolor('darkred')\n",
    "    bars_test[i].set_edgecolor('darkblue')\n",
    "    bars_train[i].set_linewidth(1.5)\n",
    "    bars_test[i].set_linewidth(1.5)\n",
    "\n",
    "for i in indici_cnn:\n",
    "    bars_train[i].set_edgecolor('orange')\n",
    "    bars_test[i].set_edgecolor('green')\n",
    "    bars_train[i].set_linewidth(2)\n",
    "    bars_test[i].set_linewidth(2)\n",
    "\n",
    "ax.set_xlabel('Configurazione')\n",
    "ax.set_ylabel('Accuratezza')\n",
    "ax.set_title('Confronto Completo: Accuratezza Training vs Test per Tutte le Configurazioni')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(nomi_config, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Evidenziazione delle migliori configurazioni\n",
    "idx_migliore_mlp = tutti_risultati.index(migliore_mlp)\n",
    "idx_migliore_cnn = tutti_risultati.index(migliore_cnn)\n",
    "\n",
    "ax.annotate(f'Miglior MLP\\n{migliore_mlp[\"test_accuracy\"]:.4f}', \n",
    "           xy=(idx_migliore_mlp + larghezza/2, migliore_mlp['test_accuracy']),\n",
    "           xytext=(10, 20), textcoords='offset points',\n",
    "           bbox=dict(boxstyle='round,pad=0.3', facecolor='lightblue', alpha=0.7),\n",
    "           arrowprops=dict(arrowstyle='->', color='blue'))\n",
    "\n",
    "ax.annotate(f'Miglior CNN\\n{migliore_cnn[\"test_accuracy\"]:.4f}', \n",
    "           xy=(idx_migliore_cnn + larghezza/2, migliore_cnn['test_accuracy']),\n",
    "           xytext=(10, -30), textcoords='offset points',\n",
    "           bbox=dict(boxstyle='round,pad=0.3', facecolor='lightgreen', alpha=0.7),\n",
    "           arrowprops=dict(arrowstyle='->', color='green'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"CONFRONTO ARCHITETTURE:\")\n",
    "print(f\"Miglior MLP: {migliore_mlp['nome_config']} - Accuratezza Test: {migliore_mlp['test_accuracy']:.4f}\")\n",
    "print(f\"Miglior CNN: {migliore_cnn['nome_config']} - Accuratezza Test: {migliore_cnn['test_accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a1d72d",
   "metadata": {},
   "source": [
    "#### Discussione del grafico e riflessione sui risultati\n",
    "Il confronto completo rivela pattern distintivi tra MLP e CNN: le CNN mostrano consistentemente maggiore capacità di generalizzazione con gap train-test più contenuti (mediamente 0.0034-0.0114) rispetto agli MLP (0.0004-0.0201), indicando architetture intrinsecamente più robuste all'overfitting grazie ai meccanismi di condivisione dei pesi e alle operazioni di convoluzione che catturano invarianze spaziali.\n",
    "\n",
    "La migliore configurazione **CNN** (*extended_lr0.001*: 98.82%) supera il miglior **MLP** (*250n_1S_lr0.001*: 98.10%) di 0.72 punti percentuali, dimostrando la superiorità delle architetture convoluzionali per dati visivi anche su dataset relativamente semplici come MNIST.\n",
    "\n",
    "Particolarmente critico è l'effetto del learning rate 0.1 che causa collasso completo nelle CNN (accuratezza ~10%) suggerendo maggiore sensibilità all'instabilità di training, mentre gli MLP mostrano degrado graduale. \n",
    "\n",
    "Per applicazioni pratiche, si raccomanda l'uso di CNN con learning rate conservativi (≤0.01) quando le risorse computazionali lo permettono, riservando gli MLP a scenari con vincoli di velocità estremi dove la differenza di accuratezza è accettabile."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84ac810",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "### Grafico 3: Analisi dell'Efficienza (Accuratezza per Secondo di Training)\n",
    "\n",
    "Questo grafico quantifica l'efficienza di ogni configurazione calcolando il rapporto accuratezza/tempo, metrica fondamentale per applicazioni con vincoli temporali. L'efficienza rivela quale architettura offre il miglior ritorno in termini di prestazioni per unità di tempo investito, considerazione cruciale per deployment in produzione o sperimentazione rapida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227e43af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcolo efficienza per ogni configurazione\n",
    "efficienze = [r['test_accuracy'] / r['training_time'] for r in tutti_risultati]\n",
    "nomi_config_ordinati = []\n",
    "efficienze_ordinate = []\n",
    "tipi_ordinati = []\n",
    "\n",
    "# Ordinamento per efficienza decrescente\n",
    "indici_ordinati = sorted(range(len(efficienze)), key=lambda i: efficienze[i], reverse=True)\n",
    "\n",
    "for i in indici_ordinati:\n",
    "    nomi_config_ordinati.append(nomi_config[i])\n",
    "    efficienze_ordinate.append(efficienze[i])\n",
    "    tipi_ordinati.append(tipi_modello[i])\n",
    "\n",
    "# Visualizzazione\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "# Colori diversi per MLP e CNN\n",
    "colori = ['lightblue' if tipo == 'MLP' else 'salmon' for tipo in tipi_ordinati]\n",
    "bordi = ['darkblue' if tipo == 'MLP' else 'darkred' for tipo in tipi_ordinati]\n",
    "\n",
    "bars = ax.bar(range(len(nomi_config_ordinati)), efficienze_ordinate, \n",
    "              color=colori, edgecolor=bordi, linewidth=1.5, alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Configurazione (ordinate per efficienza decrescente)')\n",
    "ax.set_ylabel('Efficienza (Accuratezza / Tempo di Training)')\n",
    "ax.set_title('Analisi Efficienza: Accuratezza per Secondo di Training')\n",
    "ax.set_xticks(range(len(nomi_config_ordinati)))\n",
    "ax.set_xticklabels(nomi_config_ordinati, rotation=45, ha='right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Annotazioni per le configurazioni più efficienti\n",
    "for i in range(min(5, len(bars))):  # Evidenzia top 5\n",
    "    height = bars[i].get_height()\n",
    "    ax.annotate(f'{height:.4f}', xy=(i, height),\n",
    "               xytext=(0, 3), textcoords=\"offset points\", \n",
    "               ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Legenda manuale\n",
    "ax.bar([], [], color='lightblue', alpha=0.8, label='MLP')\n",
    "ax.bar([], [], color='salmon', alpha=0.8, label='CNN')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calcolo statistiche di efficienza\n",
    "eff_mlp = [efficienze[i] for i in range(len(tipi_modello)) if tipi_modello[i] == 'MLP']\n",
    "eff_cnn = [efficienze[i] for i in range(len(tipi_modello)) if tipi_modello[i] == 'CNN']\n",
    "\n",
    "print(\"ANALISI EFFICIENZA:\")\n",
    "print(f\"Configurazione più efficiente: {nomi_config_ordinati[0]} - {efficienze_ordinate[0]:.4f} acc/s\")\n",
    "print(f\"Efficienza media MLP: {np.mean(eff_mlp):.4f} acc/s\")\n",
    "print(f\"Efficienza media CNN: {np.mean(eff_cnn):.4f} acc/s\")\n",
    "print(f\"Rapporto efficienza MLP/CNN: {np.mean(eff_mlp)/np.mean(eff_cnn):.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f7f9ec",
   "metadata": {},
   "source": [
    "#### Discussione del grafico e riflessione sui risultati\n",
    "L'analisi dell'efficienza rivela una dominanza netta degli **MLP** con le configurazioni più piccole che raggiungono i vertici della classifica (tipicamente >0.2 accuratezza/secondo), principalmente dovuta ai tempi di training drammaticamente inferiori (4.5-37.9s vs 48.3-112.6s delle CNN) che compensano ampiamente il leggero gap di accuratezza.  \n",
    "\n",
    "Le **CNN**, nonostante prestazioni superiori, mostrano efficienza significativamente ridotta (media 0.018 vs 0.084 acc/s degli MLP) rappresentando un rapporto di 4.7x a favore degli MLP, confermando il trade-off fondamentale velocità-accuratezza nel machine learning. \n",
    "Le configurazioni MLP con learning rate moderati (0.01-0.001) e architetture snelle (50-100 neuroni, 1 strato) emergono come ideali per prototipazione rapida e deployment con vincoli temporali stretti. \n",
    "\n",
    "Dal punto di vista pratico, la scelta dovrebbe basarsi sui requisiti specifici: \n",
    "- MLP per iterazione veloce di sviluppo, validazione di proof-of-concept e sistemi real-time\n",
    "- CNN quando l'accuratezza marginale giustifica l'investimento computazionale aggiuntivo, tipicamente in sistemi di produzione critici dove ogni frazione di punto percentuale ha valore economico."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae94ac8d",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "### Grafico 4: Overfitting per Complessità del Modello\n",
    "\n",
    "Questo grafico analizza la relazione tra complessità del modello (numero totale di parametri) e il fenomeno dell'overfitting (differenza tra accuratezza di training e test). La visualizzazione ordinata per complessità crescente permette di identificare soglie critiche oltre le quali i modelli iniziano a memorizzare anziché generalizzare, informazione cruciale per la progettazione di architetture bilanciate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5eddf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparazione dati ordinati per complessità\n",
    "complessita = [r['parametri_totali'] for r in tutti_risultati]\n",
    "overfitting_valori = [r['overfitting'] for r in tutti_risultati]\n",
    "\n",
    "# Ordinamento per complessità crescente\n",
    "indici_complessita = sorted(range(len(complessita)), key=lambda i: complessita[i])\n",
    "\n",
    "nomi_ordinati_complessita = [nomi_config[i] for i in indici_complessita]\n",
    "complessita_ordinata = [complessita[i] for i in indici_complessita]\n",
    "overfitting_ordinato = [overfitting_valori[i] for i in indici_complessita]\n",
    "tipi_ordinati_complessita = [tipi_modello[i] for i in indici_complessita]\n",
    "\n",
    "# Visualizzazione\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "# Colori basati sul livello di overfitting\n",
    "colori_overfitting = []\n",
    "for ovf in overfitting_ordinato:\n",
    "    if ovf < 0.01:\n",
    "        colori_overfitting.append('lightgreen')  # Basso overfitting\n",
    "    elif ovf < 0.02:\n",
    "        colori_overfitting.append('gold')       # Moderato overfitting\n",
    "    else:\n",
    "        colori_overfitting.append('lightcoral') # Alto overfitting\n",
    "\n",
    "bars = ax.bar(range(len(nomi_ordinati_complessita)), overfitting_ordinato, \n",
    "              color=colori_overfitting, alpha=0.8)\n",
    "\n",
    "# Bordi diversi per tipo di modello\n",
    "for i, tipo in enumerate(tipi_ordinati_complessita):\n",
    "    if tipo == 'MLP':\n",
    "        bars[i].set_edgecolor('darkblue')\n",
    "        bars[i].set_linewidth(1.5)\n",
    "    else:\n",
    "        bars[i].set_edgecolor('darkred')\n",
    "        bars[i].set_linewidth(2)\n",
    "\n",
    "ax.set_xlabel('Configurazione (ordinate per complessità crescente)')\n",
    "ax.set_ylabel('Overfitting (Accuratezza Training - Test)')\n",
    "ax.set_title('Overfitting vs Complessità del Modello')\n",
    "ax.set_xticks(range(len(nomi_ordinati_complessita)))\n",
    "ax.set_xticklabels(nomi_ordinati_complessita, rotation=45, ha='right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Annotazioni per i valori più alti\n",
    "soglia_annotazione = sorted(overfitting_ordinato, reverse=True)[4]  # Top 5\n",
    "for i, (ovf, comp) in enumerate(zip(overfitting_ordinato, complessita_ordinata)):\n",
    "    if ovf >= soglia_annotazione:\n",
    "        ax.annotate(f'{ovf:.3f}\\n{comp/1000:.0f}K param', \n",
    "                   xy=(i, ovf), xytext=(0, 10), \n",
    "                   textcoords='offset points', ha='center', fontsize=9)\n",
    "\n",
    "# Legenda\n",
    "from matplotlib.patches import Patch\n",
    "legenda_elementi = [\n",
    "    Patch(facecolor='lightgreen', label='Basso Overfitting (<0.01)'),\n",
    "    Patch(facecolor='gold', label='Moderato Overfitting (0.01-0.02)'),\n",
    "    Patch(facecolor='lightcoral', label='Alto Overfitting (>0.02)'),\n",
    "    Patch(facecolor='white', edgecolor='darkblue', label='MLP'),\n",
    "    Patch(facecolor='white', edgecolor='darkred', label='CNN')\n",
    "]\n",
    "ax.legend(handles=legenda_elementi, loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ANALISI OVERFITTING:\")\n",
    "print(f\"Range overfitting MLP: {min([r['overfitting'] for r in risultati_mlp]):.4f} - {max([r['overfitting'] for r in risultati_mlp]):.4f}\")\n",
    "print(f\"Range overfitting CNN: {min([r['overfitting'] for r in risultati_cnn]):.4f} - {max([r['overfitting'] for r in risultati_cnn]):.4f}\")\n",
    "print(f\"Modello più complesso: {max(complessita_ordinata)/1000:.0f}K parametri\")\n",
    "print(f\"Modello meno complesso: {min(complessita_ordinata)/1000:.0f}K parametri\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0817dc8",
   "metadata": {},
   "source": [
    "#### Discussione del grafico e riflessione sui risultati\n",
    "\n",
    "L'analisi dell'overfitting rivela comportamenti distintivi tra architetture: \n",
    "- Le CNN mantengono controllo superiore dell'overfitting (range 0.0012-0.0114) anche con alta complessità parametrica grazie ai meccanismi intrinsechi di regolarizzazione (weight sharing, invarianze spaziali)\n",
    "- Gli MLP mostrano variabilità maggiore (0.0004-0.0201) con particolare vulnerabilità nelle configurazioni più profonde e con learning rate sub-ottimali. \n",
    "  \n",
    "Controintuitivamente, non emerge una correlazione diretta tra numero di parametri e overfitting, suggerendo che l'architettura e l'algoritmo di ottimizzazione sono più determinanti della mera complessità parametrica: le CNN con 260K parametri mostrano overfitting inferiore a MLP con 80K parametri. \n",
    "\n",
    "I modelli con learning rate 0.1 presentano pattern anomali (overfitting estremamente basso) dovuti al collasso del training piuttosto che a buona generalizzazione. \n",
    "\n",
    "Dal punto di vista pratico, l'early stopping si rivela efficace nel prevenire overfitting severo in entrambe le architetture, mentre la scelta dell'architettura (CNN vs MLP) e del learning rate hanno impatto più significativo della complessità assoluta, supportando approcci di progettazione che privilegiano l'appropriatezza architettonica rispetto alla semplice limitazione parametrica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b03372e",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "### Grafico 5: Velocità di Convergenza (Iterazioni per Configurazione)\n",
    "\n",
    "Questo grafico confronta il numero di iterazioni necessarie per raggiungere la convergenza across tutte le configurazioni, rivelando l'efficienza algoritmica di diverse architetture e iperparametri. La velocità di convergenza è cruciale per la comprensione dell'ottimizzazione: configurazioni che convergono rapidamente indicano paesaggi di loss più favorevoli e gradient flow più efficace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce16e7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparazione dati convergenza\n",
    "iterazioni_tutte = [r['iterations'] for r in tutti_risultati]\n",
    "\n",
    "# Ordinamento per numero di iterazioni crescente\n",
    "indici_iter = sorted(range(len(iterazioni_tutte)), key=lambda i: iterazioni_tutte[i])\n",
    "\n",
    "nomi_ordinati_iter = [nomi_config[i] for i in indici_iter]\n",
    "iterazioni_ordinate = [iterazioni_tutte[i] for i in indici_iter]\n",
    "tipi_ordinati_iter = [tipi_modello[i] for i in indici_iter]\n",
    "lr_ordinati = [tutti_risultati[i]['learning_rate'] for i in indici_iter]\n",
    "\n",
    "# Visualizzazione\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "# Colori basati su learning rate\n",
    "colori_lr = []\n",
    "for lr in lr_ordinati:\n",
    "    if lr == 0.001:\n",
    "        colori_lr.append('lightgreen')\n",
    "    elif lr == 0.01:\n",
    "        colori_lr.append('gold')\n",
    "    else:\n",
    "        colori_lr.append('lightcoral')\n",
    "\n",
    "bars = ax.bar(range(len(nomi_ordinati_iter)), iterazioni_ordinate, \n",
    "              color=colori_lr, alpha=0.8)\n",
    "\n",
    "# Bordi per tipo di modello\n",
    "for i, tipo in enumerate(tipi_ordinati_iter):\n",
    "    if tipo == 'MLP':\n",
    "        bars[i].set_edgecolor('darkblue')\n",
    "        bars[i].set_linewidth(1.5)\n",
    "    else:\n",
    "        bars[i].set_edgecolor('darkred')\n",
    "        bars[i].set_linewidth(2)\n",
    "\n",
    "ax.set_xlabel('Configurazione (ordinate per iterazioni crescenti)')\n",
    "ax.set_ylabel('Iterazioni per Convergenza')\n",
    "ax.set_title('Velocità di Convergenza per Tutte le Configurazioni')\n",
    "ax.set_xticks(range(len(nomi_ordinati_iter)))\n",
    "ax.set_xticklabels(nomi_ordinati_iter, rotation=45, ha='right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Annotazioni per valori significativi\n",
    "for i in range(0, len(bars), 4):  # Ogni 4 configurazioni\n",
    "    height = bars[i].get_height()\n",
    "    ax.annotate(f'{int(height)}', xy=(i, height),\n",
    "               xytext=(0, 3), textcoords=\"offset points\", \n",
    "               ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# Legenda\n",
    "legenda_elementi = [\n",
    "    Patch(facecolor='lightgreen', label='LR = 0.001'),\n",
    "    Patch(facecolor='gold', label='LR = 0.01'),\n",
    "    Patch(facecolor='lightcoral', label='LR = 0.1'),\n",
    "    Patch(facecolor='white', edgecolor='darkblue', label='MLP'),\n",
    "    Patch(facecolor='white', edgecolor='darkred', label='CNN')\n",
    "]\n",
    "ax.legend(handles=legenda_elementi)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistiche per tipo di modello\n",
    "iter_mlp = [r['iterations'] for r in risultati_mlp]\n",
    "iter_cnn = [r['iterations'] for r in risultati_cnn]\n",
    "\n",
    "print(\"ANALISI VELOCITÀ CONVERGENZA:\")\n",
    "print(f\"Iterazioni medie MLP: {np.mean(iter_mlp):.1f}\")\n",
    "print(f\"Iterazioni medie CNN: {np.mean(iter_cnn):.1f}\")\n",
    "print(f\"Configurazione più veloce: {nomi_ordinati_iter[0]} - {iterazioni_ordinate[0]} iterazioni\")\n",
    "print(f\"Configurazione più lenta: {nomi_ordinati_iter[-1]} - {iterazioni_ordinate[-1]} iterazioni\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efe93d9",
   "metadata": {},
   "source": [
    "#### Discussione del grafico e dei risultati  \n",
    "La velocità di convergenza mostra pattern chiari legati all'architettura e agli iperparametri: le CNN convergono sistematicamente più velocemente (media 6.7 iterazioni) rispetto agli MLP (media 22.2 iterazioni) grazie a gradient flow più efficace e paesaggi di loss più regolari derivanti dalla struttura convoluzionale.  \n",
    "\n",
    "Il learning rate gioca un ruolo determinante con LR=0.1 che causa convergenza prematura in configurazioni degradate e LR conservativi (0.001) che richiedono più iterazioni ma raggiungono soluzioni superiori.  \n",
    "Le configurazioni CNN con LR elevati mostrano convergenza artificialmente rapida (6 iterazioni) dovuta al collasso del training piuttosto che a ottimizzazione efficace, mentre configurazioni MLP complesse con LR moderati richiedono fino a 43 iterazioni riflettendo la maggiore difficoltà di navigazione in spazi parametrici ad alta dimensionalità.  \n",
    "\n",
    "Dal punto di vista dell'efficienza computazionale, nonostante la convergenza più lenta degli MLP in termini di epoche, il tempo totale rimane competitivo per le architetture snelle grazie al costo computazionale per iterazione significativamente inferiore.  \n",
    "\n",
    "Questa analisi suggerisce che per applicazioni con budget computazionale limitato, MLP con architetture moderate (50-100 neuroni) e LR=0.01 offrono il miglior compromesso convergenza-prestazioni, mentre CNN giustificano il maggior costo iterativo quando l'accuratezza finale è prioritaria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7eb814b",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "### Grafico 6: Effetto Scaling MLP (1 vs 2 Strati Nascosti)\n",
    "\n",
    "Questo grafico analizza sistematicamente l'effetto della profondità nelle reti MLP confrontando prestazioni e tempi di training tra architetture a 1 e 2 strati nascosti. L'analisi rivela il trade-off fondamentale tra capacità espressiva (profondità) e efficienza computazionale, fornendo insights cruciali per la progettazione di architetture bilanciate su dataset di complessità moderata come MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997049ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisi scaling MLP\n",
    "range_neuroni = neuroni_lista\n",
    "acc_1_strato = []\n",
    "acc_2_strati = []\n",
    "tempo_1_strato = []\n",
    "tempo_2_strati = []\n",
    "\n",
    "for neuroni in range_neuroni:\n",
    "    # 1 strato\n",
    "    risultati_1s = [r for r in risultati_mlp if r['neuroni'] == neuroni and r['n_strati'] == 1]\n",
    "    if risultati_1s:\n",
    "        acc_1_strato.append(np.mean([r['test_accuracy'] for r in risultati_1s]))\n",
    "        tempo_1_strato.append(np.mean([r['training_time'] for r in risultati_1s]))\n",
    "    \n",
    "    # 2 strati  \n",
    "    risultati_2s = [r for r in risultati_mlp if r['neuroni'] == neuroni and r['n_strati'] == 2]\n",
    "    if risultati_2s:\n",
    "        acc_2_strati.append(np.mean([r['test_accuracy'] for r in risultati_2s]))\n",
    "        tempo_2_strati.append(np.mean([r['training_time'] for r in risultati_2s]))\n",
    "\n",
    "# Visualizzazione\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Subplot 1: Scaling accuratezza\n",
    "ax1.plot(range_neuroni, acc_1_strato, 'o-', linewidth=2, markersize=8, \n",
    "         label='1 Strato Nascosto', color='blue')\n",
    "ax1.plot(range_neuroni, acc_2_strati, 's-', linewidth=2, markersize=8, \n",
    "         label='2 Strati Nascosti', color='darkblue')\n",
    "\n",
    "ax1.set_xlabel('Neuroni per Strato')\n",
    "ax1.set_ylabel('Accuratezza Test')\n",
    "ax1.set_title('Scaling MLP: Accuratezza vs Profondità')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Annotazioni\n",
    "for i, (neuroni, acc1, acc2) in enumerate(zip(range_neuroni, acc_1_strato, acc_2_strati)):\n",
    "    ax1.annotate(f'{acc1:.3f}', (neuroni, acc1), textcoords=\"offset points\", \n",
    "                xytext=(0,10), ha='center', color='blue', fontweight='bold')\n",
    "    ax1.annotate(f'{acc2:.3f}', (neuroni, acc2), textcoords=\"offset points\", \n",
    "                xytext=(0,-15), ha='center', color='darkblue', fontweight='bold')\n",
    "\n",
    "# Subplot 2: Scaling tempo di training\n",
    "ax2.plot(range_neuroni, tempo_1_strato, 'o-', linewidth=2, markersize=8, \n",
    "         label='1 Strato Nascosto', color='green')\n",
    "ax2.plot(range_neuroni, tempo_2_strati, 's-', linewidth=2, markersize=8, \n",
    "         label='2 Strati Nascosti', color='darkgreen')\n",
    "\n",
    "ax2.set_xlabel('Neuroni per Strato')\n",
    "ax2.set_ylabel('Tempo di Training (secondi)')\n",
    "ax2.set_title('Scaling MLP: Tempo di Training vs Profondità')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Annotazioni tempo\n",
    "for i, (neuroni, t1, t2) in enumerate(zip(range_neuroni, tempo_1_strato, tempo_2_strati)):\n",
    "    ax2.annotate(f'{t1:.1f}s', (neuroni, t1), textcoords=\"offset points\", \n",
    "                xytext=(0,10), ha='center', color='green', fontweight='bold')\n",
    "    ax2.annotate(f'{t2:.1f}s', (neuroni, t2), textcoords=\"offset points\", \n",
    "                xytext=(0,-15), ha='center', color='darkgreen', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ANALISI SCALING MLP:\")\n",
    "for i, neuroni in enumerate(range_neuroni):\n",
    "    print(f\"{neuroni} neuroni: 1S={acc_1_strato[i]:.4f} ({tempo_1_strato[i]:.1f}s), \"\n",
    "          f\"2S={acc_2_strati[i]:.4f} ({tempo_2_strati[i]:.1f}s)\")\n",
    "\n",
    "# Calcolo differenze prestazioni\n",
    "diff_acc = [acc_1_strato[i] - acc_2_strati[i] for i in range(len(range_neuroni))]\n",
    "rapporto_tempo = [tempo_2_strati[i] / tempo_1_strato[i] for i in range(len(range_neuroni))]\n",
    "\n",
    "print(f\"\\nDifferenza accuratezza media (1S - 2S): {np.mean(diff_acc):+.4f}\")\n",
    "print(f\"Rapporto tempo medio (2S : 1S): {np.mean(rapporto_tempo):.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c087fa7e",
   "metadata": {},
   "source": [
    "#### Discussione dei grafici e riflessione sui risultati\n",
    "L'analisi dello scaling rivela un risultato controintuitivo per MNIST: le architetture a 1 strato nascosto superano sistematicamente quelle a 2 strati con un vantaggio medio di +0.022 punti di accuratezza, suggerendo che la maggiore profondità introduce overfitting anziché migliorare l'espressività per dataset relativamente semplici come le cifre manoscritte. \n",
    "\n",
    "Il fenomeno è particolarmente evidente con architetture larghe (250 neuroni) dove il gap raggiunge 0.052 punti, indicando che l'aumento di parametri da profondità aggiuntiva eccede la complessità intrinseca del task causando memorizzazione del training set. \n",
    "\n",
    "Dal punto di vista computazionale, le architetture a 2 strati richiedono mediamente 1.11-1.68x più tempo per convergere, penalizzando ulteriormente il rapporto prestazioni-costo già sfavorevole. \n",
    "Questo comportamento riflette la natura del dataset MNIST dove le features discriminative sono relativamente semplici e non richiedono composizioni gerarchiche complesse che motiverebbero architetture profonde. \n",
    "\n",
    "Per applicazioni pratiche su MNIST, si raccomanda fortemente l'uso di architetture a singolo strato nascosto con 100-250 neuroni che offrono il miglior compromesso accuratezza-efficienza, riservando architetture più profonde a dataset con maggiore complessità strutturale dove i benefici della gerarchia di features giustifichino il costo computazionale aggiuntivo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bd777d",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "### Conclusioni\n",
    "\n",
    "**Configurazioni ottimali identificate:**  \n",
    "\n",
    "Gli esperimenti sistematici hanno identificato due architetture leader: \n",
    "- **MLP** con *250 neuroni, 1 strato nascosto* e *learning rate 0.001* raggiunge **98.10%** di accuratezza rappresentando la soluzione più efficiente, \n",
    "- **CNN** *extended* con *learning rate 0.001* ottiene **98.82%** stabilendo il nuovo benchmark di prestazioni con superiore robustezza all'overfitting. \n",
    "\n",
    "**Insights principali emergenti:**  \n",
    "\n",
    "Il learning rate si conferma iperparametro critico con 0.001-0.01 come range ottimale, valori di 0.1 causano collasso catastrofico nelle CNN mentre rimangono tollerabili negli MLP.  \n",
    "\n",
    "La profondità aggiuntiva negli MLP danneggia le prestazioni su MNIST introducendo overfitting senza benefici, contraddicendo l'intuizione comune sulla superiorità di architetture profonde.  \n",
    "\n",
    "Le CNN mostrano intrinseca resistenza all'overfitting e convergenza più rapida ma richiedono 2.5-4x più tempo totale di training.\n",
    "\n",
    "**Raccomandazioni strategiche:** \n",
    "- Per *prototipazione rapida e vincoli computazionali* utilizzare MLP(100, lr=0.01) che offre 97.3% accuratezza in <10 secondi\n",
    "- Per *massimizzazione prestazioni senza vincoli temporali* impiegare CNN extended con lr=0.001 ottenendo 98.8% con robustezza superiore \n",
    "- Per *deployment critico* bilanciare con MLP(250, lr=0.001) che raggiunge 98.1% mantenendo efficienza 4x superiore alle CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5229592b",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "---\n",
    "## Punto B: Analisi delle cifre più difficili da riconoscere\n",
    "\n",
    "Utilizziamo la matrice di confusione per identificare quali cifre il modello MLP trova più difficili da classificare correttamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62cb0a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mlp_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Addestro un MLP con architettura ottimale trovata precedentemente\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m best_mlp_config = \u001b[38;5;28mmax\u001b[39m(\u001b[43mmlp_results\u001b[49m, key=\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[33m'\u001b[39m\u001b[33mtest_accuracy\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      4\u001b[39m mlp_best = MLPClassifier(\n\u001b[32m      5\u001b[39m     hidden_layer_sizes=best_mlp_config[\u001b[33m'\u001b[39m\u001b[33mhidden_layers\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m      6\u001b[39m     learning_rate_init=best_mlp_config[\u001b[33m'\u001b[39m\u001b[33mlearning_rate\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     10\u001b[39m     validation_fraction=\u001b[32m0.1\u001b[39m\n\u001b[32m     11\u001b[39m )\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining MLP con architettura ottimale: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_mlp_config[\u001b[33m'\u001b[39m\u001b[33mconfig_name\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'mlp_results' is not defined"
     ]
    }
   ],
   "source": [
    "# Addestro un MLP con architettura ottimale trovata precedentemente\n",
    "best_mlp_config = max(mlp_results, key=lambda x: x['test_accuracy'])\n",
    "\n",
    "mlp_best = MLPClassifier(\n",
    "    hidden_layer_sizes=best_mlp_config['hidden_layers'],\n",
    "    learning_rate_init=best_mlp_config['learning_rate'],\n",
    "    max_iter=100,\n",
    "    random_state=42,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.1\n",
    ")\n",
    "\n",
    "print(f\"Training MLP con architettura ottimale: {best_mlp_config['config_name']}\")\n",
    "mlp_best.fit(x_tr, mnist_tr_labels)\n",
    "print(f\"Accuratezza sul test set: {mlp_best.score(x_te, mnist_te_labels):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa1e676",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mlp_best' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Calcolo predizioni e matrice di confusione\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m y_pred = \u001b[43mmlp_best\u001b[49m.predict(x_te)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Visualizzazione matrice di confusione\u001b[39;00m\n\u001b[32m      5\u001b[39m cm = metrics.confusion_matrix(mnist_te_labels, y_pred)\n",
      "\u001b[31mNameError\u001b[39m: name 'mlp_best' is not defined"
     ]
    }
   ],
   "source": [
    "# Calcolo predizioni e matrice di confusione\n",
    "y_pred = mlp_best.predict(x_te)\n",
    "\n",
    "# Visualizzazione matrice di confusione\n",
    "cm = metrics.confusion_matrix(mnist_te_labels, y_pred)\n",
    "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "disp.plot(ax=ax, cmap='Blues', values_format='d')\n",
    "ax.set_title('Matrice di Confusione - MLP su MNIST', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aea94d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisi degli errori più frequenti\n",
    "errors_per_digit = []\n",
    "for digit in range(10):\n",
    "    mask = mnist_te_labels == digit\n",
    "    total = np.sum(mask)\n",
    "    correct = np.sum((y_pred == mnist_te_labels) & mask)\n",
    "    error_rate = 1 - (correct / total)\n",
    "    \n",
    "    errors_per_digit.append({\n",
    "        'digit': digit,\n",
    "        'total_samples': total,\n",
    "        'correct': correct,\n",
    "        'errors': total - correct,\n",
    "        'error_rate': error_rate,\n",
    "        'accuracy': correct / total\n",
    "    })\n",
    "\n",
    "df_errors = pd.DataFrame(errors_per_digit)\n",
    "df_errors_sorted = df_errors.sort_values('error_rate', ascending=False)\n",
    "\n",
    "print(\"Cifre ordinate per difficoltà (tasso di errore):\")\n",
    "print(df_errors_sorted[['digit', 'total_samples', 'errors', 'error_rate', 'accuracy']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fee995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizzazione delle coppie di cifre più confuse\n",
    "confusion_pairs = []\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        if i != j and cm[i, j] > 0:\n",
    "            confusion_pairs.append({\n",
    "                'true_digit': i,\n",
    "                'predicted_digit': j,\n",
    "                'count': cm[i, j],\n",
    "                'percentage': cm[i, j] / np.sum(cm[i, :]) * 100\n",
    "            })\n",
    "\n",
    "df_confusion = pd.DataFrame(confusion_pairs)\n",
    "df_confusion_sorted = df_confusion.sort_values('count', ascending=False).head(10)\n",
    "\n",
    "print(\"\\nLe 10 coppie di cifre più confuse:\")\n",
    "for _, row in df_confusion_sorted.iterrows():\n",
    "    print(f\"{row['true_digit']} → {row['predicted_digit']}: {row['count']} errori ({row['percentage']:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297a7f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizzazione esempi di cifre classificate erroneamente\n",
    "fig, axes = plt.subplots(4, 5, figsize=(15, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "example_idx = 0\n",
    "for _, conf_pair in df_confusion_sorted.head(4).iterrows():\n",
    "    true_digit = conf_pair['true_digit']\n",
    "    pred_digit = conf_pair['predicted_digit']\n",
    "    \n",
    "    # Trovo esempi di questo tipo di errore\n",
    "    error_mask = (mnist_te_labels == true_digit) & (y_pred == pred_digit)\n",
    "    error_indices = np.where(error_mask)[0]\n",
    "    \n",
    "    # Mostro fino a 5 esempi per ogni coppia\n",
    "    for i in range(min(5, len(error_indices))):\n",
    "        if example_idx < 20:\n",
    "            idx = error_indices[i]\n",
    "            axes[example_idx].imshow(mnist_te_data[idx], cmap='gray')\n",
    "            axes[example_idx].set_title(f'Vero: {true_digit}, Predetto: {pred_digit}', fontsize=10)\n",
    "            axes[example_idx].axis('off')\n",
    "            example_idx += 1\n",
    "\n",
    "# Nascondo assi non utilizzati\n",
    "for i in range(example_idx, 20):\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Esempi di cifre classificate erroneamente', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c739254c",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 1
   },
   "source": [
    "## Punto C: Curve psicometriche - Effetto del rumore\n",
    "\n",
    "Seguendo la metodologia dell'articolo di Testolin et al. (2017), analizziamo come l'accuratezza degrada all'aumentare del rumore Gaussiano aggiunto alle immagini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4af4f1e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Funzione per aggiungere rumore Gaussiano\n",
    "def add_gaussian_noise(images, noise_std):\n",
    "    \"\"\"\n",
    "    Aggiunge rumore Gaussiano alle immagini.\n",
    "    \n",
    "    Args:\n",
    "        images: array di immagini\n",
    "        noise_std: deviazione standard del rumore\n",
    "    \n",
    "    Returns:\n",
    "        Immagini con rumore, clippate tra 0 e 1\n",
    "    \"\"\"\n",
    "    noise = np.random.normal(0, noise_std, images.shape)\n",
    "    noisy_images = images + noise\n",
    "    return np.clip(noisy_images, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5612fff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calcolo curve psicometriche per MLP...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mlp_best' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m noise_std \u001b[38;5;129;01min\u001b[39;00m noise_levels:\n\u001b[32m     12\u001b[39m     x_te_noisy = add_gaussian_noise(x_te_subset, noise_std)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     acc_mlp = \u001b[43mmlp_best\u001b[49m.score(x_te_noisy, y_te_subset)\n\u001b[32m     14\u001b[39m     accuracies_mlp.append(acc_mlp)\n\u001b[32m     15\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNoise std: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnoise_std\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m - MLP acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc_mlp\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'mlp_best' is not defined"
     ]
    }
   ],
   "source": [
    "# Test con diversi livelli di rumore\n",
    "noise_levels = np.arange(0, 0.5, 0.05)\n",
    "accuracies_mlp = []\n",
    "\n",
    "# Uso un subset del test set per velocizzare\n",
    "subset_size = 2000\n",
    "x_te_subset = x_te[:subset_size]\n",
    "y_te_subset = mnist_te_labels[:subset_size]\n",
    "\n",
    "print(\"Calcolo curve psicometriche per MLP...\")\n",
    "for noise_std in noise_levels:\n",
    "    x_te_noisy = add_gaussian_noise(x_te_subset, noise_std)\n",
    "    acc_mlp = mlp_best.score(x_te_noisy, y_te_subset)\n",
    "    accuracies_mlp.append(acc_mlp)\n",
    "    print(f\"Noise std: {noise_std:.3f} - MLP acc: {acc_mlp:.4f}\")\n",
    "\n",
    "# Test anche con CNN se disponibile\n",
    "best_cnn_config = max(cnn_results, key=lambda x: x['test_accuracy'])\n",
    "cnn_model = create_cnn_model(best_cnn_config['architecture'], best_cnn_config['learning_rate'])\n",
    "\n",
    "# Riaddestro il modello CNN migliore\n",
    "early_stopping = keras.callbacks.EarlyStopping(patience=5, min_delta=0.001, restore_best_weights=True, verbose=0)\n",
    "cnn_model.fit(x_tr_conv, mnist_tr_labels, validation_split=0.1, epochs=20, batch_size=128, \n",
    "              callbacks=[early_stopping], verbose=0)\n",
    "\n",
    "print(\"\\nCalcolo curve psicometriche per CNN...\")\n",
    "accuracies_cnn = []\n",
    "x_te_conv_subset = x_te_conv[:subset_size]\n",
    "\n",
    "for noise_std in noise_levels:\n",
    "    x_te_conv_noisy = add_gaussian_noise(x_te_conv_subset, noise_std)\n",
    "    test_loss, acc_cnn = cnn_model.evaluate(x_te_conv_noisy, y_te_subset, verbose=0)\n",
    "    accuracies_cnn.append(acc_cnn)\n",
    "    print(f\"Noise std: {noise_std:.3f} - CNN acc: {acc_cnn:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05a95ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizzazione curve psicometriche\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Grafico 1: Curve psicometriche\n",
    "ax1.plot(noise_levels, accuracies_mlp, 'o-', label='MLP', linewidth=3, markersize=8, color='blue')\n",
    "ax1.plot(noise_levels, accuracies_cnn, 's-', label='CNN', linewidth=3, markersize=8, color='red')\n",
    "\n",
    "ax1.set_xlabel('Deviazione standard del rumore', fontsize=12)\n",
    "ax1.set_ylabel('Accuratezza', fontsize=12)\n",
    "ax1.set_title('Curve Psicometriche - Robustezza al rumore', fontsize=14)\n",
    "ax1.legend(fontsize=12)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim(0, 1.05)\n",
    "\n",
    "# Evidenziare punti chiave\n",
    "for i, (noise, acc_mlp, acc_cnn) in enumerate(zip(noise_levels[::2], accuracies_mlp[::2], accuracies_cnn[::2])):\n",
    "    ax1.annotate(f'{acc_mlp:.2f}', (noise, acc_mlp), textcoords=\"offset points\", \n",
    "                xytext=(0,10), ha='center', fontsize=9, color='blue')\n",
    "    ax1.annotate(f'{acc_cnn:.2f}', (noise, acc_cnn), textcoords=\"offset points\", \n",
    "                xytext=(0,-15), ha='center', fontsize=9, color='red')\n",
    "\n",
    "# Grafico 2: Esempi di cifre con diversi livelli di rumore\n",
    "noise_examples = [0, 0.1, 0.2, 0.3, 0.4]\n",
    "digit_idx = 0\n",
    "\n",
    "axes_noise = []\n",
    "for i, noise in enumerate(noise_examples):\n",
    "    ax_sub = fig.add_subplot(2, 5, 6+i)\n",
    "    noisy_img = add_gaussian_noise(x_te[digit_idx:digit_idx+1], noise)[0]\n",
    "    ax_sub.imshow(noisy_img.reshape(28, 28), cmap='gray', vmin=0, vmax=1)\n",
    "    ax_sub.set_title(f'σ = {noise}', fontsize=10)\n",
    "    ax_sub.axis('off')\n",
    "\n",
    "plt.figtext(0.75, 0.02, f'Esempi di cifra {mnist_te_labels[digit_idx]} con diversi livelli di rumore', \n",
    "           ha='center', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8eafb6",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Punto D: Effetto della riduzione dei dati di training\n",
    "\n",
    "Analizziamo come le prestazioni degradano quando riduciamo drasticamente la quantità di dati di training disponibili."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2990972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test con riduzione dei dati di training...\n",
      "\n",
      "Training con 1% dei dati...\n",
      "Samples utilizzati: 596 / 60000\n",
      "Train acc: 0.9664, Test acc: 0.8687\n",
      "\n",
      "Training con 5% dei dati...\n",
      "Samples utilizzati: 2996 / 60000\n",
      "Train acc: 0.9907, Test acc: 0.9215\n",
      "\n",
      "Training con 10% dei dati...\n",
      "Samples utilizzati: 5996 / 60000\n",
      "Train acc: 0.9887, Test acc: 0.9409\n",
      "\n",
      "Training con 25% dei dati...\n",
      "Samples utilizzati: 14995 / 60000\n",
      "Train acc: 0.9944, Test acc: 0.9600\n",
      "\n",
      "Training con 50% dei dati...\n",
      "Samples utilizzati: 29997 / 60000\n",
      "Train acc: 0.9976, Test acc: 0.9706\n",
      "\n",
      "Training con 75% dei dati...\n",
      "Samples utilizzati: 44995 / 60000\n",
      "Train acc: 0.9975, Test acc: 0.9761\n",
      "\n",
      "Training con 100% dei dati...\n",
      "Samples utilizzati: 60000 / 60000\n",
      "Train acc: 0.9972, Test acc: 0.9783\n"
     ]
    }
   ],
   "source": [
    "# Test con diverse percentuali di dati di training\n",
    "train_percentages = [1, 5, 10, 25, 50, 75, 100]\n",
    "results_data_reduction = []\n",
    "\n",
    "print(\"Test con riduzione dei dati di training...\")\n",
    "for percentage in train_percentages:\n",
    "    print(f\"\\nTraining con {percentage}% dei dati...\")\n",
    "    \n",
    "    # Campionamento stratificato per mantenere bilanciamento classi\n",
    "    indices = []\n",
    "    for digit in range(10):\n",
    "        digit_indices = np.where(mnist_tr_labels == digit)[0]\n",
    "        n_digit_samples = int(len(digit_indices) * percentage / 100)\n",
    "        if n_digit_samples > 0:\n",
    "            selected_indices = np.random.choice(digit_indices, n_digit_samples, replace=False)\n",
    "            indices.extend(selected_indices)\n",
    "    \n",
    "    indices = np.array(indices)\n",
    "    x_tr_reduced = x_tr[indices]\n",
    "    y_tr_reduced = mnist_tr_labels[indices]\n",
    "    \n",
    "    print(f\"Samples utilizzati: {len(indices)} su {len(x_tr)}\")\n",
    "    \n",
    "    # Training MLP\n",
    "    mlp_reduced = MLPClassifier(\n",
    "        hidden_layer_sizes=(100, 100),\n",
    "        max_iter=100,\n",
    "        random_state=42,\n",
    "        early_stopping=True,\n",
    "        validation_fraction=0.1 if len(indices) > 100 else 0.2\n",
    "    )\n",
    "    \n",
    "    start_time = time.time()\n",
    "    mlp_reduced.fit(x_tr_reduced, y_tr_reduced)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    train_acc = mlp_reduced.score(x_tr_reduced, y_tr_reduced)\n",
    "    test_acc = mlp_reduced.score(x_te, mnist_te_labels)\n",
    "    \n",
    "    results_data_reduction.append({\n",
    "        'percentage': percentage,\n",
    "        'n_samples': len(indices),\n",
    "        'train_accuracy': train_acc,\n",
    "        'test_accuracy': test_acc,\n",
    "        'overfitting': train_acc - test_acc,\n",
    "        'training_time': training_time\n",
    "    })\n",
    "    \n",
    "    print(f\"Train acc: {train_acc:.4f}, Test acc: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbece1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizzazione effetto riduzione dati\n",
    "df_reduction = pd.DataFrame(results_data_reduction)\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Grafico 1: Accuratezza vs percentuale dati\n",
    "ax1.plot(df_reduction['percentage'], df_reduction['test_accuracy'], 'o-', \n",
    "        linewidth=3, markersize=10, color='darkblue', label='Test')\n",
    "ax1.plot(df_reduction['percentage'], df_reduction['train_accuracy'], 's-', \n",
    "        linewidth=3, markersize=10, color='lightblue', label='Train')\n",
    "ax1.set_xlabel('Percentuale di dati di training utilizzati (%)')\n",
    "ax1.set_ylabel('Accuratezza')\n",
    "ax1.set_title('Effetto della riduzione dei dati di training')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Evidenzio il punto al 10%\n",
    "idx_10 = df_reduction[df_reduction['percentage'] == 10].index[0]\n",
    "ax1.scatter(10, df_reduction.loc[idx_10, 'test_accuracy'], \n",
    "          s=200, color='red', zorder=5)\n",
    "ax1.annotate(f\"10%: {df_reduction.loc[idx_10, 'test_accuracy']:.3f}\", \n",
    "           xy=(10, df_reduction.loc[idx_10, 'test_accuracy']),\n",
    "           xytext=(20, df_reduction.loc[idx_10, 'test_accuracy'] - 0.05),\n",
    "           arrowprops=dict(arrowstyle='->', color='red'),\n",
    "           fontsize=11)\n",
    "\n",
    "# Grafico 2: Overfitting vs dimensione dataset\n",
    "ax2.plot(df_reduction['percentage'], df_reduction['overfitting'], 'o-', \n",
    "        linewidth=3, markersize=10, color='purple')\n",
    "ax2.set_xlabel('Percentuale di dati (%)')\n",
    "ax2.set_ylabel('Overfitting (Train - Test)')\n",
    "ax2.set_title('Overfitting vs Dimensione dataset')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Grafico 3: Tempo vs dimensione dataset\n",
    "ax3.plot(df_reduction['n_samples'], df_reduction['training_time'], 'o-', \n",
    "        linewidth=3, markersize=10, color='green')\n",
    "ax3.set_xlabel('Numero di campioni')\n",
    "ax3.set_ylabel('Tempo di training (s)')\n",
    "ax3.set_title('Tempo di training vs Dimensione dataset')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Grafico 4: Efficienza (acc/tempo) vs dimensione\n",
    "efficiency = df_reduction['test_accuracy'] / df_reduction['training_time']\n",
    "ax4.plot(df_reduction['percentage'], efficiency, 'o-', \n",
    "        linewidth=3, markersize=10, color='orange')\n",
    "ax4.set_xlabel('Percentuale di dati (%)')\n",
    "ax4.set_ylabel('Efficienza (Accuratezza / Tempo)')\n",
    "ax4.set_title('Efficienza vs Dimensione dataset')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaeed67a",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Punto E: Training con rumore per migliorare la robustezza\n",
    "\n",
    "Verifichiamo se l'aggiunta di rumore durante il training può migliorare le prestazioni su dati di test rumorosi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870cbfa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training modelli con rumore nei dati di training...\n",
      "\n",
      "Training con rumore std = 0\n",
      "Accuratezza su test set pulito: 0.9803\n",
      "Tempo di training: 21.3s\n",
      "\n",
      "Training con rumore std = 0.05\n",
      "Accuratezza su test set pulito: 0.9760\n",
      "Tempo di training: 22.1s\n",
      "\n",
      "Training con rumore std = 0.1\n",
      "Accuratezza su test set pulito: 0.9688\n",
      "Tempo di training: 10.5s\n",
      "\n",
      "Training con rumore std = 0.15\n",
      "Accuratezza su test set pulito: 0.9720\n",
      "Tempo di training: 17.8s\n",
      "\n",
      "Training con rumore std = 0.2\n",
      "Accuratezza su test set pulito: 0.9622\n",
      "Tempo di training: 15.7s\n"
     ]
    }
   ],
   "source": [
    "# Training di modelli con diversi livelli di rumore nel training set\n",
    "training_noise_levels = [0, 0.05, 0.1, 0.15, 0.2]\n",
    "models_with_noise = {}\n",
    "\n",
    "print(\"Training modelli con rumore nei dati di training...\")\n",
    "for train_noise in training_noise_levels:\n",
    "    print(f\"\\nTraining con rumore std = {train_noise}\")\n",
    "    \n",
    "    # Aggiungo rumore ai dati di training\n",
    "    if train_noise > 0:\n",
    "        x_tr_noisy = add_gaussian_noise(x_tr, train_noise)\n",
    "    else:\n",
    "        x_tr_noisy = x_tr\n",
    "    \n",
    "    # Training MLP\n",
    "    mlp_noise = MLPClassifier(\n",
    "        hidden_layer_sizes=(100, 100),\n",
    "        max_iter=100,\n",
    "        random_state=42,\n",
    "        early_stopping=True,\n",
    "        validation_fraction=0.1\n",
    "    )\n",
    "    \n",
    "    start_time = time.time()\n",
    "    mlp_noise.fit(x_tr_noisy, mnist_tr_labels)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    models_with_noise[train_noise] = mlp_noise\n",
    "    \n",
    "    # Test su dati puliti\n",
    "    clean_acc = mlp_noise.score(x_te, mnist_te_labels)\n",
    "    print(f\"Accuratezza su test set pulito: {clean_acc:.4f}\")\n",
    "    print(f\"Tempo di training: {training_time:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badae218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test dei modelli su dati rumorosi...\n",
      "Training noise 0: AUC = 0.290\n",
      "Training noise 0.05: AUC = 0.279\n",
      "Training noise 0.1: AUC = 0.313\n",
      "Training noise 0.15: AUC = 0.326\n",
      "Training noise 0.2: AUC = 0.330\n"
     ]
    }
   ],
   "source": [
    "# Test dei modelli su diversi livelli di rumore nel test set\n",
    "test_noise_levels = np.arange(0, 0.4, 0.05)\n",
    "results_noise_training = {}\n",
    "\n",
    "print(\"\\nTest dei modelli su dati rumorosi...\")\n",
    "for train_noise, model in models_with_noise.items():\n",
    "    accuracies = []\n",
    "    \n",
    "    for test_noise in test_noise_levels:\n",
    "        x_te_noisy = add_gaussian_noise(x_te_subset, test_noise)\n",
    "        acc = model.score(x_te_noisy, y_te_subset)\n",
    "        accuracies.append(acc)\n",
    "    \n",
    "    results_noise_training[train_noise] = accuracies\n",
    "    print(f\"Training noise {train_noise}: AUC = {np.trapz(accuracies, test_noise_levels):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf75176a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizzazione curve psicometriche con diversi livelli di rumore nel training\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(training_noise_levels)))\n",
    "\n",
    "# Grafico 1: Curve psicometriche\n",
    "for i, (train_noise, accuracies) in enumerate(results_noise_training.items()):\n",
    "    ax1.plot(test_noise_levels, accuracies, 'o-', \n",
    "           label=f'Training noise σ = {train_noise}',\n",
    "           color=colors[i], linewidth=2, markersize=6)\n",
    "\n",
    "ax1.set_xlabel('Deviazione standard del rumore (test)', fontsize=12)\n",
    "ax1.set_ylabel('Accuratezza', fontsize=12)\n",
    "ax1.set_title('Effetto del rumore nel training sulla robustezza', fontsize=14)\n",
    "ax1.legend(loc='upper right')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim(0, 1.05)\n",
    "\n",
    "# Grafico 2: Analisi quantitativa del miglioramento\n",
    "auc_scores = {}\n",
    "for train_noise, accuracies in results_noise_training.items():\n",
    "    auc = np.trapz(accuracies, test_noise_levels)\n",
    "    auc_scores[train_noise] = auc\n",
    "\n",
    "train_noises = list(auc_scores.keys())\n",
    "aucs = list(auc_scores.values())\n",
    "\n",
    "ax2.plot(train_noises, aucs, 'o-', linewidth=3, markersize=10, color='darkred')\n",
    "ax2.set_xlabel('Rumore nel training (σ)', fontsize=12)\n",
    "ax2.set_ylabel('AUC (Area Under Curve)', fontsize=12)\n",
    "ax2.set_title('Area sotto la curva vs Rumore nel training', fontsize=14)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Identifico il miglior livello\n",
    "best_noise = max(auc_scores, key=auc_scores.get)\n",
    "best_auc = auc_scores[best_noise]\n",
    "ax2.scatter(best_noise, best_auc, s=200, color='gold', zorder=5)\n",
    "ax2.annotate(f'Ottimo: σ={best_noise}\\nAUC={best_auc:.3f}', \n",
    "           xy=(best_noise, best_auc),\n",
    "           xytext=(best_noise + 0.05, best_auc - 0.5),\n",
    "           arrowprops=dict(arrowstyle='->', color='gold'),\n",
    "           fontsize=11, bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nMiglior livello di rumore nel training: σ = {best_noise}\")\n",
    "print(f\"Miglioramento rispetto al modello senza rumore: {(best_auc - auc_scores[0])/auc_scores[0]*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d111d5",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Punto Bonus: Estensione con FashionMNIST\n",
    "\n",
    "Replichiamo alcuni degli esperimenti precedenti utilizzando il dataset FashionMNIST, che presenta maggiore complessità."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f815534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricamento FashionMNIST...\n"
     ]
    }
   ],
   "source": [
    "# Caricamento FashionMNIST\n",
    "print(\"Caricamento FashionMNIST...\")\n",
    "fashion_tr = FashionMNIST(root=\"./data\", train=True, download=True)\n",
    "fashion_te = FashionMNIST(root=\"./data\", train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bed0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FashionMNIST caricato: 60000 train, 10000 test\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing FashionMNIST\n",
    "fashion_tr_data, fashion_tr_labels = fashion_tr.data.numpy(), fashion_tr.targets.numpy()\n",
    "fashion_te_data, fashion_te_labels = fashion_te.data.numpy(), fashion_te.targets.numpy()\n",
    "\n",
    "x_fashion_tr = fashion_tr_data.reshape(60000, 28 * 28) / 255.0\n",
    "x_fashion_te = fashion_te_data.reshape(10000, 28 * 28) / 255.0\n",
    "\n",
    "# Nomi delle classi\n",
    "fashion_classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "                  'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "print(f\"FashionMNIST caricato: {x_fashion_tr.shape[0]} train, {x_fashion_te.shape[0]} test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232d1f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizzazione esempi FashionMNIST\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(10):\n",
    "    idx = np.where(fashion_tr_labels == i)[0][0]\n",
    "    axes[i].imshow(fashion_tr_data[idx], cmap='gray')\n",
    "    axes[i].set_title(f'{i}: {fashion_classes[i]}', fontsize=12)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Esempi dal dataset FashionMNIST', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ad4cde",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_mlp_config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Training MLP su FashionMNIST con stessa architettura ottimale\u001b[39;00m\n\u001b[32m      2\u001b[39m mlp_fashion = MLPClassifier(\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     hidden_layer_sizes=\u001b[43mbest_mlp_config\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mhidden_layers\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m      4\u001b[39m     learning_rate_init=best_mlp_config[\u001b[33m'\u001b[39m\u001b[33mlearning_rate\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m      5\u001b[39m     max_iter=\u001b[32m100\u001b[39m,\n\u001b[32m      6\u001b[39m     random_state=\u001b[32m42\u001b[39m,\n\u001b[32m      7\u001b[39m     early_stopping=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m      8\u001b[39m     validation_fraction=\u001b[32m0.1\u001b[39m\n\u001b[32m      9\u001b[39m )\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining MLP su FashionMNIST con architettura: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_mlp_config[\u001b[33m'\u001b[39m\u001b[33mconfig_name\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m start_time = time.time()\n",
      "\u001b[31mNameError\u001b[39m: name 'best_mlp_config' is not defined"
     ]
    }
   ],
   "source": [
    "# Training MLP su FashionMNIST con stessa architettura ottimale\n",
    "mlp_fashion = MLPClassifier(\n",
    "    hidden_layer_sizes=best_mlp_config['hidden_layers'],\n",
    "    learning_rate_init=best_mlp_config['learning_rate'],\n",
    "    max_iter=100,\n",
    "    random_state=42,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.1\n",
    ")\n",
    "\n",
    "print(f\"Training MLP su FashionMNIST con architettura: {best_mlp_config['config_name']}\")\n",
    "start_time = time.time()\n",
    "mlp_fashion.fit(x_fashion_tr, fashion_tr_labels)\n",
    "fashion_training_time = time.time() - start_time\n",
    "\n",
    "fashion_train_acc = mlp_fashion.score(x_fashion_tr, fashion_tr_labels)\n",
    "fashion_test_acc = mlp_fashion.score(x_fashion_te, fashion_te_labels)\n",
    "\n",
    "print(f\"Training time: {fashion_training_time:.1f}s\")\n",
    "print(f\"Train accuracy: {fashion_train_acc:.4f}\")\n",
    "print(f\"Test accuracy: {fashion_test_acc:.4f}\")\n",
    "print(f\"Overfitting: {fashion_train_acc - fashion_test_acc:+.4f}\")\n",
    "\n",
    "# Confronto con MNIST\n",
    "mnist_test_acc = mlp_best.score(x_te, mnist_te_labels)\n",
    "print(f\"\\nConfronto con MNIST:\")\n",
    "print(f\"MNIST test accuracy: {mnist_test_acc:.4f}\")\n",
    "print(f\"FashionMNIST test accuracy: {fashion_test_acc:.4f}\")\n",
    "print(f\"Differenza: {mnist_test_acc - fashion_test_acc:+.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83d7bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curve psicometriche comparative MNIST vs FashionMNIST\n",
    "noise_levels_comp = np.arange(0, 0.3, 0.05)\n",
    "acc_mnist = []\n",
    "acc_fashion = []\n",
    "\n",
    "# Subset per velocità\n",
    "x_fashion_te_subset = x_fashion_te[:2000]\n",
    "y_fashion_te_subset = fashion_te_labels[:2000]\n",
    "\n",
    "print(\"Calcolo curve psicometriche comparative...\")\n",
    "for noise_std in noise_levels_comp:\n",
    "    # MNIST\n",
    "    x_noisy_mnist = add_gaussian_noise(x_te_subset, noise_std)\n",
    "    acc_mnist.append(mlp_best.score(x_noisy_mnist, y_te_subset))\n",
    "    \n",
    "    # FashionMNIST\n",
    "    x_noisy_fashion = add_gaussian_noise(x_fashion_te_subset, noise_std)\n",
    "    acc_fashion.append(mlp_fashion.score(x_noisy_fashion, y_fashion_te_subset))\n",
    "    \n",
    "    print(f\"Noise {noise_std:.2f}: MNIST {acc_mnist[-1]:.3f}, Fashion {acc_fashion[-1]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e5eab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizzazione comparativa finale\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Grafico 1: Curve psicometriche comparative\n",
    "ax1.plot(noise_levels_comp, acc_mnist, 'o-', label='MNIST', \n",
    "         linewidth=3, markersize=8, color='blue')\n",
    "ax1.plot(noise_levels_comp, acc_fashion, 's-', label='FashionMNIST', \n",
    "         linewidth=3, markersize=8, color='red')\n",
    "ax1.set_xlabel('Deviazione standard del rumore', fontsize=12)\n",
    "ax1.set_ylabel('Accuratezza', fontsize=12)\n",
    "ax1.set_title('Confronto robustezza al rumore:\\nMNIST vs FashionMNIST', fontsize=14)\n",
    "ax1.legend(fontsize=12)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim(0, 1.05)\n",
    "\n",
    "# Grafico 2: Matrice di confusione FashionMNIST\n",
    "y_pred_fashion = mlp_fashion.predict(x_fashion_te)\n",
    "cm_fashion = metrics.confusion_matrix(fashion_te_labels, y_pred_fashion)\n",
    "\n",
    "im = ax2.imshow(cm_fashion, cmap='Blues')\n",
    "ax2.set_xticks(range(10))\n",
    "ax2.set_yticks(range(10))\n",
    "ax2.set_xticklabels([f'{i}' for i in range(10)])\n",
    "ax2.set_yticklabels([f'{i}: {fashion_classes[i][:7]}' for i in range(10)], fontsize=10)\n",
    "ax2.set_xlabel('Predetto', fontsize=12)\n",
    "ax2.set_ylabel('Vero', fontsize=12)\n",
    "ax2.set_title('Matrice di Confusione\\nFashionMNIST', fontsize=14)\n",
    "\n",
    "# Grafico 3: Confronto accuratezze per classe\n",
    "fashion_class_accs = []\n",
    "mnist_class_accs = []\n",
    "\n",
    "for digit in range(10):\n",
    "    # FashionMNIST\n",
    "    mask_f = fashion_te_labels == digit\n",
    "    acc_f = np.sum((y_pred_fashion == fashion_te_labels) & mask_f) / np.sum(mask_f)\n",
    "    fashion_class_accs.append(acc_f)\n",
    "    \n",
    "    # MNIST\n",
    "    mask_m = mnist_te_labels == digit\n",
    "    acc_m = np.sum((y_pred == mnist_te_labels) & mask_m) / np.sum(mask_m)\n",
    "    mnist_class_accs.append(acc_m)\n",
    "\n",
    "x_pos = np.arange(10)\n",
    "width = 0.35\n",
    "\n",
    "ax3.bar(x_pos - width/2, mnist_class_accs, width, label='MNIST', alpha=0.8, color='blue')\n",
    "ax3.bar(x_pos + width/2, fashion_class_accs, width, label='FashionMNIST', alpha=0.8, color='red')\n",
    "ax3.set_xlabel('Classe', fontsize=12)\n",
    "ax3.set_ylabel('Accuratezza per classe', fontsize=12)\n",
    "ax3.set_title('Accuratezza per classe:\\nMNIST vs FashionMNIST', fontsize=14)\n",
    "ax3.set_xticks(x_pos)\n",
    "ax3.set_xticklabels([f'{i}' for i in range(10)])\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Grafico 4: Confronto errori più frequenti FashionMNIST\n",
    "fashion_confusion_pairs = []\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        if i != j and cm_fashion[i, j] > 0:\n",
    "            fashion_confusion_pairs.append({\n",
    "                'true_class': fashion_classes[i],\n",
    "                'pred_class': fashion_classes[j],\n",
    "                'count': cm_fashion[i, j]\n",
    "            })\n",
    "\n",
    "df_fashion_confusion = pd.DataFrame(fashion_confusion_pairs)\n",
    "top_fashion_errors = df_fashion_confusion.nlargest(8, 'count')\n",
    "\n",
    "y_pos = np.arange(len(top_fashion_errors))\n",
    "ax4.barh(y_pos, top_fashion_errors['count'], color='coral', alpha=0.8)\n",
    "ax4.set_yticks(y_pos)\n",
    "ax4.set_yticklabels([f\"{row['true_class'][:6]} → {row['pred_class'][:6]}\" \n",
    "                    for _, row in top_fashion_errors.iterrows()], fontsize=10)\n",
    "ax4.set_xlabel('Numero di errori', fontsize=12)\n",
    "ax4.set_title('Top 8 errori più frequenti\\nFashionMNIST', fontsize=14)\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50a916e",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Conclusioni\n",
    "\n",
    "### Riepilogo dei risultati principali:\n",
    "\n",
    "[risultati da implementare]\n",
    "\n",
    "1. **Effetto degli iperparametri (Punto A):**\n",
    "   - [analisi basata sui risultati numerici]\n",
    "\n",
    "2. **Cifre più difficili (Punto B):**\n",
    "   - [analisi pattern errori specifici]\n",
    "\n",
    "3. **Robustezza al rumore (Punto C):**\n",
    "   - [confronto degradazione MLP vs CNN]\n",
    "\n",
    "4. **Effetto dei dati di training (Punto D):**\n",
    "   - [analisi prestazioni con dataset ridotto]\n",
    "\n",
    "5. **Training con rumore (Punto E):**\n",
    "   - [valutazione miglioramenti robustezza]\n",
    "\n",
    "6. **FashionMNIST (Bonus):**\n",
    "   - [confronto complessità dataset]\n",
    "\n",
    "### Implicazioni pratiche:\n",
    "\n",
    "[raccomandazioni basate sui risultati]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c4f72b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RIEPILOGO FINALE DEL PROGETTO\n",
      "============================================================\n",
      "\n",
      "Punto A - Analisi Iperparametri:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mlp_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m60\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mPunto A - Analisi Iperparametri:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  • Esperimenti MLP: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[43mmlp_results\u001b[49m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  • Esperimenti CNN: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(cnn_results)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  • Miglior MLP: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_mlp_config[\u001b[33m'\u001b[39m\u001b[33mconfig_name\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m -> Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_mlp_config[\u001b[33m'\u001b[39m\u001b[33mtest_accuracy\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'mlp_results' is not defined"
     ]
    }
   ],
   "source": [
    "# Statistiche finali del progetto\n",
    "print(\"=\"*60)\n",
    "print(\"RIEPILOGO FINALE DEL PROGETTO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nPunto A - Analisi Iperparametri:\")\n",
    "print(f\"  • Esperimenti MLP: {len(mlp_results)}\")\n",
    "print(f\"  • Esperimenti CNN: {len(cnn_results)}\")\n",
    "print(f\"  • Miglior MLP: {best_mlp_config['config_name']} -> Acc: {best_mlp_config['test_accuracy']:.4f}\")\n",
    "print(f\"  • Miglior CNN: {best_cnn_config['config_name']} -> Acc: {best_cnn_config['test_accuracy']:.4f}\")\n",
    "\n",
    "print(f\"\\nPunto B - Analisi Errori:\")\n",
    "print(f\"  • Cifra più difficile: {df_errors_sorted.iloc[0]['digit']} (Error rate: {df_errors_sorted.iloc[0]['error_rate']:.3f})\")\n",
    "print(f\"  • Cifra più facile: {df_errors_sorted.iloc[-1]['digit']} (Error rate: {df_errors_sorted.iloc[-1]['error_rate']:.3f})\")\n",
    "print(f\"  • Confusione più frequente: {df_confusion_sorted.iloc[0]['true_digit']} → {df_confusion_sorted.iloc[0]['predicted_digit']} ({df_confusion_sorted.iloc[0]['count']} errori)\")\n",
    "\n",
    "print(f\"\\nPunto C - Robustezza al Rumore:\")\n",
    "print(f\"  • Livelli di rumore testati: {len(noise_levels)}\")\n",
    "print(f\"  • Accuratezza senza rumore MLP: {accuracies_mlp[0]:.4f}\")\n",
    "print(f\"  • Accuratezza senza rumore CNN: {accuracies_cnn[0]:.4f}\")\n",
    "\n",
    "print(f\"\\nPunto D - Riduzione Dati:\")\n",
    "print(f\"  • Accuratezza con 100% dati: {df_reduction[df_reduction['percentage']==100]['test_accuracy'].iloc[0]:.4f}\")\n",
    "print(f\"  • Accuratezza con 10% dati: {df_reduction[df_reduction['percentage']==10]['test_accuracy'].iloc[0]:.4f}\")\n",
    "\n",
    "print(f\"\\nPunto E - Training con Rumore:\")\n",
    "print(f\"  • Livelli testati: {len(training_noise_levels)}\")\n",
    "print(f\"  • Miglior configurazione: σ = {best_noise}\")\n",
    "\n",
    "print(f\"\\nBonus - FashionMNIST:\")\n",
    "print(f\"  • Accuratezza MNIST: {mnist_test_acc:.4f}\")\n",
    "print(f\"  • Accuratezza FashionMNIST: {fashion_test_acc:.4f}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"PROGETTO COMPLETATO CON SUCCESSO!\")\n",
    "print(\"Tutti i 5 punti + bonus implementati e analizzati.\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Mini Progetto IA",
   "language": "python",
   "name": "mini-progetto-ia"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
