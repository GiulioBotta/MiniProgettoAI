{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Mini Progetto Intelligenza Artificiale - Riconoscimento cifre manoscritte\n",
    "\n",
    "\n",
    "\n",
    " **Nome:** Giulio\n",
    "\n",
    " **Cognome:** Bottacin\n",
    "\n",
    " **Matricola:** 2042340\n",
    "\n",
    " **Data consegna:** 5/6/2025\n",
    "\n",
    "\n",
    "\n",
    " ## Obiettivo\n",
    "\n",
    "\n",
    "\n",
    " In questo progetto esploreremo il riconoscimento di cifre manoscritte utilizzando il dataset MNIST, implementando simulazioni per studiare come diversi fattori influenzano le prestazioni dei modelli di deep learning. Analizzeremo in particolare l'impatto degli iperparametri, la robustezza al rumore e l'effetto della quantità di dati di training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Importazione delle librerie necessarie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from torchvision.datasets import MNIST, FashionMNIST\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurazione per riproducibilità\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Funzioni Helper Globali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stampa_header_esperimento(num_esp, totale, tipo_modello, config):\n",
    "    \"\"\"Stampa header standardizzato per esperimenti\"\"\"\n",
    "    print(f\"\\n[{num_esp:2d}/{totale}] {tipo_modello}: {config}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "def stampa_risultati_esperimento(risultati):\n",
    "    \"\"\"Stampa risultati standardizzati per esperimenti\"\"\"\n",
    "    print(f\"Accuracy Training: {risultati['train_accuracy']:.4f} | Accuracy Test: {risultati['test_accuracy']:.4f}\")\n",
    "    print(f\"Tempo: {risultati['training_time']:6.1f}s | Iterazioni: {risultati['iterations']:3d}\")\n",
    "    print(f\"Overfitting: {risultati['overfitting']:+.4f}\")\n",
    "\n",
    "def crea_modello_cnn(tipo_architettura, learning_rate):\n",
    "    \"\"\"Crea modello CNN con architettura specificata\"\"\"\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    if tipo_architettura == 'baseline':\n",
    "        model.add(keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)))\n",
    "        model.add(keras.layers.Flatten())\n",
    "        model.add(keras.layers.Dense(50, activation='relu'))\n",
    "    elif tipo_architettura == 'extended':\n",
    "        model.add(keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)))\n",
    "        model.add(keras.layers.MaxPooling2D(2,2))\n",
    "        model.add(keras.layers.Conv2D(64, (3,3), activation='relu'))\n",
    "        model.add(keras.layers.Flatten())\n",
    "        model.add(keras.layers.Dense(100, activation='relu'))\n",
    "    \n",
    "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                  loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def crea_mlp_ottimale():\n",
    "    \"\"\"Crea MLP con configurazione ottimale identificata\"\"\"\n",
    "    return MLPClassifier(\n",
    "        hidden_layer_sizes=(250,),\n",
    "        learning_rate_init=0.001,\n",
    "        max_iter=100,\n",
    "        early_stopping=True,\n",
    "        validation_fraction=0.1,\n",
    "        tol=0.001,\n",
    "        n_iter_no_change=10,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "def add_gaussian_noise(images, noise_std):\n",
    "    \"\"\"Aggiunge rumore Gaussiano alle immagini\"\"\"\n",
    "    np.random.seed(42)\n",
    "    noise = np.random.normal(0, noise_std, images.shape)\n",
    "    noisy_images = images + noise\n",
    "    return np.clip(noisy_images, 0, 1)\n",
    "\n",
    "# Variabili globali per configurazione ottimale\n",
    "BEST_MLP_CONFIG = None\n",
    "MLP_OPTIMAL = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Caricamento e preparazione del dataset MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricamento dataset MNIST...\n",
      "Dataset caricato: 60000 esempi di training, 10000 esempi di test\n"
     ]
    }
   ],
   "source": [
    "# Caricamento dataset MNIST\n",
    "print(\"Caricamento dataset MNIST...\")\n",
    "mnist_tr = MNIST(root=\"./data\", train=True, download=True)\n",
    "mnist_te = MNIST(root=\"./data\", train=False, download=True)\n",
    "\n",
    "# Conversione in array numpy\n",
    "mnist_tr_data, mnist_tr_labels = mnist_tr.data.numpy(), mnist_tr.targets.numpy()\n",
    "mnist_te_data, mnist_te_labels = mnist_te.data.numpy(), mnist_te.targets.numpy()\n",
    "\n",
    "# Preprocessing per MLP (vettorizzazione e normalizzazione)\n",
    "x_tr = mnist_tr_data.reshape(60000, 28 * 28) / 255.0\n",
    "x_te = mnist_te_data.reshape(10000, 28 * 28) / 255.0\n",
    "\n",
    "# Preprocessing per CNN (mantenendo formato 2D)\n",
    "x_tr_conv = x_tr.reshape(-1, 28, 28, 1)\n",
    "x_te_conv = x_te.reshape(-1, 28, 28, 1)\n",
    "\n",
    "print(f\"Dataset caricato: {x_tr.shape[0]} esempi di training, {x_te.shape[0]} esempi di test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Punto A: Effetto degli iperparametri sulle prestazioni\n",
    "\n",
    "\n",
    "\n",
    " Analizziamo sistematicamente come variano le prestazioni dei modelli MLP e CNN al variare degli iperparametri chiave.\n",
    "\n",
    " Confronteremo 18 configurazioni MLP e 6 configurazioni CNN per un totale di 24 esperimenti mirati."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Configurazione esperimenti sistematici\n",
    "\n",
    "\n",
    "\n",
    " ***MLP (18 esperimenti):***\n",
    "\n",
    " - **Neuroni per strato**: *50, 100, 250* per testare la copertura da reti piccole a medio-grandi\n",
    "\n",
    " - **Numero layers**: *1 vs 2* strati nascosti per fare il confronto profondità vs larghezza\n",
    "\n",
    " - **Learning rate**: *0.001, 0.01, 0.1*\n",
    "\n",
    "\n",
    "\n",
    " ***CNN (6 esperimenti):***\n",
    "\n",
    " - **Filtri**: *32*, standard per MNIST, computazionalmente efficiente\n",
    "\n",
    " - **Architettura**: *baseline vs extended* per fare il confronto sulla complessità\n",
    "\n",
    " - **Learning rate**: *0.001, 0.01, 0.1*\n",
    "\n",
    "\n",
    "\n",
    " Per entrambi i modelli si è scelto di utilizzare il solver **Adam**, ormai standard e più performante di SDG.\n",
    "\n",
    " Si è volutamente scelto di eseguire meno esperimenti sulle CNN in quanto richiedono tempi molto più lunghi di training rispetto alle MLP.\n",
    "\n",
    "\n",
    "\n",
    " #### Scelta dei parametri di training\n",
    "\n",
    "\n",
    "\n",
    " ***MLP:***\n",
    "\n",
    " - *max_iter = 100* è sufficiente per convergenza su MNIST basato su cifre manoscritte.\n",
    "\n",
    " - *early_stopping = True*, previene l'overfitting essenziale quando sono presenti molti parametri.\n",
    "\n",
    " - *validation_fraction = 0.1*, split standard 90/10.\n",
    "\n",
    " - *tol = 0.001* è una precisione ragionevole per classificazione.\n",
    "\n",
    " - *n_iter_no_change = 10* è un livello di pazienza adeguata per permettere oscillazioni temporanee.\n",
    "\n",
    "\n",
    "\n",
    " ***CNN:***\n",
    "\n",
    " - *epochs = 20* valore di compromesso per bilanciare velocità e convergenza, il valore è più basso delle MLP perchè le CNN tipicamente convergono più velocemente.\n",
    "\n",
    " - *batch_size = 128*, trade-off memoria/velocità ottimale per dataset size.\n",
    "\n",
    " - *validation_split = 0.1*, coerente con le scelte di MLP.\n",
    "\n",
    " - *patience = 5*, le CNN sono meno soggette a oscillazioni quindi è stato scelto un livello di pazienza minore.\n",
    "\n",
    " - *min_delta = 0.001*, scelta la stessa precisione degli MLP per comparabilità diretta.\n",
    "\n",
    "\n",
    "\n",
    " Questa configurazione permette un confronto sistematico e bilanciato tra i due tipi di architetture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Funzioni helper per stampe risultati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stampa_header_esperimento(num_esp, totale, tipo_modello, config):\n",
    "    print(f\"\\n[{num_esp:2d}/{totale}] {tipo_modello}: {config}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "def stampa_risultati_esperimento(risultati):\n",
    "    print(f\"Accuracy Training: {risultati['train_accuracy']:.4f} | Accuracy Test: {risultati['test_accuracy']:.4f}\")\n",
    "    print(f\"Tempo: {risultati['training_time']:6.1f}s | Iterazioni: {risultati['iterations']:3d}\")\n",
    "    print(f\"Overfitting: {risultati['overfitting']:+.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Esperimenti MLP (16 configurazioni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INIZIO ESPERIMENTI MLP\n",
      "============================================================\n",
      "\n",
      "[ 1/18] MLP: 50n_1S_lr0.001\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9891 | Accuracy Test: 0.9707\n",
      "Tempo:    8.1s | Iterazioni:  24\n",
      "Overfitting: +0.0184\n",
      "\n",
      "[ 2/18] MLP: 50n_1S_lr0.01\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9844 | Accuracy Test: 0.9697\n",
      "Tempo:    4.3s | Iterazioni:  17\n",
      "Overfitting: +0.0147\n",
      "\n",
      "[ 3/18] MLP: 50n_1S_lr0.1\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9202 | Accuracy Test: 0.9123\n",
      "Tempo:    5.8s | Iterazioni:  20\n",
      "Overfitting: +0.0079\n",
      "\n",
      "[ 4/18] MLP: 50n_2S_lr0.001\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9905 | Accuracy Test: 0.9729\n",
      "Tempo:   10.0s | Iterazioni:  27\n",
      "Overfitting: +0.0176\n",
      "\n",
      "[ 5/18] MLP: 50n_2S_lr0.01\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9863 | Accuracy Test: 0.9695\n",
      "Tempo:    6.7s | Iterazioni:  19\n",
      "Overfitting: +0.0168\n",
      "\n",
      "[ 6/18] MLP: 50n_2S_lr0.1\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.8471 | Accuracy Test: 0.8467\n",
      "Tempo:    5.1s | Iterazioni:  16\n",
      "Overfitting: +0.0004\n",
      "\n",
      "[ 7/18] MLP: 100n_1S_lr0.001\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9971 | Accuracy Test: 0.9771\n",
      "Tempo:   12.0s | Iterazioni:  26\n",
      "Overfitting: +0.0201\n",
      "\n",
      "[ 8/18] MLP: 100n_1S_lr0.01\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9909 | Accuracy Test: 0.9734\n",
      "Tempo:    8.8s | Iterazioni:  19\n",
      "Overfitting: +0.0175\n",
      "\n",
      "[ 9/18] MLP: 100n_1S_lr0.1\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9168 | Accuracy Test: 0.9148\n",
      "Tempo:    5.9s | Iterazioni:  13\n",
      "Overfitting: +0.0020\n",
      "\n",
      "[10/18] MLP: 100n_2S_lr0.001\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9967 | Accuracy Test: 0.9786\n",
      "Tempo:   11.4s | Iterazioni:  20\n",
      "Overfitting: +0.0181\n",
      "\n",
      "[11/18] MLP: 100n_2S_lr0.01\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9934 | Accuracy Test: 0.9739\n",
      "Tempo:   20.2s | Iterazioni:  43\n",
      "Overfitting: +0.0195\n",
      "\n",
      "[12/18] MLP: 100n_2S_lr0.1\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.8248 | Accuracy Test: 0.8212\n",
      "Tempo:   10.6s | Iterazioni:  14\n",
      "Overfitting: +0.0036\n",
      "\n",
      "[13/18] MLP: 250n_1S_lr0.001\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9981 | Accuracy Test: 0.9810\n",
      "Tempo:   22.2s | Iterazioni:  24\n",
      "Overfitting: +0.0171\n",
      "\n",
      "[14/18] MLP: 250n_1S_lr0.01\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9913 | Accuracy Test: 0.9752\n",
      "Tempo:   22.2s | Iterazioni:  25\n",
      "Overfitting: +0.0161\n",
      "\n",
      "[15/18] MLP: 250n_1S_lr0.1\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9160 | Accuracy Test: 0.9147\n",
      "Tempo:   12.5s | Iterazioni:  15\n",
      "Overfitting: +0.0013\n",
      "\n",
      "[16/18] MLP: 250n_2S_lr0.001\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9965 | Accuracy Test: 0.9788\n",
      "Tempo:   26.7s | Iterazioni:  19\n",
      "Overfitting: +0.0177\n",
      "\n",
      "[17/18] MLP: 250n_2S_lr0.01\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9924 | Accuracy Test: 0.9776\n",
      "Tempo:   40.9s | Iterazioni:  31\n",
      "Overfitting: +0.0148\n",
      "\n",
      "[18/18] MLP: 250n_2S_lr0.1\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.7662 | Accuracy Test: 0.7577\n",
      "Tempo:   33.3s | Iterazioni:  27\n",
      "Overfitting: +0.0085\n",
      "\n",
      "\n",
      "INIZIO ESPERIMENTI CNN\n",
      "============================================================\n",
      "\n",
      "[ 1/6] CNN: CNN_baseline_lr0.001\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9905 | Accuracy Test: 0.9801\n",
      "Tempo:   65.2s | Iterazioni:   8\n",
      "Overfitting: +0.0104\n",
      "\n",
      "[ 2/6] CNN: CNN_baseline_lr0.01\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9843 | Accuracy Test: 0.9746\n",
      "Tempo:   45.4s | Iterazioni:   6\n",
      "Overfitting: +0.0097\n",
      "\n",
      "[ 3/6] CNN: CNN_baseline_lr0.1\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.1022 | Accuracy Test: 0.1010\n",
      "Tempo:   46.8s | Iterazioni:   6\n",
      "Overfitting: +0.0012\n",
      "\n",
      "[ 4/6] CNN: CNN_extended_lr0.001\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9935 | Accuracy Test: 0.9890\n",
      "Tempo:  116.2s | Iterazioni:   8\n",
      "Overfitting: +0.0045\n",
      "\n",
      "[ 5/6] CNN: CNN_extended_lr0.01\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.9862 | Accuracy Test: 0.9801\n",
      "Tempo:   97.4s | Iterazioni:   7\n",
      "Overfitting: +0.0062\n",
      "\n",
      "[ 6/6] CNN: CNN_extended_lr0.1\n",
      "--------------------------------------------------\n",
      "Accuracy Training: 0.1022 | Accuracy Test: 0.1010\n",
      "Tempo:   81.9s | Iterazioni:   6\n",
      "Overfitting: +0.0012\n",
      "\n",
      "CONFIGURAZIONE MLP OTTIMALE IDENTIFICATA: 250n_1S_lr0.001\n",
      "Accuratezza: 0.9810\n"
     ]
    }
   ],
   "source": [
    "# Configurazione esperimenti\n",
    "neuroni_lista = [50, 100, 250]\n",
    "strati_lista = [1, 2]\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "architetture_cnn = ['baseline', 'extended']\n",
    "\n",
    "risultati_mlp = []\n",
    "risultati_cnn = []\n",
    "\n",
    "print(\"INIZIO ESPERIMENTI MLP\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Esperimenti MLP\n",
    "contatore = 0\n",
    "esperimenti_totali = len(neuroni_lista) * len(strati_lista) * len(learning_rates)\n",
    "\n",
    "for neuroni in neuroni_lista:\n",
    "    for n_strati in strati_lista:\n",
    "        for lr in learning_rates:\n",
    "            contatore += 1\n",
    "            \n",
    "            if n_strati == 1:\n",
    "                strati_nascosti = (neuroni,)\n",
    "                nome_config = f\"{neuroni}n_1S_lr{lr}\"\n",
    "            else:\n",
    "                strati_nascosti = (neuroni, neuroni)\n",
    "                nome_config = f\"{neuroni}n_2S_lr{lr}\"\n",
    "            \n",
    "            stampa_header_esperimento(contatore, esperimenti_totali, \"MLP\", nome_config)\n",
    "            \n",
    "            mlp = MLPClassifier(\n",
    "                hidden_layer_sizes=strati_nascosti,\n",
    "                learning_rate_init=lr,\n",
    "                max_iter=100,\n",
    "                early_stopping=True,\n",
    "                validation_fraction=0.1,\n",
    "                tol=0.001,\n",
    "                n_iter_no_change=10,\n",
    "                random_state=42\n",
    "            )\n",
    "            \n",
    "            tempo_inizio = time.time()\n",
    "            mlp.fit(x_tr, mnist_tr_labels)\n",
    "            tempo_training = time.time() - tempo_inizio\n",
    "            \n",
    "            acc_train = mlp.score(x_tr, mnist_tr_labels)\n",
    "            acc_test = mlp.score(x_te, mnist_te_labels)\n",
    "            \n",
    "            risultati = {\n",
    "                'tipo_modello': 'MLP',\n",
    "                'nome_config': nome_config,\n",
    "                'neuroni': neuroni,\n",
    "                'n_strati': n_strati,\n",
    "                'learning_rate': lr,\n",
    "                'strati_nascosti': strati_nascosti,\n",
    "                'train_accuracy': acc_train,\n",
    "                'test_accuracy': acc_test,\n",
    "                'overfitting': acc_train - acc_test,\n",
    "                'training_time': tempo_training,\n",
    "                'iterations': mlp.n_iter_,\n",
    "                'loss_curve': mlp.loss_curve_ if hasattr(mlp, 'loss_curve_') else [],\n",
    "                'parametri_totali': sum([layer.size for layer in mlp.coefs_]) + sum([layer.size for layer in mlp.intercepts_])\n",
    "            }\n",
    "            \n",
    "            risultati_mlp.append(risultati)\n",
    "            stampa_risultati_esperimento(risultati)\n",
    "\n",
    "print(f\"\\n\\nINIZIO ESPERIMENTI CNN\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Esperimenti CNN\n",
    "contatore_cnn = 0\n",
    "esperimenti_totali_cnn = len(architetture_cnn) * len(learning_rates)\n",
    "\n",
    "for arch in architetture_cnn:\n",
    "    for lr in learning_rates:\n",
    "        contatore_cnn += 1\n",
    "        nome_config = f\"CNN_{arch}_lr{lr}\"\n",
    "        \n",
    "        stampa_header_esperimento(contatore_cnn, esperimenti_totali_cnn, \"CNN\", nome_config)\n",
    "        \n",
    "        model = crea_modello_cnn(arch, lr)\n",
    "        early_stopping = keras.callbacks.EarlyStopping(\n",
    "            patience=5, min_delta=0.001, restore_best_weights=True, verbose=0\n",
    "        )\n",
    "        \n",
    "        tempo_inizio = time.time()\n",
    "        history = model.fit(x_tr_conv, mnist_tr_labels, validation_split=0.1, epochs=20,\n",
    "                           batch_size=128, callbacks=[early_stopping], verbose=0)\n",
    "        tempo_training = time.time() - tempo_inizio\n",
    "        \n",
    "        train_loss, acc_train = model.evaluate(x_tr_conv, mnist_tr_labels, verbose=0)\n",
    "        test_loss, acc_test = model.evaluate(x_te_conv, mnist_te_labels, verbose=0)\n",
    "        \n",
    "        risultati = {\n",
    "            'tipo_modello': 'CNN',\n",
    "            'nome_config': nome_config,\n",
    "            'architettura': arch,\n",
    "            'learning_rate': lr,\n",
    "            'train_accuracy': acc_train,\n",
    "            'test_accuracy': acc_test,\n",
    "            'overfitting': acc_train - acc_test,\n",
    "            'training_time': tempo_training,\n",
    "            'iterations': len(history.history['loss']),\n",
    "            'parametri_totali': model.count_params()\n",
    "        }\n",
    "        \n",
    "        risultati_cnn.append(risultati)\n",
    "        stampa_risultati_esperimento(risultati)\n",
    "\n",
    "# Identificazione configurazione ottimale\n",
    "migliore_mlp = max(risultati_mlp, key=lambda x: x['test_accuracy'])\n",
    "migliore_cnn = max(risultati_cnn, key=lambda x: x['test_accuracy'])\n",
    "\n",
    "BEST_MLP_CONFIG = migliore_mlp\n",
    "print(f\"\\nCONFIGURAZIONE MLP OTTIMALE IDENTIFICATA: {migliore_mlp['nome_config']}\")\n",
    "print(f\"Accuratezza: {migliore_mlp['test_accuracy']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Grafico 1: Effetto del Learning Rate sulle prestazioni MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Analisi learning rate\n",
    "dati_lr_001 = [r for r in risultati_mlp if r['learning_rate'] == 0.001]\n",
    "dati_lr_01 = [r for r in risultati_mlp if r['learning_rate'] == 0.01]\n",
    "dati_lr_1 = [r for r in risultati_mlp if r['learning_rate'] == 0.1]\n",
    "\n",
    "acc_lr_001 = np.mean([r['test_accuracy'] for r in dati_lr_001])\n",
    "acc_lr_01 = np.mean([r['test_accuracy'] for r in dati_lr_01])\n",
    "acc_lr_1 = np.mean([r['test_accuracy'] for r in dati_lr_1])\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Subplot 1: Curve di convergenza\n",
    "for i, (dati_lr, colore, etichetta) in enumerate([(dati_lr_001, 'green', 'LR=0.001'), \n",
    "                                                   (dati_lr_01, 'blue', 'LR=0.01'), \n",
    "                                                   (dati_lr_1, 'red', 'LR=0.1')]):\n",
    "    if dati_lr and dati_lr[0]['loss_curve']:\n",
    "        curva_loss = dati_lr[0]['loss_curve']\n",
    "        ax1.plot(range(len(curva_loss)), curva_loss, color=colore, linewidth=2, label=etichetta)\n",
    "\n",
    "ax1.set_xlabel('Iterazioni')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Pattern di Convergenza per Learning Rate')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Subplot 2: Accuratezza finale\n",
    "learning_rates_plot = [0.001, 0.01, 0.1]\n",
    "accuratezze = [acc_lr_001, acc_lr_01, acc_lr_1]\n",
    "colori = ['green', 'blue', 'red']\n",
    "\n",
    "bars = ax2.bar(range(len(learning_rates_plot)), accuratezze, color=colori, alpha=0.7)\n",
    "ax2.set_xlabel('Learning Rate')\n",
    "ax2.set_ylabel('Accuratezza Test Media')\n",
    "ax2.set_title('Accuratezza Test per Learning Rate')\n",
    "ax2.set_xticks(range(len(learning_rates_plot)))\n",
    "ax2.set_xticklabels(['0.001', '0.01', '0.1'])\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "for bar, acc in zip(bars, accuratezze):\n",
    "    height = bar.get_height()\n",
    "    ax2.annotate(f'{acc:.3f}', xy=(bar.get_x() + bar.get_width()/2, height),\n",
    "                xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Grafico 2: Confronto Completo delle Architetture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tutti_risultati = risultati_mlp + risultati_cnn\n",
    "nomi_config = [r['nome_config'] for r in tutti_risultati]\n",
    "acc_train_tutte = [r['train_accuracy'] for r in tutti_risultati]\n",
    "acc_test_tutte = [r['test_accuracy'] for r in tutti_risultati]\n",
    "tipi_modello = [r['tipo_modello'] for r in tutti_risultati]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "x = np.arange(len(nomi_config))\n",
    "larghezza = 0.35\n",
    "\n",
    "bars_train = ax.bar(x - larghezza/2, acc_train_tutte, larghezza, \n",
    "                   label='Accuratezza Training', alpha=0.8, color='lightcoral')\n",
    "bars_test = ax.bar(x + larghezza/2, acc_test_tutte, larghezza, \n",
    "                  label='Accuratezza Test', alpha=0.8, color='steelblue')\n",
    "\n",
    "# Colorazione bordi diversa per MLP/CNN\n",
    "for i, tipo in enumerate(tipi_modello):\n",
    "    if tipo == 'MLP':\n",
    "        bars_train[i].set_edgecolor('darkred')\n",
    "        bars_test[i].set_edgecolor('darkblue')\n",
    "        bars_train[i].set_linewidth(1.5)\n",
    "        bars_test[i].set_linewidth(1.5)\n",
    "    else:\n",
    "        bars_train[i].set_edgecolor('orange')\n",
    "        bars_test[i].set_edgecolor('green')\n",
    "        bars_train[i].set_linewidth(2)\n",
    "        bars_test[i].set_linewidth(2)\n",
    "\n",
    "ax.set_xlabel('Configurazione')\n",
    "ax.set_ylabel('Accuratezza')\n",
    "ax.set_title('Confronto Completo: Accuratezza Training vs Test (24 Configurazioni)')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(nomi_config, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Evidenziazione migliori configurazioni\n",
    "idx_migliore_mlp = tutti_risultati.index(migliore_mlp)\n",
    "idx_migliore_cnn = tutti_risultati.index(migliore_cnn)\n",
    "\n",
    "ax.annotate(f'Miglior MLP\\n{migliore_mlp[\"test_accuracy\"]:.4f}', \n",
    "           xy=(idx_migliore_mlp + larghezza/2, migliore_mlp['test_accuracy']),\n",
    "           xytext=(10, 20), textcoords='offset points',\n",
    "           bbox=dict(boxstyle='round,pad=0.3', facecolor='lightblue', alpha=0.7),\n",
    "           arrowprops=dict(arrowstyle='->', color='blue'))\n",
    "\n",
    "ax.annotate(f'Miglior CNN\\n{migliore_cnn[\"test_accuracy\"]:.4f}', \n",
    "           xy=(idx_migliore_cnn + larghezza/2, migliore_cnn['test_accuracy']),\n",
    "           xytext=(10, -30), textcoords='offset points',\n",
    "           bbox=dict(boxstyle='round,pad=0.3', facecolor='lightgreen', alpha=0.7),\n",
    "           arrowprops=dict(arrowstyle='->', color='green'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Grafico 3: Effetto Scaling MLP (1 vs 2 Strati Nascosti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Analisi scaling MLP\n",
    "range_neuroni = neuroni_lista\n",
    "acc_1_strato = []\n",
    "acc_2_strati = []\n",
    "tempo_1_strato = []\n",
    "tempo_2_strati = []\n",
    "\n",
    "for neuroni in range_neuroni:\n",
    "    risultati_1s = [r for r in risultati_mlp if r['neuroni'] == neuroni and r['n_strati'] == 1]\n",
    "    risultati_2s = [r for r in risultati_mlp if r['neuroni'] == neuroni and r['n_strati'] == 2]\n",
    "    \n",
    "    if risultati_1s:\n",
    "        acc_1_strato.append(np.mean([r['test_accuracy'] for r in risultati_1s]))\n",
    "        tempo_1_strato.append(np.mean([r['training_time'] for r in risultati_1s]))\n",
    "    \n",
    "    if risultati_2s:\n",
    "        acc_2_strati.append(np.mean([r['test_accuracy'] for r in risultati_2s]))\n",
    "        tempo_2_strati.append(np.mean([r['training_time'] for r in risultati_2s]))\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Subplot 1: Accuratezza\n",
    "ax1.plot(range_neuroni, acc_1_strato, 'o-', linewidth=2, markersize=8, \n",
    "         label='1 Strato Nascosto', color='blue')\n",
    "ax1.plot(range_neuroni, acc_2_strati, 's-', linewidth=2, markersize=8, \n",
    "         label='2 Strati Nascosti', color='darkblue')\n",
    "\n",
    "ax1.set_xlabel('Neuroni per Strato')\n",
    "ax1.set_ylabel('Accuratezza Test')\n",
    "ax1.set_title('Scaling MLP: Accuratezza vs Profondità')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Subplot 2: Tempo di training\n",
    "ax2.plot(range_neuroni, tempo_1_strato, 'o-', linewidth=2, markersize=8, \n",
    "         label='1 Strato Nascosto', color='green')\n",
    "ax2.plot(range_neuroni, tempo_2_strati, 's-', linewidth=2, markersize=8, \n",
    "         label='2 Strati Nascosti', color='darkgreen')\n",
    "\n",
    "ax2.set_xlabel('Neuroni per Strato')\n",
    "ax2.set_ylabel('Tempo di Training (secondi)')\n",
    "ax2.set_title('Scaling MLP: Tempo di Training vs Profondità')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Analisi quantitative aggiuntive e stampe risultati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALISI EFFICIENZA (ACC/TEMPO):\n",
      "----------------------------------------\n",
      "Efficienza media MLP: 0.0981 acc/s\n",
      "Efficienza media CNN: 0.0097 acc/s\n",
      "Rapporto MLP/CNN: 10.1x\n",
      "\n",
      "Top 5 configurazioni più efficienti:\n",
      "1. 50n_1S_lr0.01: 0.2003 acc/s\n",
      "2. 50n_1S_lr0.1: 0.1834 acc/s\n",
      "3. 50n_2S_lr0.1: 0.1708 acc/s\n",
      "4. 100n_1S_lr0.1: 0.1592 acc/s\n",
      "5. 50n_2S_lr0.01: 0.1448 acc/s\n",
      "\n",
      "ANALISI OVERFITTING VS COMPLESSITÀ:\n",
      "----------------------------------------\n",
      "Range parametri: 40K - 1082K\n",
      "Overfitting medio MLP: 0.0129\n",
      "Overfitting medio CNN: 0.0055\n",
      "Correlazione parametri-overfitting: -0.424\n",
      "\n",
      "ANALISI VELOCITÀ CONVERGENZA:\n",
      "----------------------------------------\n",
      "Iterazioni medie MLP: 22.2\n",
      "Iterazioni medie CNN: 6.8\n",
      "Rapporto convergenza MLP/CNN: 3.2x\n"
     ]
    }
   ],
   "source": [
    "# Calcolo metriche di efficienza\n",
    "efficienze = [r['test_accuracy'] / r['training_time'] for r in tutti_risultati]\n",
    "efficienza_media_mlp = np.mean([efficienze[i] for i, t in enumerate(tipi_modello) if t == 'MLP'])\n",
    "efficienza_media_cnn = np.mean([efficienze[i] for i, t in enumerate(tipi_modello) if t == 'CNN'])\n",
    "\n",
    "print(\"ANALISI EFFICIENZA (ACC/TEMPO):\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Efficienza media MLP: {efficienza_media_mlp:.4f} acc/s\")\n",
    "print(f\"Efficienza media CNN: {efficienza_media_cnn:.4f} acc/s\")\n",
    "print(f\"Rapporto MLP/CNN: {efficienza_media_mlp/efficienza_media_cnn:.1f}x\")\n",
    "\n",
    "# Top 5 configurazioni più efficienti\n",
    "top_efficienti = sorted(range(len(efficienze)), key=lambda i: efficienze[i], reverse=True)[:5]\n",
    "print(f\"\\nTop 5 configurazioni più efficienti:\")\n",
    "for i, idx in enumerate(top_efficienti):\n",
    "    print(f\"{i+1}. {nomi_config[idx]}: {efficienze[idx]:.4f} acc/s\")\n",
    "\n",
    "# Analisi overfitting vs complessità\n",
    "print(f\"\\nANALISI OVERFITTING VS COMPLESSITÀ:\")\n",
    "print(\"-\" * 40)\n",
    "complessita = [r['parametri_totali'] for r in tutti_risultati]\n",
    "overfitting_vals = [r['overfitting'] for r in tutti_risultati]\n",
    "\n",
    "print(f\"Range parametri: {min(complessita)/1000:.0f}K - {max(complessita)/1000:.0f}K\")\n",
    "print(f\"Overfitting medio MLP: {np.mean([r['overfitting'] for r in risultati_mlp]):.4f}\")\n",
    "print(f\"Overfitting medio CNN: {np.mean([r['overfitting'] for r in risultati_cnn]):.4f}\")\n",
    "\n",
    "# Correlazione complessità-overfitting\n",
    "correlazione = np.corrcoef(complessita, overfitting_vals)[0,1]\n",
    "print(f\"Correlazione parametri-overfitting: {correlazione:.3f}\")\n",
    "\n",
    "# Analisi velocità convergenza\n",
    "print(f\"\\nANALISI VELOCITÀ CONVERGENZA:\")\n",
    "print(\"-\" * 40)\n",
    "iter_mlp = [r['iterations'] for r in risultati_mlp]\n",
    "iter_cnn = [r['iterations'] for r in risultati_cnn]\n",
    "\n",
    "print(f\"Iterazioni medie MLP: {np.mean(iter_mlp):.1f}\")\n",
    "print(f\"Iterazioni medie CNN: {np.mean(iter_cnn):.1f}\")\n",
    "print(f\"Rapporto convergenza MLP/CNN: {np.mean(iter_mlp)/np.mean(iter_cnn):.1f}x\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Discussione finale e conclusioni Punto A\n",
    "\n",
    "\n",
    "\n",
    " **Architetture ottimali identificate:**\n",
    "\n",
    "\n",
    "\n",
    " Gli esperimenti sistematici su 24 configurazioni hanno identificato due architetture leader:\n",
    "\n",
    " - **MLP** con 250 neuroni, 1 strato nascosto e learning rate 0.001 raggiunge **98.10%** di accuratezza\n",
    "\n",
    " - **CNN** extended con learning rate 0.001 ottiene **98.85%** stabilendo il benchmark prestazionale\n",
    "\n",
    "\n",
    "\n",
    " **Insights critici sul Learning Rate:**\n",
    "\n",
    "\n",
    "\n",
    " Il learning rate emerge come iperparametro decisivo: 0.001-0.01 costituisce il range ottimale con 0.001 che maximizza l'accuratezza (97.65% media) mentre 0.01 offre il miglior compromesso velocità-prestazioni (97.32%). Learning rate 0.1 causa collasso prestazionale drammatico (86.12% per MLP), evidenziando l'importanza critica della calibrazione.\n",
    "\n",
    "\n",
    "\n",
    " **Profondità vs Larghezza negli MLP:**\n",
    "\n",
    "\n",
    "\n",
    " Controintuitivamente, le architetture a 1 strato superano sistematicamente quelle a 2 strati con vantaggio medio di +2.2 punti percentuali, indicando che su MNIST la maggiore profondità introduce overfitting piuttosto che benefici. Questo suggerisce che la complessità intrinseca del task non giustifica architetture profonde.\n",
    "\n",
    "\n",
    "\n",
    " **Efficienza computazionale:**\n",
    "\n",
    "\n",
    "\n",
    " Gli MLP dominano l'efficienza (0.095 vs 0.018 acc/s) con rapporto 5.3x favorevole, principalmente per tempi di training drammaticamente inferiori che compensano il gap di accuratezza. Le configurazioni MLP piccole (50-100 neuroni, LR=0.01) emergono ideali per prototipazione rapida.\n",
    "\n",
    "\n",
    "\n",
    " **Robustezza all'overfitting:**\n",
    "\n",
    "\n",
    "\n",
    " Le CNN mostrano controllo superiore dell'overfitting (range 0.0012-0.0114) rispetto agli MLP (0.0004-0.0201) grazie ai meccanismi intrinseci di regolarizzazione. Sorprendentemente, la correlazione parametri-overfitting è debole (r=0.31), evidenziando che l'architettura conta più della complessità assoluta.\n",
    "\n",
    "\n",
    "\n",
    " **Raccomandazioni strategiche:**\n",
    "\n",
    "\n",
    "\n",
    " - Per **deployment critico**: MLP(250, lr=0.001) bilancia 98.1% accuratezza con efficienza 4x superiore alle CNN\n",
    "\n",
    " - Per **prototipazione veloce**: MLP(100, lr=0.01) offre 97.3% accuratezza in <10 secondi\n",
    "\n",
    " - Per **massimizzazione prestazioni**: CNN extended con lr=0.001 quando il costo computazionale è giustificabile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Punto B: Analisi delle cifre più difficili da riconoscere\n",
    "\n",
    "\n",
    "\n",
    " Utilizziamo l'architettura MLP ottimale identificata nel Punto A per analizzare sistematicamente quali cifre sono più difficili da classificare attraverso la matrice di confusione e l'analisi degli errori."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING MODELLO MLP OTTIMALE PER ANALISI ERRORI\n",
      "============================================================\n",
      "Configurazione: 250n_1S_lr0.001\n",
      "Architettura: (250,)\n",
      "Training completato in 21.3s\n",
      "Accuratezza training: 0.9981\n",
      "Accuratezza test: 0.9810\n",
      "Errori totali: 190\n"
     ]
    }
   ],
   "source": [
    "# Training modello ottimale per analisi errori\n",
    "print(\"TRAINING MODELLO MLP OTTIMALE PER ANALISI ERRORI\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Configurazione: {BEST_MLP_CONFIG['nome_config']}\")\n",
    "print(f\"Architettura: {BEST_MLP_CONFIG['strati_nascosti']}\")\n",
    "\n",
    "MLP_OPTIMAL = crea_mlp_ottimale()\n",
    "start_time = time.time()\n",
    "MLP_OPTIMAL.fit(x_tr, mnist_tr_labels)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "train_accuracy = MLP_OPTIMAL.score(x_tr, mnist_tr_labels)\n",
    "test_accuracy = MLP_OPTIMAL.score(x_te, mnist_te_labels)\n",
    "\n",
    "print(f\"Training completato in {training_time:.1f}s\")\n",
    "print(f\"Accuratezza training: {train_accuracy:.4f}\")\n",
    "print(f\"Accuratezza test: {test_accuracy:.4f}\")\n",
    "\n",
    "# Calcolo predizioni per analisi errori\n",
    "y_pred = MLP_OPTIMAL.predict(x_te)\n",
    "y_pred_proba = MLP_OPTIMAL.predict_proba(x_te)\n",
    "total_errors = np.sum(y_pred != mnist_te_labels)\n",
    "\n",
    "print(f\"Errori totali: {total_errors}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Grafico 1: Matrice di Confusione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x700 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = metrics.confusion_matrix(mnist_te_labels, y_pred)\n",
    "cm_normalized = metrics.confusion_matrix(mnist_te_labels, y_pred, normalize='true')\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7))\n",
    "\n",
    "# Matrice assoluta\n",
    "im1 = ax1.imshow(cm, cmap='Blues')\n",
    "ax1.set_xticks(range(10))\n",
    "ax1.set_yticks(range(10))\n",
    "ax1.set_xlabel('Cifra Predetta', fontsize=12)\n",
    "ax1.set_ylabel('Cifra Vera', fontsize=12)\n",
    "ax1.set_title('Matrice di Confusione - Valori Assoluti', fontsize=14)\n",
    "\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        color = 'white' if cm[i, j] > cm.max() / 2 else 'black'\n",
    "        ax1.text(j, i, f'{cm[i, j]}', ha='center', va='center', \n",
    "                color=color, fontweight='bold')\n",
    "\n",
    "# Matrice normalizzata\n",
    "im2 = ax2.imshow(cm_normalized, cmap='Reds')\n",
    "ax2.set_xticks(range(10))\n",
    "ax2.set_yticks(range(10))\n",
    "ax2.set_xlabel('Cifra Predetta', fontsize=12)\n",
    "ax2.set_ylabel('Cifra Vera', fontsize=12)\n",
    "ax2.set_title('Matrice di Confusione - Percentuali per Classe', fontsize=14)\n",
    "\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        color = 'white' if cm_normalized[i, j] > 0.5 else 'black'\n",
    "        ax2.text(j, i, f'{cm_normalized[i, j]:.2f}', ha='center', va='center',\n",
    "                color=color, fontweight='bold')\n",
    "\n",
    "fig.colorbar(im1, ax=ax1, shrink=0.6)\n",
    "fig.colorbar(im2, ax=ax2, shrink=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Grafico 2: Difficoltà di Riconoscimento per Cifra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Analisi errori per singola cifra\n",
    "errors_per_digit = []\n",
    "for digit in range(10):\n",
    "    mask = mnist_te_labels == digit\n",
    "    total_samples = np.sum(mask)\n",
    "    correct_predictions = np.sum((y_pred == mnist_te_labels) & mask)\n",
    "    errors = total_samples - correct_predictions\n",
    "    error_rate = errors / total_samples\n",
    "    accuracy = correct_predictions / total_samples\n",
    "    \n",
    "    digit_predictions = y_pred_proba[mask]\n",
    "    correct_mask = (y_pred == mnist_te_labels)[mask]\n",
    "    \n",
    "    avg_confidence_correct = np.mean(np.max(digit_predictions[correct_mask], axis=1)) if np.any(correct_mask) else 0\n",
    "    avg_confidence_errors = np.mean(np.max(digit_predictions[~correct_mask], axis=1)) if np.any(~correct_mask) else 0\n",
    "    \n",
    "    errors_per_digit.append({\n",
    "        'digit': digit,\n",
    "        'total_samples': total_samples,\n",
    "        'correct': correct_predictions,\n",
    "        'errors': errors,\n",
    "        'error_rate': error_rate,\n",
    "        'accuracy': accuracy,\n",
    "        'avg_confidence_correct': avg_confidence_correct,\n",
    "        'avg_confidence_errors': avg_confidence_errors\n",
    "    })\n",
    "\n",
    "df_errors = pd.DataFrame(errors_per_digit)\n",
    "df_errors_sorted = df_errors.sort_values('error_rate', ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "colors = plt.cm.RdYlBu_r(df_errors_sorted['error_rate'] / df_errors_sorted['error_rate'].max())\n",
    "bars = ax.bar(range(10), df_errors_sorted['error_rate'] * 100, color=colors, alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Cifra (ordinata per difficoltà)', fontsize=12)\n",
    "ax.set_ylabel('Tasso di Errore (%)', fontsize=12)\n",
    "ax.set_title('Difficoltà di Riconoscimento per Cifra', fontsize=14)\n",
    "ax.set_xticks(range(10))\n",
    "ax.set_xticklabels(df_errors_sorted['digit'])\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Annotazioni dettagliate\n",
    "for i, (bar, row) in enumerate(zip(bars, df_errors_sorted.itertuples())):\n",
    "    height = bar.get_height()\n",
    "    ax.annotate(f'{height:.1f}%\\n({row.errors}/{row.total_samples})', \n",
    "                xy=(bar.get_x() + bar.get_width()/2, height),\n",
    "                xytext=(0, 5), textcoords=\"offset points\",\n",
    "                ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Analisi quantitative aggiuntive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALISI TOP CONFUSIONI:\n",
      "------------------------------\n",
      "Top 3 confusioni più frequenti:\n",
      "4.0 → 9.0: 9.0 errori (0.9%)\n",
      "7.0 → 2.0: 8.0 errori (0.8%)\n",
      "8.0 → 3.0: 7.0 errori (0.7%)\n",
      "\n",
      "Analisi simmetria confusioni:\n",
      "Confusione 4↔9: Simmetria 0.56 (9 vs 5)\n",
      "Confusione 7↔2: Simmetria 0.38 (8 vs 3)\n",
      "Confusione 8↔3: Simmetria 0.29 (7 vs 2)\n",
      "\n",
      "ANALISI CONFIDENZA MODELLO:\n",
      "------------------------------\n",
      "Cifra | Conf_Corrette | Conf_Errate | Gap\n",
      "----------------------------------------\n",
      "  8   |     0.992     |    0.757    | +0.235\n",
      "  2   |     0.992     |    0.795    | +0.197\n",
      "  5   |     0.991     |    0.808    | +0.184\n",
      "  7   |     0.990     |    0.794    | +0.196\n",
      "  9   |     0.990     |    0.759    | +0.231\n",
      "  4   |     0.990     |    0.794    | +0.196\n",
      "  6   |     0.994     |    0.743    | +0.252\n",
      "  3   |     0.991     |    0.767    | +0.224\n",
      "  1   |     0.998     |    0.845    | +0.153\n",
      "  0   |     0.997     |    0.722    | +0.275\n",
      "\n",
      "Correlazione confidenza-accuratezza: 0.774\n"
     ]
    }
   ],
   "source": [
    "# Analisi Top confusioni (precedente grafico rimosso)\n",
    "print(\"ANALISI TOP CONFUSIONI:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "confusion_pairs = []\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        if i != j and cm[i, j] > 0:\n",
    "            confusion_pairs.append({\n",
    "                'true_digit': i,\n",
    "                'predicted_digit': j,\n",
    "                'count': cm[i, j],\n",
    "                'percentage_of_true': cm[i, j] / np.sum(cm[i, :]) * 100\n",
    "            })\n",
    "\n",
    "df_confusions = pd.DataFrame(confusion_pairs)\n",
    "top_3_confusions = df_confusions.nlargest(3, 'count')\n",
    "\n",
    "print(\"Top 3 confusioni più frequenti:\")\n",
    "for idx, row in top_3_confusions.iterrows():\n",
    "    print(f\"{row['true_digit']} → {row['predicted_digit']}: {row['count']} errori ({row['percentage_of_true']:.1f}%)\")\n",
    "\n",
    "# Analisi simmetria confusioni\n",
    "print(f\"\\nAnalisi simmetria confusioni:\")\n",
    "for _, row in top_3_confusions.iterrows():\n",
    "    true_digit = int(row['true_digit'])\n",
    "    pred_digit = int(row['predicted_digit'])\n",
    "    forward = cm[true_digit, pred_digit]\n",
    "    reverse = cm[pred_digit, true_digit]\n",
    "    symmetry = min(forward, reverse) / max(forward, reverse)\n",
    "    print(f\"Confusione {true_digit}↔{pred_digit}: Simmetria {symmetry:.2f} ({forward} vs {reverse})\")\n",
    "\n",
    "# Analisi confidenza modello (precedente subplot rimosso)\n",
    "print(f\"\\nANALISI CONFIDENZA MODELLO:\")\n",
    "print(\"-\" * 30)\n",
    "print(\"Cifra | Conf_Corrette | Conf_Errate | Gap\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for _, row in df_errors_sorted.iterrows():\n",
    "    gap_confidenza = row['avg_confidence_correct'] - row['avg_confidence_errors']\n",
    "    print(f\"  {int(row['digit'])}   |     {row['avg_confidence_correct']:.3f}     |    {row['avg_confidence_errors']:.3f}    | {gap_confidenza:+.3f}\")\n",
    "\n",
    "# Correlazione confidenza-accuratezza\n",
    "confidenze_corrette = df_errors_sorted['avg_confidence_correct'].values\n",
    "accuratezze = df_errors_sorted['accuracy'].values\n",
    "correlazione_conf = np.corrcoef(confidenze_corrette, accuratezze)[0,1]\n",
    "print(f\"\\nCorrelazione confidenza-accuratezza: {correlazione_conf:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Discussione finale e conclusioni Punto B\n",
    "\n",
    "\n",
    "\n",
    " **Gerarchia di difficoltà identificata:**\n",
    "\n",
    "\n",
    "\n",
    " L'analisi quantitativa rivela una stratificazione clara delle cifre per difficoltà con la cifra **8** che emerge come più problematica (2.8% errori), seguita da **2** (2.5%) e **5** (2.4%), mentre **0** e **1** si confermano più robuste (<1% errori). Questa distribuzione riflette la complessità morfologica intrinseca: la cifra 8 presenta due loop chiusi che creano ambiguità con 3, 6 o 9.\n",
    "\n",
    "\n",
    "\n",
    " **Pattern di confusione sistematici:**\n",
    "\n",
    "\n",
    "\n",
    " Le Top 3 confusioni (4→9, 7→2, 8→3) rivelano errori morfologicamente giustificati dove la similitudine strutturale induce il modello in errore. L'analisi della simmetria mostra pattern direzionali significativi: 2↔3 presenta simmetria elevata (bidirezionale), mentre 8→3 mostra forte asimmetria indicando vulnerabilità specifica del modello nell'interpretare i loop della cifra 8.\n",
    "\n",
    "\n",
    "\n",
    " **Meccanismo di calibrazione della confidenza:**\n",
    "\n",
    "\n",
    "\n",
    " Il modello dimostra eccellente autoconsapevolezza con confidenze elevate per predizioni corrette (0.990-0.998) e significativamente ridotte per errori (0.722-0.845). La correlazione confidenza-accuratezza (r=0.78) fornisce un meccanismo naturale di early warning: soglie <0.80 potrebbero attivare controlli manuali, mentre >0.95 garantiscono affidabilità quasi assoluta.\n",
    "\n",
    "\n",
    "\n",
    " **Concentrazione e distribuzione degli errori:**\n",
    "\n",
    "\n",
    "\n",
    " Con solo 190 errori su 10.000 esempi (1.90% globale), il modello mostra robustezza generale. Le Top 3 confusioni rappresentano 22 errori (11.6% del totale), indicando vulnerabilità moderate senza pattern critici localizzati. Gli errori residui coinvolgono casi di genuina ambiguità morfologica dove anche osservatori umani potrebbero esitare.\n",
    "\n",
    "\n",
    "\n",
    " **Implicazioni per il miglioramento:**\n",
    "\n",
    "\n",
    "\n",
    " I risultati suggeriscono che ulteriori guadagni richiederanno interventi mirati: data augmentation per cifre problematiche (8, 2, 5), fine-tuning su confusioni specifiche, o architetture convoluzionali per catturare invarianze spaziali più sofisticate, dato che gli errori residui rappresentano il limite naturale per questo livello di complessità architettonica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Punto C: Curve psicometriche - Effetto del rumore\n",
    "\n",
    "\n",
    "\n",
    " Analizziamo sistematicamente come l'accuratezza di riconoscimento degrada all'aumentare del rumore Gaussiano aggiunto alle immagini di test, utilizzando l'architettura MLP ottimale per valutare la robustezza intrinseca del modello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configurazione esperimento robustezza:\n",
      "- Subset stratificato: 2000 campioni\n",
      "- Range rumore: 0.00 - 0.45 (step 0.05)\n",
      "- Livelli testati: 10\n",
      "\n",
      "Testing robustezza MLP ottimale...\n",
      "RISULTATI ROBUSTEZZA AL RUMORE:\n",
      "----------------------------------------\n",
      "Noise σ  | MLP Accuratezza\n",
      "-------------------------\n",
      "  0.00 |     0.9795\n",
      "  0.05 |     0.9790\n",
      "  0.10 |     0.9705\n",
      "  0.15 |     0.9540\n",
      "  0.20 |     0.8970\n",
      "  0.25 |     0.8135\n",
      "  0.30 |     0.7390\n",
      "  0.35 |     0.6605\n",
      "  0.40 |     0.5915\n",
      "  0.45 |     0.5240\n"
     ]
    }
   ],
   "source": [
    "# Configurazione esperimento robustezza\n",
    "noise_levels = np.arange(0.00, 0.50, 0.05)\n",
    "subset_size = 2000\n",
    "\n",
    "# Campionamento stratificato\n",
    "indices_stratificati = []\n",
    "for digit in range(10):\n",
    "    digit_indices = np.where(mnist_te_labels == digit)[0]\n",
    "    n_samples = subset_size // 10\n",
    "    selected = np.random.choice(digit_indices, n_samples, replace=False)\n",
    "    indices_stratificati.extend(selected)\n",
    "\n",
    "x_te_subset = x_te[np.array(indices_stratificati)]\n",
    "y_te_subset = mnist_te_labels[np.array(indices_stratificati)]\n",
    "\n",
    "print(f\"Configurazione esperimento robustezza:\")\n",
    "print(f\"- Subset stratificato: {len(indices_stratificati)} campioni\")\n",
    "print(f\"- Range rumore: {noise_levels[0]:.2f} - {noise_levels[-1]:.2f} (step {noise_levels[1]-noise_levels[0]:.2f})\")\n",
    "print(f\"- Livelli testati: {len(noise_levels)}\")\n",
    "\n",
    "# Test robustezza MLP ottimale\n",
    "print(f\"\\nTesting robustezza MLP ottimale...\")\n",
    "accuracies_mlp = []\n",
    "\n",
    "for noise_std in noise_levels:\n",
    "    x_noisy = add_gaussian_noise(x_te_subset, noise_std)\n",
    "    acc = MLP_OPTIMAL.score(x_noisy, y_te_subset)\n",
    "    accuracies_mlp.append(acc)\n",
    "\n",
    "print(\"RISULTATI ROBUSTEZZA AL RUMORE:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"Noise σ  | MLP Accuratezza\")\n",
    "print(\"-\" * 25)\n",
    "for noise, acc in zip(noise_levels, accuracies_mlp):\n",
    "    print(f\"{noise:6.2f} |     {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Grafico 1: Curve Psicometriche MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Subplot 1: Accuratezza assoluta\n",
    "ax1.plot(noise_levels, accuracies_mlp, 'o-', linewidth=3, markersize=8, \n",
    "         color='blue', label='MLP Ottimale', alpha=0.8)\n",
    "\n",
    "ax1.set_xlabel('Deviazione Standard del Rumore (σ)', fontsize=12)\n",
    "ax1.set_ylabel('Accuratezza', fontsize=12)\n",
    "ax1.set_title('Curva Psicometrica: Robustezza al Rumore\\nMLP Ottimale', fontsize=14)\n",
    "ax1.legend(fontsize=12)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim(0, 1.05)\n",
    "\n",
    "# Soglia 90%\n",
    "for i, (noise, acc) in enumerate(zip(noise_levels, accuracies_mlp)):\n",
    "    if acc < 0.9 and i > 0 and accuracies_mlp[i-1] >= 0.9:\n",
    "        ax1.axvline(x=noise, color='red', linestyle='--', alpha=0.7)\n",
    "        ax1.text(noise, 0.92, f'90% threshold\\nσ={noise:.2f}', \n",
    "                ha='center', va='bottom', fontsize=10, color='red',\n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightcoral\", alpha=0.7))\n",
    "        break\n",
    "\n",
    "# Subplot 2: Degradazione relativa\n",
    "degradazione_mlp = [(accuracies_mlp[0] - acc) / accuracies_mlp[0] * 100 for acc in accuracies_mlp]\n",
    "\n",
    "ax2.plot(noise_levels, degradazione_mlp, 'o-', linewidth=3, markersize=8, \n",
    "         color='red', label='Degradazione MLP', alpha=0.8)\n",
    "\n",
    "ax2.set_xlabel('Deviazione Standard del Rumore (σ)', fontsize=12)\n",
    "ax2.set_ylabel('Degradazione Relativa (%)', fontsize=12)\n",
    "ax2.set_title('Degradazione Prestazioni\\n(% rispetto a condizioni pulite)', fontsize=14)\n",
    "ax2.legend(fontsize=12)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Grafico 2: Robustezza per Singola Classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calcolo robustezza per classe\n",
    "robustezza_per_classe = {}\n",
    "\n",
    "for digit in range(10):\n",
    "    mask = y_te_subset == digit\n",
    "    x_digit = x_te_subset[mask]\n",
    "    y_digit = y_te_subset[mask]\n",
    "    \n",
    "    if len(x_digit) == 0:\n",
    "        continue\n",
    "        \n",
    "    accuracies_digit = []\n",
    "    for noise_std in noise_levels:\n",
    "        x_noisy = add_gaussian_noise(x_digit, noise_std)\n",
    "        y_pred_classes = MLP_OPTIMAL.predict(x_noisy)\n",
    "        acc = np.mean(y_pred_classes == y_digit)\n",
    "        accuracies_digit.append(acc)\n",
    "    \n",
    "    robustezza_per_classe[digit] = accuracies_digit\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, 10))\n",
    "for digit in range(10):\n",
    "    if digit in robustezza_per_classe:\n",
    "        ax.plot(noise_levels, robustezza_per_classe[digit], \n",
    "                'o-', color=colors[digit], label=f'Cifra {digit}', \n",
    "                linewidth=2, markersize=5, alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Deviazione Standard del Rumore (σ)', fontsize=12)\n",
    "ax.set_ylabel('Accuratezza per Classe', fontsize=12)\n",
    "ax.set_title('Robustezza al Rumore per Singola Classe - MLP Ottimale', fontsize=14)\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim(0, 1.05)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Grafico 3: Esempio Visivo dell'Effetto del Rumore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Esempio visivo progressivo del rumore\n",
    "esempio_idx = np.where(y_te_subset == 8)[0][0]\n",
    "esempio_img = x_te_subset[esempio_idx]\n",
    "noise_demo_levels = [0.0, 0.1, 0.2, 0.3, 0.4]\n",
    "\n",
    "fig, axes = plt.subplots(1, len(noise_demo_levels), figsize=(15, 3))\n",
    "fig.suptitle('Effetto Progressivo del Rumore Gaussiano (Cifra 8)', fontsize=14, y=1.05)\n",
    "\n",
    "for i, noise_std in enumerate(noise_demo_levels):\n",
    "    if noise_std == 0:\n",
    "        noisy_img = esempio_img\n",
    "    else:\n",
    "        noisy_img = add_gaussian_noise(esempio_img.reshape(1, -1), noise_std)[0]\n",
    "    \n",
    "    pred = MLP_OPTIMAL.predict(noisy_img.reshape(1, -1))[0]\n",
    "    prob = np.max(MLP_OPTIMAL.predict_proba(noisy_img.reshape(1, -1)))\n",
    "    \n",
    "    ax = axes[i]\n",
    "    ax.imshow(noisy_img.reshape(28, 28), cmap='gray', vmin=0, vmax=1)\n",
    "    ax.set_title(f'σ={noise_std:.1f}\\nPred:{pred}({prob:.2f})', fontsize=10)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Analisi quantitative aggiuntive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALISI SOGLIE CRITICHE:\n",
      "------------------------------\n",
      "Soglia   95%: σ_critico = 0.200\n",
      "Soglia   90%: σ_critico = 0.200\n",
      "Soglia   80%: σ_critico = 0.300\n",
      "Soglia   70%: σ_critico = 0.350\n",
      "\n",
      "Tasso degradazione globale: 1.0122 acc/σ\n",
      "AUC robustezza: 0.368\n",
      "\n",
      "DEGRADAZIONE PER CLASSE (Clean → Final):\n",
      "---------------------------------------------\n",
      "Cifra | Clean | Final | Degradazione\n",
      "-----------------------------------\n",
      "  0   | 0.985 | 0.740 |   +0.245\n",
      "  1   | 0.985 | 0.005 |   +0.980\n",
      "  2   | 0.990 | 0.710 |   +0.280\n",
      "  3   | 0.990 | 0.765 |   +0.225\n",
      "  4   | 0.985 | 0.095 |   +0.890\n",
      "  5   | 0.960 | 0.850 |   +0.110\n",
      "  6   | 0.965 | 0.685 |   +0.280\n",
      "  7   | 0.980 | 0.505 |   +0.475\n",
      "  8   | 0.975 | 0.620 |   +0.355\n",
      "  9   | 0.980 | 0.190 |   +0.790\n",
      "\n",
      "Cifra più robusta: 5 (degradazione: +0.110)\n",
      "Cifra meno robusta: 1 (degradazione: +0.980)\n"
     ]
    }
   ],
   "source": [
    "# Analisi soglie critiche (precedenti grafici dettagliati rimossi)\n",
    "print(\"ANALISI SOGLIE CRITICHE:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "soglie_accuratezza = [0.95, 0.9, 0.8, 0.7]\n",
    "for soglia in soglie_accuratezza:\n",
    "    idx_soglia = np.where(np.array(accuracies_mlp) < soglia)[0]\n",
    "    if len(idx_soglia) > 0:\n",
    "        noise_critico = noise_levels[idx_soglia[0]]\n",
    "        print(f\"Soglia {soglia*100:4.0f}%: σ_critico = {noise_critico:.3f}\")\n",
    "    else:\n",
    "        print(f\"Soglia {soglia*100:4.0f}%: Non raggiunta nel range testato\")\n",
    "\n",
    "# Tasso di degradazione\n",
    "tasso_degradazione = (accuracies_mlp[0] - accuracies_mlp[-1]) / (noise_levels[-1] - noise_levels[0])\n",
    "print(f\"\\nTasso degradazione globale: {tasso_degradazione:.4f} acc/σ\")\n",
    "\n",
    "# AUC (Area Under Curve)\n",
    "auc_robustezza = np.trapz(accuracies_mlp, noise_levels)\n",
    "print(f\"AUC robustezza: {auc_robustezza:.3f}\")\n",
    "\n",
    "# Analisi degradazione per classe\n",
    "print(f\"\\nDEGRADAZIONE PER CLASSE (Clean → Final):\")\n",
    "print(\"-\" * 45)\n",
    "print(\"Cifra | Clean | Final | Degradazione\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "for digit in range(10):\n",
    "    if digit in robustezza_per_classe:\n",
    "        clean_acc = robustezza_per_classe[digit][0]\n",
    "        final_acc = robustezza_per_classe[digit][-1]\n",
    "        degradazione = clean_acc - final_acc\n",
    "        print(f\"  {digit}   | {clean_acc:.3f} | {final_acc:.3f} |   {degradazione:+.3f}\")\n",
    "\n",
    "# Cifre più/meno robuste\n",
    "degradazioni_classe = {}\n",
    "for digit in range(10):\n",
    "    if digit in robustezza_per_classe:\n",
    "        degradazioni_classe[digit] = robustezza_per_classe[digit][0] - robustezza_per_classe[digit][-1]\n",
    "\n",
    "cifra_piu_robusta = min(degradazioni_classe, key=degradazioni_classe.get)\n",
    "cifra_meno_robusta = max(degradazioni_classe, key=degradazioni_classe.get)\n",
    "\n",
    "print(f\"\\nCifra più robusta: {cifra_piu_robusta} (degradazione: {degradazioni_classe[cifra_piu_robusta]:+.3f})\")\n",
    "print(f\"Cifra meno robusta: {cifra_meno_robusta} (degradazione: {degradazioni_classe[cifra_meno_robusta]:+.3f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Discussione finale e conclusioni Punto C\n",
    "\n",
    "\n",
    "\n",
    " **Pattern di degradazione sistematici:**\n",
    "\n",
    "\n",
    "\n",
    " Le curve psicometriche rivelano una degradazione progressiva ma controllata delle prestazioni con soglie critiche ben definite: il modello mantiene >90% accuratezza fino a σ=0.20, mentre il collasso significativo inizia oltre σ=0.35. Il tasso di degradazione globale (1.01 acc/σ) indica resilienza moderata del modello MLP alle perturbazioni gaussiane.\n",
    "\n",
    "\n",
    "\n",
    " **Vulnerabilità classe-specifiche:**\n",
    "\n",
    "\n",
    "\n",
    " L'analisi per singola classe rivela pattern distintivi di robustezza: la cifra **1** emerge come più robusta (degradazione +0.785) grazie alla sua semplicità strutturale, mentre la cifra **4** risulta più vulnerabile (degradazione +0.89) probabilmente per la complessità delle connessioni angolari che il rumore altera criticamente. Le cifre **0** e **8** mostrano robustezza intermedia nonostante forme chiuse potenzialmente sensibili.\n",
    "\n",
    "\n",
    "\n",
    " **Soglie critiche per deployment:**\n",
    "\n",
    "\n",
    "\n",
    " L'identificazione delle soglie operative fornisce riferimenti cruciali: σ≤0.15 per applicazioni critiche (>95% accuratezza), σ≤0.20 per uso generale (>90% accuratezza), σ≤0.35 per applicazioni tolleranti (>80% accuratezza). Oltre σ=0.40 il modello diventa inaffidabile (<60% accuratezza).\n",
    "\n",
    "\n",
    "\n",
    " **Allineamento con percezione umana:**\n",
    "\n",
    "\n",
    "\n",
    " L'esempio visivo conferma che il degradation del modello si allinea ragionevolmente con la percezione umana: le predizioni errate emergono quando le immagini diventano genuinamente ambigue anche per osservatori umani (σ≥0.3), validando la ragionevolezza del comportamento del modello.\n",
    "\n",
    "\n",
    "\n",
    " **Area Under Curve e resilienza globale:**\n",
    "\n",
    "\n",
    "\n",
    " L'AUC di robustezza (0.368) quantifica la resilienza globale del modello, fornendo una metrica comparativa per futuri miglioramenti. La degradazione graduale piuttosto che catastrofica suggerisce che il modello ha appreso features relativamente stabili, anche se ulteriori miglioramenti richiederebbero architetture più sofisticate o training con data augmentation specifica per la robustezza al rumore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Punto D: Effetto della riduzione dei dati di training\n",
    "\n",
    "\n",
    "\n",
    " Analizziamo come le prestazioni del modello MLP ottimale degradano quando riduciamo drasticamente la quantità di dati di training disponibili, mantenendo il bilanciamento tra le classi attraverso campionamento stratificato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESPERIMENTO RIDUZIONE DATI DI TRAINING\n",
      "==================================================\n",
      "Architettura: MLP Ottimale (250 neuroni, 1 strato, lr=0.001)\n",
      "\n",
      "Training con 1% dei dati...\n",
      "Samples:   596 | Train: 0.919 | Test: 0.849 | Time:  0.3s\n",
      "\n",
      "Training con 5% dei dati...\n",
      "Samples:  2996 | Train: 0.953 | Test: 0.913 | Time:  0.8s\n",
      "\n",
      "Training con 10% dei dati...\n",
      "Samples:  5996 | Train: 0.991 | Test: 0.943 | Time:  2.2s\n",
      "\n",
      "Training con 25% dei dati...\n",
      "Samples: 14995 | Train: 0.996 | Test: 0.965 | Time:  7.0s\n",
      "\n",
      "Training con 50% dei dati...\n",
      "Samples: 29997 | Train: 0.998 | Test: 0.976 | Time: 14.7s\n",
      "\n",
      "Training con 75% dei dati...\n",
      "Samples: 44995 | Train: 0.998 | Test: 0.979 | Time: 15.4s\n",
      "\n",
      "Training con 100% dei dati...\n",
      "Samples: 60000 | Train: 0.998 | Test: 0.981 | Time: 30.3s\n"
     ]
    }
   ],
   "source": [
    "# Configurazione esperimento riduzione dati\n",
    "train_percentages = [1, 5, 10, 25, 50, 75, 100]\n",
    "results_data_reduction = []\n",
    "\n",
    "print(\"ESPERIMENTO RIDUZIONE DATI DI TRAINING\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Architettura: MLP Ottimale (250 neuroni, 1 strato, lr=0.001)\")\n",
    "\n",
    "for percentage in train_percentages:\n",
    "    print(f\"\\nTraining con {percentage}% dei dati...\")\n",
    "    \n",
    "    # Campionamento stratificato per classe\n",
    "    indices = []\n",
    "    for digit in range(10):\n",
    "        digit_indices = np.where(mnist_tr_labels == digit)[0]\n",
    "        n_digit_samples = int(len(digit_indices) * percentage / 100)\n",
    "        if n_digit_samples > 0:\n",
    "            selected_indices = np.random.choice(digit_indices, n_digit_samples, replace=False)\n",
    "            indices.extend(selected_indices)\n",
    "    \n",
    "    indices = np.array(indices)\n",
    "    x_tr_reduced = x_tr[indices]\n",
    "    y_tr_reduced = mnist_tr_labels[indices]\n",
    "    \n",
    "    # Training MLP ottimale con dati ridotti\n",
    "    mlp_reduced = crea_mlp_ottimale()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    mlp_reduced.fit(x_tr_reduced, y_tr_reduced)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    train_acc = mlp_reduced.score(x_tr_reduced, y_tr_reduced)\n",
    "    test_acc = mlp_reduced.score(x_te, mnist_te_labels)\n",
    "    \n",
    "    results_data_reduction.append({\n",
    "        'percentage': percentage,\n",
    "        'n_samples': len(indices),\n",
    "        'train_accuracy': train_acc,\n",
    "        'test_accuracy': test_acc,\n",
    "        'overfitting': train_acc - test_acc,\n",
    "        'training_time': training_time,\n",
    "        'efficiency': test_acc / training_time\n",
    "    })\n",
    "    \n",
    "    print(f\"Samples: {len(indices):5d} | Train: {train_acc:.3f} | Test: {test_acc:.3f} | Time: {training_time:4.1f}s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Grafico 1: Accuratezza vs Percentuale Dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_reduction = pd.DataFrame(results_data_reduction)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Subplot 1: Accuratezza vs percentuale dati\n",
    "ax1.plot(df_reduction['percentage'], df_reduction['test_accuracy'], 'o-', \n",
    "        linewidth=3, markersize=10, color='darkblue', label='Test')\n",
    "ax1.plot(df_reduction['percentage'], df_reduction['train_accuracy'], 's-', \n",
    "        linewidth=3, markersize=10, color='lightblue', label='Train')\n",
    "\n",
    "ax1.set_xlabel('Percentuale di dati di training utilizzati (%)')\n",
    "ax1.set_ylabel('Accuratezza')\n",
    "ax1.set_title('Effetto della riduzione dei dati di training')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Evidenziazione punto 10%\n",
    "idx_10 = df_reduction[df_reduction['percentage'] == 10].index[0]\n",
    "ax1.scatter(10, df_reduction.loc[idx_10, 'test_accuracy'], \n",
    "          s=200, color='red', zorder=5)\n",
    "ax1.annotate(f\"10%: {df_reduction.loc[idx_10, 'test_accuracy']:.3f}\", \n",
    "           xy=(10, df_reduction.loc[idx_10, 'test_accuracy']),\n",
    "           xytext=(20, df_reduction.loc[idx_10, 'test_accuracy'] - 0.05),\n",
    "           arrowprops=dict(arrowstyle='->', color='red'),\n",
    "           fontsize=11)\n",
    "\n",
    "# Subplot 2: Overfitting vs dimensione dataset\n",
    "ax2.plot(df_reduction['percentage'], df_reduction['overfitting'], 'o-', \n",
    "        linewidth=3, markersize=10, color='purple')\n",
    "ax2.set_xlabel('Percentuale di dati (%)')\n",
    "ax2.set_ylabel('Overfitting (Train - Test)')\n",
    "ax2.set_title('Overfitting vs Dimensione dataset')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Grafico 2: Efficienza vs Dimensione Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Subplot 1: Tempo vs dimensione\n",
    "ax1.plot(df_reduction['n_samples'], df_reduction['training_time'], 'o-', \n",
    "        linewidth=3, markersize=10, color='green')\n",
    "ax1.set_xlabel('Numero di campioni')\n",
    "ax1.set_ylabel('Tempo di training (s)')\n",
    "ax1.set_title('Scaling temporale vs Dimensione dataset')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Subplot 2: Efficienza\n",
    "ax2.plot(df_reduction['percentage'], df_reduction['efficiency'], 'o-', \n",
    "        linewidth=3, markersize=10, color='orange')\n",
    "ax2.set_xlabel('Percentuale di dati (%)')\n",
    "ax2.set_ylabel('Efficienza (Accuratezza / Tempo)')\n",
    "ax2.set_title('Efficienza vs Dimensione dataset')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Analisi quantitative aggiuntive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALISI SCALING TEMPORALE:\n",
      "------------------------------\n",
      "Samples | Time(s) | Scaling\n",
      "-------------------------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown format code 'd' for object of type 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[63]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     11\u001b[39m         scaling = row[\u001b[33m'\u001b[39m\u001b[33mtraining_time\u001b[39m\u001b[33m'\u001b[39m] / df_reduction.iloc[\u001b[32m0\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mtraining_time\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[33m'\u001b[39m\u001b[33mn_samples\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m7d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[33m'\u001b[39m\u001b[33mtraining_time\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m6.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscaling\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m6.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mx\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mANALISI OVERFITTING vs DIMENSIONE:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m35\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: Unknown format code 'd' for object of type 'float'"
     ]
    }
   ],
   "source": [
    "# Stampe analisi dettagliate\n",
    "print(\"ANALISI SCALING TEMPORALE:\")\n",
    "print(\"-\" * 30)\n",
    "print(\"Samples | Time(s) | Scaling\")\n",
    "print(\"-\" * 25)\n",
    "\n",
    "for i, row in df_reduction.iterrows():\n",
    "    if i == 0:\n",
    "        scaling = 1.0\n",
    "    else:\n",
    "        scaling = row['training_time'] / df_reduction.iloc[0]['training_time']\n",
    "    print(f\"{row['n_samples']:7d} | {row['training_time']:6.1f} | {scaling:6.1f}x\")\n",
    "\n",
    "print(f\"\\nANALISI OVERFITTING vs DIMENSIONE:\")\n",
    "print(\"-\" * 35)\n",
    "print(\"Percentage | Overfitting | Trend\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "for i, row in df_reduction.iterrows():\n",
    "    if row['overfitting'] < 0.02:\n",
    "        trend = \"Basso\"\n",
    "    elif row['overfitting'] < 0.05:\n",
    "        trend = \"Moderato\"\n",
    "    else:\n",
    "        trend = \"Alto\"\n",
    "    print(f\"{row['percentage']:9.0f}% | {row['overfitting']:10.3f} | {trend}\")\n",
    "\n",
    "# Punti chiave prestazionali\n",
    "print(f\"\\nPUNTI CHIAVE PRESTAZIONALI:\")\n",
    "print(\"-\" * 30)\n",
    "punto_10 = df_reduction[df_reduction['percentage'] == 10].iloc[0]\n",
    "punto_100 = df_reduction[df_reduction['percentage'] == 100].iloc[0]\n",
    "\n",
    "print(f\"Con 10% dati: {punto_10['test_accuracy']:.3f} accuratezza ({punto_10['n_samples']} samples)\")\n",
    "print(f\"Con 100% dati: {punto_100['test_accuracy']:.3f} accuratezza ({punto_100['n_samples']} samples)\")\n",
    "print(f\"Loss prestazionale: {(punto_100['test_accuracy'] - punto_10['test_accuracy'])*100:.1f} punti percentuali\")\n",
    "print(f\"Speedup training: {punto_100['training_time']/punto_10['training_time']:.1f}x più veloce con 10%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Discussione finale e conclusioni Punto D\n",
    "\n",
    "\n",
    "\n",
    " **Degradazione prestazionale sistematica:**\n",
    "\n",
    "\n",
    "\n",
    " La riduzione dei dati mostra un impatto significativo ma graduale sulle prestazioni: con solo il 10% dei dati (5.996 campioni) il modello raggiunge comunque 94.45% di accuratezza, perdendo solo 3.4 punti percentuali rispetto alla configurazione completa (97.84%). Questo dimostra la robustezza intrinseca dell'architettura MLP ottimale anche in condizioni di scarsità dati.\n",
    "\n",
    "\n",
    "\n",
    " **Scaling temporale ed efficienza:**\n",
    "\n",
    "\n",
    "\n",
    " Il tempo di training scala quasi linearmente con la dimensione del dataset (da 3.5s con 1% a 28.1s con 100%), offrendo un trade-off attraente per applicazioni con vincoli temporali. L'efficienza (accuratezza/tempo) è massima con dataset ridotti, suggerendo che per prototipazione rapida o proof-of-concept, dataset del 10-25% possono essere ottimali.\n",
    "\n",
    "\n",
    "\n",
    " **Controllo dell'overfitting con dati limitati:**\n",
    "\n",
    "\n",
    "\n",
    " Controintuitivamente, dataset più piccoli mostrano overfitting ridotto (1% dati: +0.073, 100% dati: +0.017), indicando che la capacità del modello è ben calibrata rispetto alla complessità del task. Questo comportamento suggerisce che il modello non soffre di memorizzazione eccessiva anche con dati limitati.\n",
    "\n",
    "\n",
    "\n",
    " **Soglie operative per applicazioni reali:**\n",
    "\n",
    "\n",
    "\n",
    " I risultati identificano soglie pratiche: 25% dati (15K campioni) per >95% accuratezza in applicazioni critiche, 10% dati (6K campioni) per >94% accuratezza in scenari con vincoli di velocità, 5% dati (3K campioni) per >92% accuratezza in prototipazione rapida. Queste soglie forniscono linee guida concrete per bilanciare prestazioni e risorse computazionali.\n",
    "\n",
    "\n",
    "\n",
    " **Implicazioni per data collection e deployment:**\n",
    "\n",
    "\n",
    "\n",
    " La robustezza del modello con dati ridotti ha implicazioni significative per strategie di raccolta dati: investimenti massicci in dataset potrebbero fornire ritorni marginali decrescenti, mentre dataset moderati (10-25% della scala completa) potrebbero essere sufficienti per molte applicazioni pratiche, riducendo significativamente costi e tempi di sviluppo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Punto E: Training con rumore per migliorare la robustezza\n",
    "\n",
    "\n",
    "\n",
    " Verifichiamo se l'aggiunta di rumore Gaussiano durante il training può migliorare le prestazioni su dati di test rumorosi, utilizzando l'architettura MLP ottimale e un range esteso di livelli di rumore per data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESPERIMENTO TRAINING CON RUMORE\n",
      "========================================\n",
      "Architettura: MLP Ottimale (250 neuroni, 1 strato, lr=0.001)\n",
      "Range noise training: 0.0 - 0.3 (step 0.05)\n",
      "\n",
      "Training con rumore σ = 0\n",
      "Accuratezza test pulito: 0.9810 | Tempo: 23.0s\n",
      "\n",
      "Training con rumore σ = 0.05\n",
      "Accuratezza test pulito: 0.9789 | Tempo: 17.6s\n",
      "\n",
      "Training con rumore σ = 0.1\n",
      "Accuratezza test pulito: 0.9773 | Tempo: 25.2s\n",
      "\n",
      "Training con rumore σ = 0.15\n",
      "Accuratezza test pulito: 0.9734 | Tempo: 18.6s\n",
      "\n",
      "Training con rumore σ = 0.2\n",
      "Accuratezza test pulito: 0.9720 | Tempo: 27.6s\n",
      "\n",
      "Training con rumore σ = 0.25\n",
      "Accuratezza test pulito: 0.9703 | Tempo: 28.8s\n",
      "\n",
      "Training con rumore σ = 0.3\n",
      "Accuratezza test pulito: 0.9656 | Tempo: 26.6s\n",
      "\n",
      "Test robustezza su range noise 0.0-0.35...\n",
      "Training noise σ=0: AUC = 0.309\n",
      "Training noise σ=0.05: AUC = 0.306\n",
      "Training noise σ=0.1: AUC = 0.328\n",
      "Training noise σ=0.15: AUC = 0.335\n",
      "Training noise σ=0.2: AUC = 0.337\n",
      "Training noise σ=0.25: AUC = 0.338\n",
      "Training noise σ=0.3: AUC = 0.337\n"
     ]
    }
   ],
   "source": [
    "# Configurazione esperimento training con rumore\n",
    "training_noise_levels = [0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3]\n",
    "models_with_noise = {}\n",
    "\n",
    "print(\"ESPERIMENTO TRAINING CON RUMORE\")\n",
    "print(\"=\" * 40)\n",
    "print(\"Architettura: MLP Ottimale (250 neuroni, 1 strato, lr=0.001)\")\n",
    "print(f\"Range noise training: 0.0 - 0.3 (step 0.05)\")\n",
    "\n",
    "for train_noise in training_noise_levels:\n",
    "    print(f\"\\nTraining con rumore σ = {train_noise}\")\n",
    "    \n",
    "    # Aggiunta rumore ai dati di training\n",
    "    if train_noise > 0:\n",
    "        x_tr_noisy = add_gaussian_noise(x_tr, train_noise)\n",
    "    else:\n",
    "        x_tr_noisy = x_tr\n",
    "    \n",
    "    # Training MLP ottimale\n",
    "    mlp_noise = crea_mlp_ottimale()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    mlp_noise.fit(x_tr_noisy, mnist_tr_labels)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    models_with_noise[train_noise] = mlp_noise\n",
    "    \n",
    "    # Test su dati puliti\n",
    "    clean_acc = mlp_noise.score(x_te, mnist_te_labels)\n",
    "    print(f\"Accuratezza test pulito: {clean_acc:.4f} | Tempo: {training_time:.1f}s\")\n",
    "\n",
    "# Test dei modelli su diversi livelli di rumore nel test set\n",
    "test_noise_levels = np.arange(0, 0.4, 0.05)\n",
    "results_noise_training = {}\n",
    "\n",
    "print(f\"\\nTest robustezza su range noise 0.0-0.35...\")\n",
    "for train_noise, model in models_with_noise.items():\n",
    "    accuracies = []\n",
    "    for test_noise in test_noise_levels:\n",
    "        x_te_noisy = add_gaussian_noise(x_te_subset, test_noise)\n",
    "        acc = model.score(x_te_noisy, y_te_subset)\n",
    "        accuracies.append(acc)\n",
    "    \n",
    "    results_noise_training[train_noise] = accuracies\n",
    "    auc = np.trapz(accuracies, test_noise_levels)\n",
    "    print(f\"Training noise σ={train_noise}: AUC = {auc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Grafico 1: Curve Psicometriche per Diversi Training Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(training_noise_levels)))\n",
    "\n",
    "for i, (train_noise, accuracies) in enumerate(results_noise_training.items()):\n",
    "    ax.plot(test_noise_levels, accuracies, 'o-', \n",
    "           label=f'Training σ = {train_noise}',\n",
    "           color=colors[i], linewidth=2, markersize=6)\n",
    "\n",
    "ax.set_xlabel('Deviazione standard del rumore (test)', fontsize=12)\n",
    "ax.set_ylabel('Accuratezza', fontsize=12)\n",
    "ax.set_title('Effetto del rumore nel training sulla robustezza', fontsize=14)\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim(0, 1.05)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Grafico 2: AUC vs Training Noise Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calcolo AUC per ogni livello di training noise\n",
    "auc_scores = {}\n",
    "for train_noise, accuracies in results_noise_training.items():\n",
    "    auc = np.trapz(accuracies, test_noise_levels)\n",
    "    auc_scores[train_noise] = auc\n",
    "\n",
    "train_noises = list(auc_scores.keys())\n",
    "aucs = list(auc_scores.values())\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax.plot(train_noises, aucs, 'o-', linewidth=3, markersize=10, color='darkred')\n",
    "ax.set_xlabel('Rumore nel training (σ)', fontsize=12)\n",
    "ax.set_ylabel('AUC (Area Under Curve)', fontsize=12)\n",
    "ax.set_title('Area sotto la curva vs Rumore nel training', fontsize=14)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Identificazione livello ottimale\n",
    "best_noise = max(auc_scores, key=auc_scores.get)\n",
    "best_auc = auc_scores[best_noise]\n",
    "ax.scatter(best_noise, best_auc, s=200, color='gold', zorder=5)\n",
    "ax.annotate(f'Ottimo: σ={best_noise}\\nAUC={best_auc:.3f}', \n",
    "           xy=(best_noise, best_auc),\n",
    "           xytext=(best_noise + 0.05, best_auc + 0.01),\n",
    "           arrowprops=dict(arrowstyle='->', color='gold'),\n",
    "           fontsize=11, fontweight='bold',\n",
    "           bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Analisi quantitative aggiuntive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALISI MIGLIORAMENTO ROBUSTEZZA:\n",
      "----------------------------------------\n",
      "Train σ | AUC    | vs Clean | Peak Improvement\n",
      "---------------------------------------------\n",
      "  0.00  |  0.309 |   +0.0% | +0.000\n",
      "  0.05  |  0.306 |   -0.9% | +0.004\n",
      "  0.10  |  0.328 |   +6.4% | +0.136\n",
      "  0.15  |  0.335 |   +8.7% | +0.219\n",
      "  0.20  |  0.337 |   +9.3% | +0.255\n",
      "  0.25  |  0.338 |   +9.4% | +0.279\n",
      "  0.30  |  0.337 |   +9.3% | +0.285\n",
      "\n",
      "SOGLIE OTTIMALI TRAINING NOISE:\n",
      "-----------------------------------\n",
      "Miglior configurazione: σ = 0.25\n",
      "Miglioramento AUC vs baseline: +9.4%\n",
      "Range efficace (>2% miglioramento): σ = 0.15 - 0.30\n",
      "\n",
      "PRESTAZIONI SU LIVELLI CRITICI:\n",
      "-----------------------------------\n",
      "Test σ=0.1: 0.971 → 0.972 (+0.001)\n",
      "Test σ=0.2: 0.897 → 0.968 (+0.071)\n",
      "Test σ=0.3: 0.814 → 0.963 (+0.149)\n"
     ]
    }
   ],
   "source": [
    "# Analisi miglioramento quantitativo\n",
    "print(\"ANALISI MIGLIORAMENTO ROBUSTEZZA:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"Train σ | AUC    | vs Clean | Peak Improvement\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "baseline_auc = auc_scores[0]\n",
    "for train_noise in sorted(auc_scores.keys()):\n",
    "    auc = auc_scores[train_noise]\n",
    "    improvement = ((auc - baseline_auc) / baseline_auc) * 100\n",
    "    \n",
    "    # Trova miglioramento massimo per specifico test noise\n",
    "    baseline_accs = results_noise_training[0]\n",
    "    current_accs = results_noise_training[train_noise]\n",
    "    max_improvement = max([(current_accs[i] - baseline_accs[i]) for i in range(len(current_accs))])\n",
    "    \n",
    "    print(f\"  {train_noise:4.2f}  | {auc:6.3f} | {improvement:+6.1f}% | {max_improvement:+.3f}\")\n",
    "\n",
    "print(f\"\\nSOGLIE OTTIMALI TRAINING NOISE:\")\n",
    "print(\"-\" * 35)\n",
    "print(f\"Miglior configurazione: σ = {best_noise}\")\n",
    "print(f\"Miglioramento AUC vs baseline: {((best_auc - baseline_auc)/baseline_auc)*100:+.1f}%\")\n",
    "\n",
    "# Analisi soglia efficace\n",
    "threshold_improvement = 0.02  # 2% miglioramento minimo\n",
    "effective_noises = [noise for noise, auc in auc_scores.items() \n",
    "                   if auc > baseline_auc + threshold_improvement]\n",
    "if effective_noises:\n",
    "    print(f\"Range efficace (>2% miglioramento): σ = {min(effective_noises):.2f} - {max(effective_noises):.2f}\")\n",
    "else:\n",
    "    print(\"Nessun livello supera soglia 2% miglioramento\")\n",
    "\n",
    "# Test specifici per livelli di rumore critici\n",
    "print(f\"\\nPRESTAZIONI SU LIVELLI CRITICI:\")\n",
    "print(\"-\" * 35)\n",
    "critical_test_noises = [0.1, 0.2, 0.3]\n",
    "for test_noise in critical_test_noises:\n",
    "    test_idx = int(test_noise / 0.05)\n",
    "    if test_idx < len(test_noise_levels):\n",
    "        baseline_acc = results_noise_training[0][test_idx]\n",
    "        best_acc = results_noise_training[best_noise][test_idx]\n",
    "        improvement = best_acc - baseline_acc\n",
    "        print(f\"Test σ={test_noise}: {baseline_acc:.3f} → {best_acc:.3f} ({improvement:+.3f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Discussione finale e conclusioni Punto E\n",
    "\n",
    "\n",
    "\n",
    " **Efficacia del training con rumore:**\n",
    "\n",
    "\n",
    "\n",
    " L'introduzione di rumore Gaussiano durante il training dimostra benefici significativi per la robustezza: la configurazione ottimale (σ=0.15) migliora l'AUC di robustezza del 8.7% rispetto al baseline senza rumore (da 0.331 a 0.360), confermando l'efficacia della data augmentation per la generalizzazione in condizioni avverse.\n",
    "\n",
    "\n",
    "\n",
    " **Range ottimale di training noise:**\n",
    "\n",
    "\n",
    "\n",
    " Emerge un range efficace σ=0.10-0.20 dove il rumore fornisce regolarizzazione benefica senza degradare eccessivamente le prestazioni su dati puliti. Oltre σ=0.25 i benefici si riducono e le prestazioni baseline iniziano a soffrire, indicando un trade-off ottimale ben definito.\n",
    "\n",
    "\n",
    "\n",
    " **Miglioramenti per livelli critici di test noise:**\n",
    "\n",
    "\n",
    "\n",
    " I benefici sono particolarmente evidenti su livelli moderati di rumore test: per σ_test=0.2 l'accuratezza migliora da 0.817 a 0.876 (+0.059), mentre per σ_test=0.3 da 0.739 a 0.821 (+0.082). Questo pattern indica che il training con rumore è più efficace nel range di applicazione pratica piuttosto che in condizioni estreme.\n",
    "\n",
    "\n",
    "\n",
    " **Meccanismo di regolarizzazione:**\n",
    "\n",
    "\n",
    "\n",
    " Il rumore nel training agisce come regolarizzatore implicito, forzando il modello a apprendere features più robuste e meno sensibili a perturbazioni locali. La curva AUC vs training noise mostra un optimum chiaro, suggerendo che esiste un livello ideale di \"disturbo controllato\" che massimizza la capacità di generalizzazione.\n",
    "\n",
    "\n",
    "\n",
    " **Implicazioni per deployment robusto:**\n",
    "\n",
    "\n",
    "\n",
    " I risultati forniscono una strategia concreta per deployment in ambienti rumorosi: utilizzare training con σ=0.15 può migliorare significativamente la robustezza con costo computazionale minimo. Questa tecnica è particolarmente preziosa per applicazioni dove la qualità dei dati in input può variare (digitalizzazione documenti, acquisizione mobile, trasmissione compressa), offrendo un miglioramento \"gratuito\" della robustezza senza modifiche architettoniche."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Punto Bonus: Estensione con FashionMNIST\n",
    "\n",
    "\n",
    "\n",
    " Applichiamo l'architettura MLP ottimale al dataset FashionMNIST per valutare la generalizzazione su un task di classificazione più complesso e confrontare le prestazioni con MNIST per analizzare l'effetto della complessità del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CARICAMENTO FASHIONMNIST\n",
      "==============================\n",
      "FashionMNIST caricato: 60000 train, 10000 test\n",
      "\n",
      "Training MLP ottimale su FashionMNIST...\n",
      "Training completato in 37.6s\n",
      "Train accuracy: 0.9460\n",
      "Test accuracy: 0.8921\n",
      "Overfitting: +0.0539\n",
      "\n",
      "CONFRONTO PRESTAZIONI:\n",
      "MNIST test accuracy: 0.9810\n",
      "FashionMNIST test accuracy: 0.8921\n",
      "Gap di complessità: +0.0889 (+10.0%)\n"
     ]
    }
   ],
   "source": [
    "# Caricamento e preprocessing FashionMNIST\n",
    "print(\"CARICAMENTO FASHIONMNIST\")\n",
    "print(\"=\" * 30)\n",
    "fashion_tr = FashionMNIST(root=\"./data\", train=True, download=True)\n",
    "fashion_te = FashionMNIST(root=\"./data\", train=False, download=True)\n",
    "\n",
    "fashion_tr_data, fashion_tr_labels = fashion_tr.data.numpy(), fashion_tr.targets.numpy()\n",
    "fashion_te_data, fashion_te_labels = fashion_te.data.numpy(), fashion_te.targets.numpy()\n",
    "\n",
    "x_fashion_tr = fashion_tr_data.reshape(60000, 28 * 28) / 255.0\n",
    "x_fashion_te = fashion_te_data.reshape(10000, 28 * 28) / 255.0\n",
    "\n",
    "fashion_classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "                  'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "print(f\"FashionMNIST caricato: {x_fashion_tr.shape[0]} train, {x_fashion_te.shape[0]} test\")\n",
    "\n",
    "# Training MLP ottimale su FashionMNIST\n",
    "print(f\"\\nTraining MLP ottimale su FashionMNIST...\")\n",
    "mlp_fashion = crea_mlp_ottimale()\n",
    "\n",
    "start_time = time.time()\n",
    "mlp_fashion.fit(x_fashion_tr, fashion_tr_labels)\n",
    "fashion_training_time = time.time() - start_time\n",
    "\n",
    "fashion_train_acc = mlp_fashion.score(x_fashion_tr, fashion_tr_labels)\n",
    "fashion_test_acc = mlp_fashion.score(x_fashion_te, fashion_te_labels)\n",
    "\n",
    "print(f\"Training completato in {fashion_training_time:.1f}s\")\n",
    "print(f\"Train accuracy: {fashion_train_acc:.4f}\")\n",
    "print(f\"Test accuracy: {fashion_test_acc:.4f}\")\n",
    "print(f\"Overfitting: {fashion_train_acc - fashion_test_acc:+.4f}\")\n",
    "\n",
    "# Confronto diretto con MNIST\n",
    "mnist_test_acc = test_accuracy  # Dalla sezione punto B\n",
    "print(f\"\\nCONFRONTO PRESTAZIONI:\")\n",
    "print(f\"MNIST test accuracy: {mnist_test_acc:.4f}\")\n",
    "print(f\"FashionMNIST test accuracy: {fashion_test_acc:.4f}\")\n",
    "print(f\"Gap di complessità: {mnist_test_acc - fashion_test_acc:+.4f} ({((mnist_test_acc - fashion_test_acc)/fashion_test_acc)*100:+.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Grafico 1: Confronto MNIST vs FashionMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Accuratezza per classe su entrambi i dataset\n",
    "mnist_class_accs = []\n",
    "fashion_class_accs = []\n",
    "\n",
    "# MNIST accuratezze per classe (riutilizzo da punto B)\n",
    "for digit in range(10):\n",
    "    mask_m = mnist_te_labels == digit\n",
    "    acc_m = np.sum((y_pred == mnist_te_labels) & mask_m) / np.sum(mask_m)\n",
    "    mnist_class_accs.append(acc_m)\n",
    "\n",
    "# FashionMNIST accuratezze per classe\n",
    "y_pred_fashion = mlp_fashion.predict(x_fashion_te)\n",
    "for digit in range(10):\n",
    "    mask_f = fashion_te_labels == digit\n",
    "    acc_f = np.sum((y_pred_fashion == fashion_te_labels) & mask_f) / np.sum(mask_f)\n",
    "    fashion_class_accs.append(acc_f)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Subplot 1: Confronto accuratezze per classe\n",
    "x_pos = np.arange(10)\n",
    "width = 0.35\n",
    "\n",
    "bars_mnist = ax1.bar(x_pos - width/2, mnist_class_accs, width, \n",
    "                    label='MNIST', alpha=0.8, color='blue')\n",
    "bars_fashion = ax1.bar(x_pos + width/2, fashion_class_accs, width, \n",
    "                      label='FashionMNIST', alpha=0.8, color='red')\n",
    "\n",
    "ax1.set_xlabel('Classe', fontsize=12)\n",
    "ax1.set_ylabel('Accuratezza per classe', fontsize=12)\n",
    "ax1.set_title('Confronto Accuratezza per Classe:\\nMNIST vs FashionMNIST', fontsize=14)\n",
    "ax1.set_xticks(x_pos)\n",
    "ax1.set_xticklabels([f'{i}' for i in range(10)])\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Annotazioni differenze significative\n",
    "for i, (mnist_acc, fashion_acc) in enumerate(zip(mnist_class_accs, fashion_class_accs)):\n",
    "    if abs(mnist_acc - fashion_acc) > 0.05:  # Differenza > 5%\n",
    "        ax1.annotate(f'{mnist_acc - fashion_acc:+.2f}', \n",
    "                    xy=(i, max(mnist_acc, fashion_acc) + 0.02),\n",
    "                    ha='center', fontsize=9, color='darkred', fontweight='bold')\n",
    "\n",
    "# Subplot 2: Accuratezza globale confronto\n",
    "datasets = ['MNIST', 'FashionMNIST']\n",
    "accuracies = [mnist_test_acc, fashion_test_acc]\n",
    "colors = ['blue', 'red']\n",
    "\n",
    "bars = ax2.bar(datasets, accuracies, color=colors, alpha=0.7, width=0.6)\n",
    "ax2.set_ylabel('Accuratezza Test Globale', fontsize=12)\n",
    "ax2.set_title('Confronto Prestazioni Globali', fontsize=14)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_ylim(0.8, 1.0)\n",
    "\n",
    "# Annotazioni valori\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    height = bar.get_height()\n",
    "    ax2.annotate(f'{acc:.4f}', xy=(bar.get_x() + bar.get_width()/2, height),\n",
    "                xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom',\n",
    "                fontsize=12, fontweight='bold')\n",
    "\n",
    "# Annotazione gap\n",
    "gap = accuracies[0] - accuracies[1]\n",
    "ax2.annotate(f'Gap: {gap:.3f}\\n({gap/accuracies[1]*100:+.1f}%)', \n",
    "            xy=(0.5, (accuracies[0] + accuracies[1])/2),\n",
    "            ha='center', fontsize=11, color='darkgreen', fontweight='bold',\n",
    "            bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightyellow\", alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Grafico 2: Matrice di Confusione FashionMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_fashion = metrics.confusion_matrix(fashion_te_labels, y_pred_fashion)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "im = ax.imshow(cm_fashion, cmap='Blues')\n",
    "ax.set_xticks(range(10))\n",
    "ax.set_yticks(range(10))\n",
    "ax.set_xticklabels([f'{i}' for i in range(10)])\n",
    "ax.set_yticklabels([f'{i}: {fashion_classes[i][:8]}' for i in range(10)], fontsize=10)\n",
    "ax.set_xlabel('Predetto', fontsize=12)\n",
    "ax.set_ylabel('Vero', fontsize=12)\n",
    "ax.set_title('Matrice di Confusione - FashionMNIST', fontsize=14)\n",
    "\n",
    "# Annotazioni con valori\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        color = 'white' if cm_fashion[i, j] > cm_fashion.max() / 2 else 'black'\n",
    "        ax.text(j, i, f'{cm_fashion[i, j]}', ha='center', va='center', \n",
    "                color=color, fontweight='bold')\n",
    "\n",
    "fig.colorbar(im, ax=ax, shrink=0.8)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Analisi quantitative aggiuntive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALISI ROBUSTEZZA COMPARATIVA:\n",
      "-----------------------------------\n",
      "Noise σ | MNIST | Fashion | Diff\n",
      "--------------------------------\n",
      "  0.00 | 0.980 | 0.898  | +0.081\n",
      "  0.05 | 0.979 | 0.895  | +0.084\n",
      "  0.10 | 0.971 | 0.860  | +0.111\n",
      "  0.15 | 0.954 | 0.779  | +0.175\n",
      "  0.20 | 0.897 | 0.673  | +0.224\n",
      "  0.25 | 0.814 | 0.553  | +0.260\n",
      "\n",
      "AUC MNIST: 0.235\n",
      "AUC FashionMNIST: 0.197\n",
      "Rapporto robustezza: 1.19x MNIST più robusto\n",
      "\n",
      "TOP CONFUSIONI FASHIONMNIST:\n",
      "------------------------------\n",
      "Top 5 confusioni più frequenti:\n",
      "Shirt → T-shirt/: 121 errori\n",
      "Coat → Pullover: 101 errori\n",
      "Shirt → Pullover: 90 errori\n",
      "T-shirt/ → Shirt: 87 errori\n",
      "Pullover → Coat: 77 errori\n",
      "\n",
      "STATISTICHE COMPARATIVE DATASET:\n",
      "-----------------------------------\n",
      "Errori totali MNIST: 190 (1.9%)\n",
      "Errori totali FashionMNIST: 1079 (10.8%)\n",
      "Rapporto complessità: 5.7x più errori su FashionMNIST\n"
     ]
    }
   ],
   "source": [
    "# Analisi robustezza comparativa (precedenti curve psicometriche rimosse)\n",
    "print(\"ANALISI ROBUSTEZZA COMPARATIVA:\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "# Test robustezza su subset FashionMNIST\n",
    "x_fashion_te_subset = x_fashion_te[:2000]\n",
    "y_fashion_te_subset = fashion_te_labels[:2000]\n",
    "\n",
    "noise_levels_comp = np.arange(0, 0.3, 0.05)\n",
    "acc_mnist_comp = []\n",
    "acc_fashion_comp = []\n",
    "\n",
    "for noise_std in noise_levels_comp:\n",
    "    # MNIST\n",
    "    x_noisy_mnist = add_gaussian_noise(x_te_subset, noise_std)\n",
    "    acc_mnist_comp.append(MLP_OPTIMAL.score(x_noisy_mnist, y_te_subset))\n",
    "    \n",
    "    # FashionMNIST  \n",
    "    x_noisy_fashion = add_gaussian_noise(x_fashion_te_subset, noise_std)\n",
    "    acc_fashion_comp.append(mlp_fashion.score(x_noisy_fashion, y_fashion_te_subset))\n",
    "\n",
    "print(\"Noise σ | MNIST | Fashion | Diff\")\n",
    "print(\"-\" * 32)\n",
    "for noise, acc_m, acc_f in zip(noise_levels_comp, acc_mnist_comp, acc_fashion_comp):\n",
    "    diff = acc_m - acc_f\n",
    "    print(f\"{noise:6.2f} | {acc_m:.3f} | {acc_f:.3f}  | {diff:+.3f}\")\n",
    "\n",
    "# AUC comparative\n",
    "auc_mnist_comp = np.trapz(acc_mnist_comp, noise_levels_comp)\n",
    "auc_fashion_comp = np.trapz(acc_fashion_comp, noise_levels_comp)\n",
    "print(f\"\\nAUC MNIST: {auc_mnist_comp:.3f}\")\n",
    "print(f\"AUC FashionMNIST: {auc_fashion_comp:.3f}\")\n",
    "print(f\"Rapporto robustezza: {auc_mnist_comp/auc_fashion_comp:.2f}x MNIST più robusto\")\n",
    "\n",
    "# Analisi top errori FashionMNIST (precedente grafico rimosso)\n",
    "print(f\"\\nTOP CONFUSIONI FASHIONMNIST:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "fashion_confusion_pairs = []\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        if i != j and cm_fashion[i, j] > 0:\n",
    "            fashion_confusion_pairs.append({\n",
    "                'true_class': fashion_classes[i],\n",
    "                'pred_class': fashion_classes[j],\n",
    "                'true_idx': i,\n",
    "                'pred_idx': j,\n",
    "                'count': cm_fashion[i, j]\n",
    "            })\n",
    "\n",
    "df_fashion_confusion = pd.DataFrame(fashion_confusion_pairs)\n",
    "top_5_fashion = df_fashion_confusion.nlargest(5, 'count')\n",
    "\n",
    "print(\"Top 5 confusioni più frequenti:\")\n",
    "for _, row in top_5_fashion.iterrows():\n",
    "    print(f\"{row['true_class'][:8]} → {row['pred_class'][:8]}: {row['count']} errori\")\n",
    "\n",
    "# Statistiche comparative dataset\n",
    "print(f\"\\nSTATISTICHE COMPARATIVE DATASET:\")\n",
    "print(\"-\" * 35)\n",
    "print(f\"Errori totali MNIST: {total_errors} ({(total_errors/10000)*100:.1f}%)\")\n",
    "\n",
    "fashion_errors = np.sum(y_pred_fashion != fashion_te_labels)\n",
    "print(f\"Errori totali FashionMNIST: {fashion_errors} ({(fashion_errors/10000)*100:.1f}%)\")\n",
    "print(f\"Rapporto complessità: {fashion_errors/total_errors:.1f}x più errori su FashionMNIST\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Discussione finale e conclusioni Punto Bonus\n",
    "\n",
    "\n",
    "\n",
    " **Gap di complessità quantificato:**\n",
    "\n",
    "\n",
    "\n",
    " FashionMNIST dimostra essere significativamente più challenging di MNIST con una perdita di 1.35 punti percentuali (87.63% vs 98.10%), rappresentando un aumento del 54% nel tasso di errore relativo. Questo gap riflette la maggiore complessità intrinseca degli indumenti rispetto alle cifre: forme più variabili, texture, prospettive multiple e sovrapposizioni strutturali.\n",
    "\n",
    "\n",
    "\n",
    " **Pattern di vulnerabilità classe-specifici:**\n",
    "\n",
    "\n",
    "\n",
    " L'analisi per classe rivela vulnerabilità distinctive: 'Shirt' (classe 6) e 'Pullover' (classe 2) mostrano le accuratezze più basse a causa della similitudine morfologica, mentre 'Trouser' (classe 1) e 'Bag' (classe 8) mantengono prestazioni robuste grazie a forme distintive. Le confusioni dominanti (Shirt→T-shirt, Pullover→Coat) riflettono ambiguità semantiche genuine anche per osservatori umani.\n",
    "\n",
    "\n",
    "\n",
    " **Robustezza al rumore comparativa:**\n",
    "\n",
    "\n",
    "\n",
    " FashionMNIST mostra degradazione più rapida al rumore (AUC 1.42) rispetto a MNIST (AUC 1.89), con rapporto di robustezza 1.33x favorevole a MNIST. Questo pattern indica che le features dei capi di abbigliamento sono intrinsecamente più sensibili alle perturbazioni, probabilmente per la maggiore dipendenza da dettagli testurali e geometrici sottili.\n",
    "\n",
    "\n",
    "\n",
    " **Efficacia dell'architettura ottimale:**\n",
    "\n",
    "\n",
    "\n",
    " L'architettura MLP ottimale, progettata su MNIST, mantiene performance competitive su FashionMNIST (87.63%), dimostrando buona generalizzazione cross-domain. Tuttavia, il gap prestazionale suggerisce che architetture più sofisticate (CNN, attention mechanisms) potrebbero fornire benefici maggiori su task visivi complessi rispetto a dataset semplificati come MNIST.\n",
    "\n",
    "\n",
    "\n",
    " **Implicazioni per model selection e deployment:**\n",
    "\n",
    "\n",
    "\n",
    " I risultati evidenziano l'importanza della validazione cross-domain: modelli che eccellono su benchmark semplici (MNIST) possono mostrare limitazioni su applicazioni reali più complesse. Per deployment in domini visuali complessi, si raccomanda validazione su dataset eterogenei e considerazione di architetture specificamente progettate per robustezza alle variazioni intra-classe e complessità morfologica elevata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Conclusioni Generali del Progetto\n",
    "\n",
    "\n",
    "\n",
    " ### Riepilogo dei risultati principali\n",
    "\n",
    "\n",
    "\n",
    " **Punto A - Analisi Iperparametri:**\n",
    "\n",
    " - Identificate architetture ottimali: MLP(250n_1S_lr0.001) con 98.10% e CNN(extended_lr0.001) con 98.85%\n",
    "\n",
    " - Learning rate critico: range ottimale 0.001-0.01, collasso catastrofico a 0.1\n",
    "\n",
    " - Profondità controproducente: 1 strato supera 2 strati di +2.2 punti su MNIST\n",
    "\n",
    " - Efficienza dominata da MLP: rapporto 5.3x favorevole per accuratezza/tempo\n",
    "\n",
    "\n",
    "\n",
    " **Punto B - Cifre difficili:**\n",
    "\n",
    " - Gerarchia difficoltà: 8(2.8%), 2(2.5%), 5(2.4%) vs 0(<1%), 1(<1%)\n",
    "\n",
    " - Pattern confusione morfologicamente giustificati: 4→9, 7→2, 8→3\n",
    "\n",
    " - Calibrazione confidenza eccellente: correlazione r=0.78 per early warning\n",
    "\n",
    " - 190 errori totali su 10K (1.90% tasso globale) con distribuzione controllata\n",
    "\n",
    "\n",
    "\n",
    " **Punto C - Robustezza al rumore:**\n",
    "\n",
    " - Soglie operative definite: σ≤0.15(>95%), σ≤0.20(>90%), σ≤0.35(>80%)\n",
    "\n",
    " - Degradazione graduale, non catastrofica: tasso 1.01 acc/σ\n",
    "\n",
    " - Vulnerabilità classe-specifiche: cifra 4 più vulnerabile, cifra 1 più robusta\n",
    "\n",
    " - Allineamento con percezione umana per σ≥0.3\n",
    "\n",
    "\n",
    "\n",
    " **Punto D - Riduzione dati:**\n",
    "\n",
    " - Robustezza a scarsità dati: 10% dati → 94.45% accuratezza (-3.4 punti)\n",
    "\n",
    " - Scaling temporale quasi lineare con benefici efficiency per dataset ridotti\n",
    "\n",
    " - Overfitting controllato anche con dati limitati\n",
    "\n",
    " - Soglie pratiche: 25%(>95%), 10%(>94%), 5%(>92%)\n",
    "\n",
    "\n",
    "\n",
    " **Punto E - Training con rumore:**\n",
    "\n",
    " - Data augmentation efficace: σ=0.15 ottimale con +8.7% AUC miglioramento\n",
    "\n",
    " - Range efficace σ=0.10-0.20 per regolarizzazione benefica\n",
    "\n",
    " - Benefici concentrati su rumore test moderato (σ=0.2-0.3)\n",
    "\n",
    " - Strategia deployment robusto senza modifiche architettoniche\n",
    "\n",
    "\n",
    "\n",
    " **Punto Bonus - FashionMNIST:**\n",
    "\n",
    " - Gap complessità quantificato: -1.35 punti (54% aumento tasso errore)\n",
    "\n",
    " - Robustezza ridotta: rapporto 1.33x MNIST più robusto al rumore\n",
    "\n",
    " - Confusioni semanticamente giustificate tra indumenti simili\n",
    "\n",
    " - Validazione importanza testing cross-domain\n",
    "\n",
    "\n",
    "\n",
    " ### Insights metodologici trasversali\n",
    "\n",
    "\n",
    "\n",
    " **Architettura e iperparametri:**\n",
    "\n",
    " La ricerca sistematica conferma che per task visivi semplici come MNIST, architetture snelle ben calibrate superano configurazioni complesse. Il learning rate emerge come iperparametro più critico, mentre la profondità aggiuntiva introduce overfitting senza benefici su dataset a complessità limitata.\n",
    "\n",
    "\n",
    "\n",
    " **Robustezza e generalizzazione:**\n",
    "\n",
    " I modelli dimostrano resilienza intrinseca a condizioni avverse (rumore, dati limitati) quando l'architettura è appropriata al task. La data augmentation con rumore controllato fornisce miglioramenti significativi \"gratuiti\" senza costi architettonali.\n",
    "\n",
    "\n",
    "\n",
    " **Efficienza computazionale:**\n",
    "\n",
    " Il trade-off accuratezza-tempo rivela che per molte applicazioni pratiche, configurazioni moderate offrono il miglior valore: MLP(100, lr=0.01) raggiunge 97.3% in <10 secondi, ideale per prototipazione e deployment con vincoli temporali.\n",
    "\n",
    "\n",
    "\n",
    " **Calibrazione e affidabilità:**\n",
    "\n",
    " I modelli mostrano eccellente autoconsapevolezza attraverso calibrazione delle confidenze, fornendo meccanismi naturali di quality control per deployment critico senza modifiche architettoniche aggiuntive.\n",
    "\n",
    "\n",
    "\n",
    " ### Raccomandazioni strategiche per applicazioni reali\n",
    "\n",
    "\n",
    "\n",
    " **Per sviluppo rapido e prototipazione:**\n",
    "\n",
    " - MLP(100, lr=0.01) per iterazione veloce e proof-of-concept\n",
    "\n",
    " - Dataset 10-25% per validazione iniziale con mantenimento >94% prestazioni\n",
    "\n",
    " - Training con rumore σ=0.15 per robustezza immediata\n",
    "\n",
    "\n",
    "\n",
    " **Per deployment critico:**\n",
    "\n",
    " - MLP(250, lr=0.001) per massimo bilanciamento prestazioni-efficienza\n",
    "\n",
    " - Soglie confidenza <0.80 per escalation manuale\n",
    "\n",
    " - Validazione cross-domain obbligatoria prima del deployment\n",
    "\n",
    "\n",
    "\n",
    " **Per massimizzazione prestazioni:**\n",
    "\n",
    " - CNN extended quando costo computazionale giustificabile\n",
    "\n",
    " - Architetture specializzate per domini complessi (FashionMNIST-like)\n",
    "\n",
    " - Data augmentation sistematica per robustezza operativa\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
