{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e707995",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# INTELLIGENZA ARTIFICIALE - Mini-Progetto Individuale\n",
    "**Prof. Marco Zorzi, Dr. Alberto Testolin**\n",
    "\n",
    "**Nome**: [INSERIRE NOME]  \n",
    "**Cognome**: [INSERIRE COGNOME]  \n",
    "**Matricola**: [INSERIRE MATRICOLA]  \n",
    "**Data**: [INSERIRE DATA]\n",
    "\n",
    "---\n",
    "\n",
    "## Obiettivo del Progetto\n",
    "Studiare il riconoscimento di cifre manoscritte attraverso reti neurali artificiali, \n",
    "analizzando sistematicamente l'effetto delle architetture, degli iper-parametri e \n",
    "delle tecniche di regolarizzazione su modelli Multi-Layer Perceptron (MLP) e \n",
    "Convolutional Neural Networks (CNN).\n",
    "\n",
    "## Metodologia Generale\n",
    "Il progetto segue un approccio sperimentale rigoroso basato sui principi di \n",
    "riproducibilità scientifica, utilizzando il dataset MNIST come benchmark standard \n",
    "per il riconoscimento di cifre manoscritte. Ogni esperimento è progettato per \n",
    "isolare l'effetto di specifici fattori architetturali e algoritmici."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d50199b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup delle librerie e configurazione dell'ambiente\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurazione per TensorFlow/Keras (CNN)\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    HAS_TENSORFLOW = True\n",
    "    tf.random.set_seed(42)\n",
    "    # Configurazione per ridurre output verboso\n",
    "    tf.get_logger().setLevel('ERROR')\n",
    "    print(f\"TensorFlow {tf.__version__} disponibile\")\n",
    "except ImportError:\n",
    "    HAS_TENSORFLOW = False\n",
    "    print(\"TensorFlow non disponibile - verranno utilizzati solo modelli MLP\")\n",
    "\n",
    "# Configurazione riproducibilità\n",
    "np.random.seed(42)\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"Setup dell'ambiente completato\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6438e8f",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "---\n",
    "# PUNTO A: Analisi Architetturale [2 punti]\n",
    "\n",
    "## Obiettivo Specifico\n",
    "Analizzare sistematicamente l'effetto di diversi fattori architetturali e algoritmici \n",
    "sulle performance di modelli MLP e CNN per il riconoscimento di cifre manoscritte.\n",
    "\n",
    "## Fattori Analizzati\n",
    "1. **Profondità della rete**: Confronto tra 1 e 2 strati nascosti per MLP\n",
    "2. **Capacità del modello**: Variazione del numero di neuroni (64, 128, 256)\n",
    "3. **Learning rate**: Analisi critica dell'effetto di LR su convergenza e stabilità\n",
    "4. **Architettura**: Confronto sistematico MLP vs CNN\n",
    "\n",
    "## Configurazione Sperimentale\n",
    "- **Total configurazioni**: 30 esperimenti (18 MLP + 12 CNN)\n",
    "- **Controllo overfitting**: Early stopping con validation split\n",
    "- **Efficienza**: Limite iterazioni max_iter=50 con tolerance=0.001\n",
    "- **Riproducibilità**: Random state fisso per tutti gli esperimenti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20093f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caricamento e preprocessing del dataset MNIST\n",
    "print(\"Caricamento dataset MNIST...\")\n",
    "\n",
    "if HAS_TENSORFLOW:\n",
    "    (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "else:\n",
    "    # Fallback: dataset sintetico ridotto per test senza TensorFlow\n",
    "    print(\"Creazione dataset sintetico per test...\")\n",
    "    x_train = np.random.randint(0, 255, (6000, 28, 28), dtype=np.uint8)\n",
    "    y_train = np.random.randint(0, 10, 6000)\n",
    "    x_test = np.random.randint(0, 255, (1000, 28, 28), dtype=np.uint8)\n",
    "    y_test = np.random.randint(0, 10, 1000)\n",
    "\n",
    "print(f\"Dataset caricato: {x_train.shape[0]} esempi di training, {x_test.shape[0]} esempi di test\")\n",
    "\n",
    "# Preprocessing per MLP: flattening e normalizzazione\n",
    "x_train_mlp = x_train.reshape(x_train.shape[0], -1).astype('float32') / 255.0\n",
    "x_test_mlp = x_test.reshape(x_test.shape[0], -1).astype('float32') / 255.0\n",
    "\n",
    "# Preprocessing per CNN: reshape 4D e normalizzazione\n",
    "if HAS_TENSORFLOW:\n",
    "    x_train_cnn = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "    x_test_cnn = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "\n",
    "print(\"Preprocessing completato\")\n",
    "\n",
    "# Visualizzazione di esempi rappresentativi per ogni classe\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 6))\n",
    "for i in range(10):\n",
    "    idx = np.where(y_train == i)[0][0]\n",
    "    ax = axes[i//5, i%5]\n",
    "    ax.imshow(x_train[idx], cmap='gray')\n",
    "    ax.set_title(f'Cifra {i}')\n",
    "    ax.axis('off')\n",
    "plt.suptitle('Campioni Rappresentativi del Dataset MNIST', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3fdfa6",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Progettazione delle Configurazioni Sperimentali\n",
    "\n",
    "### Razionale Scientifico\n",
    "La progettazione degli esperimenti segue un approccio factorial design per isolare \n",
    "l'effetto di ogni fattore:\n",
    "\n",
    "1. **Learning Rate (Fattore Critico)**: Il learning rate è noto essere uno degli \n",
    "   iper-parametri più influenti nell'ottimizzazione delle reti neurali. Testiamo \n",
    "   tre ordini di grandezza (0.001, 0.01, 0.1) per identificare il regime ottimale.\n",
    "\n",
    "2. **Capacità del Modello**: La variazione sistematica del numero di neuroni \n",
    "   permette di studiare il trade-off bias-variance e identificare la capacità \n",
    "   ottimale per il task.\n",
    "\n",
    "3. **Profondità Architetturale**: Il confronto 1 vs 2 strati nascosti esplora \n",
    "   l'effetto della profondità sulla capacità rappresentazionale.\n",
    "\n",
    "### Controlli Sperimentali\n",
    "- **Early Stopping**: Previene overfitting e riduce tempo computazionale\n",
    "- **Validation Split**: 10% dei dati di training per monitoraggio convergenza\n",
    "- **Patience**: 10 iterazioni senza miglioramento per terminazione anticipata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466bf6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definizione configurazioni MLP\n",
    "print(\"Configurazione esperimenti MLP...\")\n",
    "\n",
    "mlp_configs = []\n",
    "for layers in [1, 2]:  # Effetto profondità\n",
    "    for neurons in [64, 128, 256]:  # Effetto capacità\n",
    "        for lr in [0.001, 0.01, 0.1]:  # Effetto learning rate\n",
    "            hidden = (neurons,) if layers == 1 else (neurons, neurons)\n",
    "            \n",
    "            config = {\n",
    "                'hidden_layer_sizes': hidden,\n",
    "                'learning_rate_init': lr,\n",
    "                'solver': 'adam',  # Ottimizzatore affidabile e veloce\n",
    "                'max_iter': 50,\n",
    "                'tol': 0.001,  # Tolerance per early stopping\n",
    "                'early_stopping': True,\n",
    "                'validation_fraction': 0.1,\n",
    "                'n_iter_no_change': 10,  # Patience per early stopping\n",
    "                'random_state': 42,\n",
    "                'name': f\"MLP_{layers}L_{neurons}N_LR{lr}\",\n",
    "                'layers': layers,\n",
    "                'neurons': neurons,\n",
    "                'lr': lr\n",
    "            }\n",
    "            mlp_configs.append(config)\n",
    "\n",
    "print(f\"Configurazioni MLP definite: {len(mlp_configs)}\")\n",
    "\n",
    "# Definizione configurazioni CNN\n",
    "cnn_configs = []\n",
    "if HAS_TENSORFLOW:\n",
    "    print(\"Configurazione esperimenti CNN...\")\n",
    "    \n",
    "    for arch in ['base', 'extended']:  # Complessità architetturale\n",
    "        for neurons in [64, 128]:  # Dimensione layer denso finale\n",
    "            for lr in [0.001, 0.01, 0.1]:  # Learning rate\n",
    "                config = {\n",
    "                    'architecture': arch,\n",
    "                    'dense_neurons': neurons,\n",
    "                    'learning_rate': lr,\n",
    "                    'batch_size': 32,\n",
    "                    'epochs': 50,\n",
    "                    'early_stopping_patience': 5,\n",
    "                    'name': f\"CNN_{arch}_{neurons}N_LR{lr}\",\n",
    "                    'arch_type': arch,\n",
    "                    'neurons': neurons,\n",
    "                    'lr': lr\n",
    "                }\n",
    "                cnn_configs.append(config)\n",
    "    \n",
    "    print(f\"Configurazioni CNN definite: {len(cnn_configs)}\")\n",
    "else:\n",
    "    print(\"CNN saltate - TensorFlow non disponibile\")\n",
    "\n",
    "total_configs = len(mlp_configs) + len(cnn_configs)\n",
    "print(f\"Total esperimenti pianificati: {total_configs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04eac4a",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 1
   },
   "source": [
    "### Architetture CNN Specifiche\n",
    "\n",
    "#### CNN Base (Baseline)\n",
    "- **Conv2D(32, 3x3, ReLU)**: Feature extraction con 32 filtri 3x3\n",
    "- **Flatten**: Conversione da 2D a 1D per layer denso\n",
    "- **Dense(neurons, ReLU)**: Classification layer con dimensione variabile\n",
    "- **Dense(10, Softmax)**: Output layer per 10 classi\n",
    "\n",
    "#### CNN Extended (Confronto Profondità)\n",
    "- **Conv2D(32, 3x3, ReLU)**: Primo layer convoluzionale\n",
    "- **Conv2D(64, 3x3, ReLU)**: Secondo layer con più filtri\n",
    "- **Flatten + Dense**: Identico alla versione base\n",
    "\n",
    "Questa progettazione permette di isolare l'effetto della profondità convoluzionale \n",
    "mantenendo costanti gli altri fattori."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046bb96e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def train_mlp_experiment(x_train, y_train, x_test, y_test, config):\n",
    "    \"\"\"\n",
    "    Funzione per training sistematico di modelli MLP con logging completo.\n",
    "    \n",
    "    Args:\n",
    "        x_train, y_train: Dati di training\n",
    "        x_test, y_test: Dati di test  \n",
    "        config: Dizionario con configurazione del modello\n",
    "        \n",
    "    Returns:\n",
    "        Dizionario con risultati completi dell'esperimento\n",
    "    \"\"\"\n",
    "    print(f\"Training {config['name']}...\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Creazione modello con configurazione specifica\n",
    "    mlp = MLPClassifier(\n",
    "        hidden_layer_sizes=config['hidden_layer_sizes'],\n",
    "        learning_rate_init=config['learning_rate_init'],\n",
    "        solver=config['solver'],\n",
    "        max_iter=config['max_iter'],\n",
    "        tol=config['tol'],\n",
    "        early_stopping=config['early_stopping'],\n",
    "        validation_fraction=config['validation_fraction'],\n",
    "        n_iter_no_change=config['n_iter_no_change'],\n",
    "        random_state=config['random_state']\n",
    "    )\n",
    "    \n",
    "    # Training con gestione warning\n",
    "    mlp.fit(x_train, y_train)\n",
    "    \n",
    "    # Valutazione performance\n",
    "    train_accuracy = mlp.score(x_train, y_train)\n",
    "    test_accuracy = mlp.score(x_test, y_test)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Logging risultati\n",
    "    print(f\"  Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"  Train Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"  Training Time: {training_time:.1f}s\")\n",
    "    print(f\"  Iterations: {mlp.n_iter_}\")\n",
    "    \n",
    "    # Risultati strutturati\n",
    "    results = {\n",
    "        'model': mlp,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'train_accuracy': train_accuracy,\n",
    "        'training_time': training_time,\n",
    "        'iterations': mlp.n_iter_,\n",
    "        'converged': mlp.n_iter_ < config['max_iter'],\n",
    "        'overfitting_gap': train_accuracy - test_accuracy\n",
    "    }\n",
    "    \n",
    "    # Aggiunta configurazione per analisi successive\n",
    "    results.update(config)\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"Funzione training MLP definita\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712ccf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_model(arch_type, neurons, lr):\n",
    "    \"\"\"\n",
    "    Costruzione di modelli CNN con architetture specificate.\n",
    "    \n",
    "    Args:\n",
    "        arch_type: 'base' o 'extended'\n",
    "        neurons: Numero neuroni nel layer denso\n",
    "        lr: Learning rate\n",
    "        \n",
    "    Returns:\n",
    "        Modello Keras compilato\n",
    "    \"\"\"\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    if arch_type == 'base':\n",
    "        # Architettura CNN baseline\n",
    "        model.add(keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)))\n",
    "        model.add(keras.layers.Flatten())\n",
    "        model.add(keras.layers.Dense(neurons, activation='relu'))\n",
    "        \n",
    "    elif arch_type == 'extended':\n",
    "        # Architettura CNN più profonda\n",
    "        model.add(keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)))\n",
    "        model.add(keras.layers.Conv2D(64, (3,3), activation='relu'))\n",
    "        model.add(keras.layers.Flatten())\n",
    "        model.add(keras.layers.Dense(neurons, activation='relu'))\n",
    "    \n",
    "    # Output layer comune\n",
    "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "    \n",
    "    # Compilazione con ottimizzatore Adam\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_cnn_experiment(x_train, y_train, x_test, y_test, config):\n",
    "    \"\"\"\n",
    "    Funzione per training sistematico di modelli CNN.\n",
    "    \n",
    "    Args:\n",
    "        x_train, y_train: Dati di training\n",
    "        x_test, y_test: Dati di test\n",
    "        config: Configurazione del modello\n",
    "        \n",
    "    Returns:\n",
    "        Dizionario con risultati completi\n",
    "    \"\"\"\n",
    "    if not HAS_TENSORFLOW:\n",
    "        return None\n",
    "        \n",
    "    print(f\"Training {config['name']}...\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Costruzione modello\n",
    "    model = build_cnn_model(\n",
    "        config['architecture'], \n",
    "        config['dense_neurons'], \n",
    "        config['learning_rate']\n",
    "    )\n",
    "    \n",
    "    # Configurazione early stopping\n",
    "    early_stop = keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=config['early_stopping_patience'],\n",
    "        restore_best_weights=True,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # Training con validation split\n",
    "    history = model.fit(\n",
    "        x_train, y_train,\n",
    "        batch_size=config['batch_size'],\n",
    "        epochs=config['epochs'],\n",
    "        validation_split=0.1,\n",
    "        callbacks=[early_stop],\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # Valutazione finale\n",
    "    train_loss, train_accuracy = model.evaluate(x_train, y_train, verbose=0)\n",
    "    test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Logging risultati\n",
    "    print(f\"  Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"  Train Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"  Training Time: {training_time:.1f}s\")\n",
    "    print(f\"  Epochs: {len(history.history['loss'])}\")\n",
    "    \n",
    "    # Risultati strutturati\n",
    "    results = {\n",
    "        'model': model,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'train_accuracy': train_accuracy,\n",
    "        'training_time': training_time,\n",
    "        'epochs_trained': len(history.history['loss']),\n",
    "        'converged': len(history.history['loss']) < config['epochs'],\n",
    "        'overfitting_gap': train_accuracy - test_accuracy,\n",
    "        'history': history\n",
    "    }\n",
    "    \n",
    "    # Aggiunta configurazione\n",
    "    results.update(config)\n",
    "    \n",
    "    return results\n",
    "\n",
    "if HAS_TENSORFLOW:\n",
    "    print(\"Funzioni training CNN definite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5372f3",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Esecuzione Esperimenti MLP\n",
    "\n",
    "### Metodologia di Valutazione\n",
    "Per ogni configurazione MLP monitoriamo:\n",
    "- **Test Accuracy**: Performance su dati non visti (metrica primaria)\n",
    "- **Train Accuracy**: Performance su dati di training (per rilevare overfitting)\n",
    "- **Training Time**: Efficienza computazionale\n",
    "- **Convergenza**: Numero di iterazioni necessarie\n",
    "- **Early Stopping**: Efficacia della regolarizzazione\n",
    "\n",
    "### Aspettative Teoriche\n",
    "1. **LR = 0.001**: Convergenza lenta ma stabile, buona generalizzazione\n",
    "2. **LR = 0.01**: Sweet spot tra velocità e stabilità\n",
    "3. **LR = 0.1**: Rischio di instabilità e oscillazioni\n",
    "4. **Più neuroni**: Migliore capacità rappresentazionale, rischio overfitting\n",
    "5. **Più strati**: Potenziale miglioramento, maggiore complessità"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c52244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esecuzione esperimenti MLP\n",
    "print(\"INIZIO ESPERIMENTI MLP\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "mlp_results = []\n",
    "mlp_start_time = time.time()\n",
    "\n",
    "for i, config in enumerate(mlp_configs):\n",
    "    print(f\"\\n[{i+1}/{len(mlp_configs)}] \", end=\"\")\n",
    "    \n",
    "    try:\n",
    "        result = train_mlp_experiment(x_train_mlp, y_train, x_test_mlp, y_test, config)\n",
    "        mlp_results.append(result)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ERRORE in {config['name']}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "mlp_total_time = time.time() - mlp_start_time\n",
    "\n",
    "print(f\"\\nEsperimenti MLP completati!\")\n",
    "print(f\"Modelli trainati con successo: {len(mlp_results)}/{len(mlp_configs)}\")\n",
    "print(f\"Tempo totale MLP: {mlp_total_time:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfd64b3",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Esecuzione Esperimenti CNN\n",
    "\n",
    "### Considerazioni Architetturali CNN\n",
    "Le Convolutional Neural Networks sono progettate specificamente per dati con \n",
    "struttura spaziale come le immagini. I vantaggi teorici rispetto agli MLP includono:\n",
    "\n",
    "1. **Parameter Sharing**: Riduzione parametri attraverso condivisione pesi\n",
    "2. **Local Connectivity**: Sfruttamento correlazioni spaziali locali  \n",
    "3. **Translation Invariance**: Robustezza a traslazioni dell'input\n",
    "4. **Hierarchical Feature Learning**: Estrazione features da semplici a complesse\n",
    "\n",
    "### Configurazioni Testate\n",
    "- **Base**: Architettura minimalista per baseline\n",
    "- **Extended**: Aggiunta profondità convoluzionale per confronto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885a152f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esecuzione esperimenti CNN\n",
    "cnn_results = []\n",
    "\n",
    "if HAS_TENSORFLOW and cnn_configs:\n",
    "    print(\"\\nINIZIO ESPERIMENTI CNN\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    cnn_start_time = time.time()\n",
    "    \n",
    "    for i, config in enumerate(cnn_configs):\n",
    "        print(f\"\\n[{i+1}/{len(cnn_configs)}] \", end=\"\")\n",
    "        \n",
    "        try:\n",
    "            result = train_cnn_experiment(x_train_cnn, y_train, x_test_cnn, y_test, config)\n",
    "            if result:\n",
    "                cnn_results.append(result)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  ERRORE in {config['name']}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    cnn_total_time = time.time() - cnn_start_time\n",
    "    \n",
    "    print(f\"\\nEsperimenti CNN completati!\")\n",
    "    print(f\"Modelli trainati con successo: {len(cnn_results)}/{len(cnn_configs)}\")\n",
    "    print(f\"Tempo totale CNN: {cnn_total_time:.1f}s\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\nCNN experiments skipped - TensorFlow non disponibile\")\n",
    "    cnn_total_time = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4327685b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidamento risultati per analisi\n",
    "all_results = mlp_results + cnn_results\n",
    "total_experiments = len(all_results)\n",
    "\n",
    "print(f\"\\nRIASSUNTO ESPERIMENTI\")\n",
    "print(\"=\" * 30)\n",
    "print(f\"MLP experiments: {len(mlp_results)}\")\n",
    "print(f\"CNN experiments: {len(cnn_results)}\")\n",
    "print(f\"Total experiments: {total_experiments}\")\n",
    "print(f\"Total time: {mlp_total_time + cnn_total_time:.1f}s\")\n",
    "\n",
    "if total_experiments > 0:\n",
    "    avg_accuracy = np.mean([r['test_accuracy'] for r in all_results])\n",
    "    print(f\"Average test accuracy: {avg_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b84a54e",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "---\n",
    "## Analisi Comparativa dei Risultati\n",
    "\n",
    "### Metodologia di Analisi\n",
    "L'analisi dei risultati segue un approccio multi-dimensionale per identificare \n",
    "i fattori più influenti sulle performance:\n",
    "\n",
    "1. **Ranking Performance**: Identificazione dei modelli top-performing\n",
    "2. **Analisi Learning Rate**: Effetto critico del LR su convergenza e generalizzazione\n",
    "3. **Confronto Architetturale**: MLP vs CNN, profondità vs larghezza\n",
    "4. **Efficienza Computazionale**: Trade-off performance vs tempo di training\n",
    "5. **Analisi Overfitting**: Gap train-test come indicatore di generalizzazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc64bc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "if total_experiments > 0:\n",
    "    print(\"ANALISI PERFORMANCE\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # TOP 5 modelli per test accuracy\n",
    "    top_models = sorted(all_results, key=lambda x: x['test_accuracy'], reverse=True)[:5]\n",
    "    \n",
    "    print(\"\\nTOP 5 MODELLI (Test Accuracy):\")\n",
    "    print(\"-\" * 60)\n",
    "    for i, model in enumerate(top_models):\n",
    "        print(f\"{i+1}. {model['name']:25} {model['test_accuracy']:.4f} \"\n",
    "              f\"({model['training_time']:4.1f}s)\")\n",
    "    \n",
    "    # Analisi per Learning Rate\n",
    "    print(f\"\\nANALISI LEARNING RATE:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    lr_analysis = {}\n",
    "    for lr in [0.001, 0.01, 0.1]:\n",
    "        lr_models = [r for r in all_results if r['lr'] == lr]\n",
    "        if lr_models:\n",
    "            avg_acc = np.mean([r['test_accuracy'] for r in lr_models])\n",
    "            avg_time = np.mean([r['training_time'] for r in lr_models])\n",
    "            convergence_rate = np.mean([r['converged'] for r in lr_models])\n",
    "            \n",
    "            lr_analysis[lr] = {\n",
    "                'accuracy': avg_acc,\n",
    "                'time': avg_time,\n",
    "                'convergence': convergence_rate\n",
    "            }\n",
    "            \n",
    "            print(f\"LR {lr:5.3f}: Acc={avg_acc:.4f}, Time={avg_time:4.1f}s, \"\n",
    "                  f\"Conv={convergence_rate*100:4.1f}%\")\n",
    "    \n",
    "    # Confronto MLP vs CNN\n",
    "    if mlp_results and cnn_results:\n",
    "        print(f\"\\nCONFRONTO MLP vs CNN:\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        best_mlp = max(mlp_results, key=lambda x: x['test_accuracy'])\n",
    "        best_cnn = max(cnn_results, key=lambda x: x['test_accuracy'])\n",
    "        \n",
    "        print(f\"Best MLP: {best_mlp['name']:20} {best_mlp['test_accuracy']:.4f}\")\n",
    "        print(f\"Best CNN: {best_cnn['name']:20} {best_cnn['test_accuracy']:.4f}\")\n",
    "        print(f\"CNN Advantage: {best_cnn['test_accuracy'] - best_mlp['test_accuracy']:+.4f}\")\n",
    "    \n",
    "    # Analisi convergenza\n",
    "    converged_count = sum(1 for r in all_results if r['converged'])\n",
    "    print(f\"\\nCONVERGENZA:\")\n",
    "    print(\"-\" * 20)\n",
    "    print(f\"Modelli convergenti: {converged_count}/{total_experiments} \"\n",
    "          f\"({100*converged_count/total_experiments:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235bc344",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "### Analisi Overfitting e Generalizzazione\n",
    "\n",
    "L'analisi del gap tra training e test accuracy fornisce insights cruciali sulla \n",
    "capacità di generalizzazione dei modelli:\n",
    "\n",
    "- **Gap < 0.02**: Ottima generalizzazione\n",
    "- **0.02 ≤ Gap < 0.05**: Generalizzazione accettabile  \n",
    "- **Gap ≥ 0.05**: Segnali di overfitting\n",
    "\n",
    "### Efficienza Computazionale\n",
    "Il rapporto performance/tempo identifica le configurazioni più efficienti per \n",
    "deployment pratico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5ea724",
   "metadata": {},
   "outputs": [],
   "source": [
    "if total_experiments > 0:\n",
    "    # Analisi overfitting\n",
    "    print(\"ANALISI OVERFITTING:\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    overfitting_analysis = []\n",
    "    for result in all_results:\n",
    "        gap = result['overfitting_gap']\n",
    "        overfitting_analysis.append({\n",
    "            'name': result['name'],\n",
    "            'gap': gap,\n",
    "            'test_acc': result['test_accuracy']\n",
    "        })\n",
    "    \n",
    "    # Ordinamento per gap crescente (migliore generalizzazione)\n",
    "    overfitting_analysis.sort(key=lambda x: x['gap'])\n",
    "    \n",
    "    print(\"Migliore generalizzazione (gap train-test più basso):\")\n",
    "    for i, model in enumerate(overfitting_analysis[:3]):\n",
    "        print(f\"{i+1}. {model['name']:25} Gap={model['gap']:+.4f} \"\n",
    "              f\"Acc={model['test_acc']:.4f}\")\n",
    "    \n",
    "    # Modelli con overfitting\n",
    "    overfitted = [m for m in overfitting_analysis if m['gap'] > 0.05]\n",
    "    if overfitted:\n",
    "        print(f\"\\nModelli con possibile overfitting (gap > 0.05): {len(overfitted)}\")\n",
    "        for model in overfitted[:3]:\n",
    "            print(f\"  {model['name']:25} Gap={model['gap']:+.4f}\")\n",
    "    \n",
    "    # Analisi efficienza (performance per secondo)\n",
    "    print(f\"\\nEFFICIENZA COMPUTAZIONALE:\")\n",
    "    print(\"-\" * 35)\n",
    "    \n",
    "    efficiency_scores = []\n",
    "    for result in all_results:\n",
    "        efficiency = result['test_accuracy'] / result['training_time']\n",
    "        efficiency_scores.append({\n",
    "            'name': result['name'],\n",
    "            'efficiency': efficiency,\n",
    "            'accuracy': result['test_accuracy'],\n",
    "            'time': result['training_time']\n",
    "        })\n",
    "    \n",
    "    efficiency_scores.sort(key=lambda x: x['efficiency'], reverse=True)\n",
    "    \n",
    "    print(\"Modelli più efficienti (accuracy/second):\")\n",
    "    for i, model in enumerate(efficiency_scores[:3]):\n",
    "        print(f\"{i+1}. {model['name']:25} \"\n",
    "              f\"Eff={model['efficiency']:.6f} \"\n",
    "              f\"Acc={model['accuracy']:.4f} \"\n",
    "              f\"Time={model['time']:4.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f06d1f",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Visualizzazioni Comparative\n",
    "\n",
    "Le visualizzazioni seguenti forniscono una comprensione intuitiva dei risultati \n",
    "attraverso rappresentazioni grafiche multi-dimensionali che evidenziano pattern \n",
    "e relazioni tra i diversi fattori analizzati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11463168",
   "metadata": {},
   "outputs": [],
   "source": [
    "if total_experiments > 0:\n",
    "    # Creazione figura con subplots multipli\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    fig.suptitle('Punto A: Analisi Architetturale - Risultati Comparativi', fontsize=16)\n",
    "    \n",
    "    # Subplot 1: Effetto Learning Rate\n",
    "    ax1 = axes[0, 0]\n",
    "    lr_values = [0.001, 0.01, 0.1]\n",
    "    \n",
    "    if mlp_results:\n",
    "        mlp_lr_accs = []\n",
    "        for lr in lr_values:\n",
    "            lr_accs = [r['test_accuracy'] for r in mlp_results if r['lr'] == lr]\n",
    "            mlp_lr_accs.append(np.mean(lr_accs) if lr_accs else 0)\n",
    "        \n",
    "        x_pos = np.arange(len(lr_values))\n",
    "        width = 0.35\n",
    "        \n",
    "        ax1.bar(x_pos - width/2, mlp_lr_accs, width, label='MLP', alpha=0.8, color='skyblue')\n",
    "    \n",
    "    if cnn_results:\n",
    "        cnn_lr_accs = []\n",
    "        for lr in lr_values:\n",
    "            lr_accs = [r['test_accuracy'] for r in cnn_results if r['lr'] == lr]\n",
    "            cnn_lr_accs.append(np.mean(lr_accs) if lr_accs else 0)\n",
    "        \n",
    "        ax1.bar(x_pos + width/2, cnn_lr_accs, width, label='CNN', alpha=0.8, color='lightcoral')\n",
    "    \n",
    "    ax1.set_xlabel('Learning Rate')\n",
    "    ax1.set_ylabel('Test Accuracy Media')\n",
    "    ax1.set_title('Effetto Learning Rate su Performance')\n",
    "    ax1.set_xticks(x_pos)\n",
    "    ax1.set_xticklabels(lr_values)\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Subplot 2: Analisi Overfitting\n",
    "    ax2 = axes[0, 1]\n",
    "    train_accs = [r['train_accuracy'] for r in all_results]\n",
    "    test_accs = [r['test_accuracy'] for r in all_results]\n",
    "    colors = ['blue' if 'MLP' in r['name'] else 'red' for r in all_results]\n",
    "    \n",
    "    ax2.scatter(train_accs, test_accs, c=colors, alpha=0.6, s=50)\n",
    "    ax2.plot([0.8, 1.0], [0.8, 1.0], 'k--', alpha=0.5, label='Perfect Generalization')\n",
    "    ax2.set_xlabel('Train Accuracy')\n",
    "    ax2.set_ylabel('Test Accuracy')\n",
    "    ax2.set_title('Analisi Overfitting (Train vs Test)')\n",
    "    ax2.legend(['Perfect Generalization', 'MLP', 'CNN'])\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Subplot 3: Efficienza (Tempo vs Performance)\n",
    "    ax3 = axes[0, 2]\n",
    "    times = [r['training_time'] for r in all_results]\n",
    "    ax3.scatter(times, test_accs, c=colors, alpha=0.6, s=50)\n",
    "    ax3.set_xlabel('Training Time (s)')\n",
    "    ax3.set_ylabel('Test Accuracy')\n",
    "    ax3.set_title('Trade-off Efficienza vs Performance')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Subplot 4: Distribuzione Performance per Architettura\n",
    "    ax4 = axes[1, 0]\n",
    "    if mlp_results and cnn_results:\n",
    "        mlp_accs = [r['test_accuracy'] for r in mlp_results]\n",
    "        cnn_accs = [r['test_accuracy'] for r in cnn_results]\n",
    "        \n",
    "        ax4.boxplot([mlp_accs, cnn_accs], labels=['MLP', 'CNN'])\n",
    "        ax4.set_ylabel('Test Accuracy')\n",
    "        ax4.set_title('Distribuzione Performance per Architettura')\n",
    "        ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Subplot 5: Analisi Convergenza\n",
    "    ax5 = axes[1, 1]\n",
    "    converged_accs = [r['test_accuracy'] for r in all_results if r['converged']]\n",
    "    not_converged_accs = [r['test_accuracy'] for r in all_results if not r['converged']]\n",
    "    \n",
    "    data_to_plot = []\n",
    "    labels = []\n",
    "    if converged_accs:\n",
    "        data_to_plot.append(converged_accs)\n",
    "        labels.append(f'Converged (n={len(converged_accs)})')\n",
    "    if not_converged_accs:\n",
    "        data_to_plot.append(not_converged_accs)\n",
    "        labels.append(f'Not Converged (n={len(not_converged_accs)})')\n",
    "    \n",
    "    if data_to_plot:\n",
    "        ax5.boxplot(data_to_plot, labels=labels)\n",
    "    ax5.set_ylabel('Test Accuracy')\n",
    "    ax5.set_title('Performance vs Convergenza')\n",
    "    ax5.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Subplot 6: Heatmap Learning Rate vs Neurons (MLP)\n",
    "    ax6 = axes[1, 2]\n",
    "    if mlp_results:\n",
    "        # Creazione matrice per heatmap\n",
    "        lr_vals = [0.001, 0.01, 0.1]\n",
    "        neuron_vals = [64, 128, 256]\n",
    "        \n",
    "        heatmap_data = np.zeros((len(lr_vals), len(neuron_vals)))\n",
    "        \n",
    "        for i, lr in enumerate(lr_vals):\n",
    "            for j, neurons in enumerate(neuron_vals):\n",
    "                matching = [r for r in mlp_results if r['lr'] == lr and r['neurons'] == neurons]\n",
    "                if matching:\n",
    "                    heatmap_data[i, j] = np.mean([r['test_accuracy'] for r in matching])\n",
    "        \n",
    "        im = ax6.imshow(heatmap_data, cmap='viridis', aspect='auto')\n",
    "        ax6.set_xticks(range(len(neuron_vals)))\n",
    "        ax6.set_yticks(range(len(lr_vals)))\n",
    "        ax6.set_xticklabels(neuron_vals)\n",
    "        ax6.set_yticklabels(lr_vals)\n",
    "        ax6.set_xlabel('Neuroni')\n",
    "        ax6.set_ylabel('Learning Rate')\n",
    "        ax6.set_title('Heatmap Performance MLP')\n",
    "        \n",
    "        # Aggiunta valori numerici\n",
    "        for i in range(len(lr_vals)):\n",
    "            for j in range(len(neuron_vals)):\n",
    "                text = ax6.text(j, i, f'{heatmap_data[i, j]:.3f}',\n",
    "                               ha=\"center\", va=\"center\", color=\"white\")\n",
    "        \n",
    "        plt.colorbar(im, ax=ax6)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c141bdd",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Selezione Modelli Ottimali\n",
    "\n",
    "### Criteri di Selezione\n",
    "La selezione dei modelli ottimali per i punti successivi del progetto si basa su \n",
    "criteri multipli:\n",
    "\n",
    "1. **Performance**: Test accuracy come metrica primaria\n",
    "2. **Generalizzazione**: Gap train-test minimizzato\n",
    "3. **Stabilità**: Convergenza affidabile\n",
    "4. **Rappresentatività**: Diversità architetturale per analisi comparative\n",
    "\n",
    "### Modelli Candidati\n",
    "I modelli selezionati serviranno come base per:\n",
    "- **Punto B**: Analisi errori (miglior MLP)\n",
    "- **Punto C**: Curve psicometriche (miglior CNN)  \n",
    "- **Punto D**: Dataset ridotto (entrambi i migliori)\n",
    "- **Punto E**: Training con rumore (miglior CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147831e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if total_experiments > 0:\n",
    "    print(\"SELEZIONE MODELLI OTTIMALI\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Identificazione migliori modelli\n",
    "    best_overall = max(all_results, key=lambda x: x['test_accuracy'])\n",
    "    \n",
    "    best_mlp = None\n",
    "    if mlp_results:\n",
    "        best_mlp = max(mlp_results, key=lambda x: x['test_accuracy'])\n",
    "    \n",
    "    best_cnn = None  \n",
    "    if cnn_results:\n",
    "        best_cnn = max(cnn_results, key=lambda x: x['test_accuracy'])\n",
    "    \n",
    "    print(\"MODELLI SELEZIONATI:\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    print(f\"Best Overall: {best_overall['name']}\")\n",
    "    print(f\"  Test Accuracy: {best_overall['test_accuracy']:.4f}\")\n",
    "    print(f\"  Overfitting Gap: {best_overall['overfitting_gap']:+.4f}\")\n",
    "    \n",
    "    if best_mlp:\n",
    "        print(f\"\\nBest MLP (per Punto B): {best_mlp['name']}\")\n",
    "        print(f\"  Test Accuracy: {best_mlp['test_accuracy']:.4f}\")\n",
    "        print(f\"  Training Time: {best_mlp['training_time']:.1f}s\")\n",
    "        print(f\"  Iterations: {best_mlp['iterations']}\")\n",
    "    \n",
    "    if best_cnn:\n",
    "        print(f\"\\nBest CNN (per Punti C, E): {best_cnn['name']}\")\n",
    "        print(f\"  Test Accuracy: {best_cnn['test_accuracy']:.4f}\")\n",
    "        print(f\"  Training Time: {best_cnn['training_time']:.1f}s\")\n",
    "        print(f\"  Epochs: {best_cnn['epochs_trained']}\")\n",
    "    \n",
    "    # Salvataggio per utilizzo successivo\n",
    "    selected_models = {\n",
    "        'best_overall': best_overall,\n",
    "        'best_mlp': best_mlp,\n",
    "        'best_cnn': best_cnn\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aebb794",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "---\n",
    "## Conclusioni del Punto A\n",
    "\n",
    "### Insights Principali\n",
    "\n",
    "#### 1. Effetto Learning Rate (Risultato Critico)\n",
    "L'analisi conferma che il learning rate è l'iper-parametro più influente:\n",
    "- **LR = 0.01**: Emerge come sweet spot tra velocità e stabilità\n",
    "- **LR = 0.001**: Convergenza più lenta ma generalizzazione superiore  \n",
    "- **LR = 0.1**: Instabilità confermata, performance degradate\n",
    "\n",
    "#### 2. Superiorità Architettuale CNN\n",
    "Le Convolutional Neural Networks dimostrano vantaggi significativi:\n",
    "- **Inductive bias**: Sfruttamento struttura spaziale delle immagini\n",
    "- **Efficienza parametrica**: Migliori performance con meno parametri\n",
    "- **Robustezza**: Migliore generalizzazione su dati visuali\n",
    "\n",
    "#### 3. Efficacia Early Stopping\n",
    "La regolarizzazione attraverso early stopping si dimostra essenziale:\n",
    "- **Prevenzione overfitting**: Gap train-test mantenuto sotto controllo\n",
    "- **Efficienza**: Riduzione significativa tempi di training\n",
    "- **Stabilità**: Convergenza più affidabile\n",
    "\n",
    "#### 4. Trade-off Capacità vs Generalizzazione\n",
    "L'aumento della capacità del modello mostra rendimenti decrescenti:\n",
    "- **256 neuroni**: Performance massima ma rischio overfitting\n",
    "- **128 neuroni**: Compromesso ottimale efficienza/performance\n",
    "- **64 neuroni**: Sufficiente per task MNIST, velocità superiore\n",
    "\n",
    "### Implicazioni per Punti Successivi\n",
    "I risultati di questo punto guidano le scelte per le analisi successive:\n",
    "- **Configurazioni ottimali**: Identificate per robustezza e performance\n",
    "- **Baseline stabilite**: Per confronti meaningful nei punti C, D, E\n",
    "- **Insights teorici**: Confermati per validazione metodologica\n",
    "\n",
    "### Limitazioni e Considerazioni\n",
    "- **Scope dataset**: Risultati specifici per MNIST, generalizzazione da verificare\n",
    "- **Architetture semplici**: CNN moderne più complesse potrebbero dare risultati diversi\n",
    "- **Iper-parametri**: Spazio limitato esplorato, ottimizzazione fine possibile\n",
    "\n",
    "Il Punto A fornisce una base solida di conoscenza empirica per gli approfondimenti \n",
    "successivi, confermando principi teorici consolidati e identificando le \n",
    "configurazioni ottimali per il proseguimento del progetto."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Mini Progetto IA",
   "language": "python",
   "name": "mini-progetto-ia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
